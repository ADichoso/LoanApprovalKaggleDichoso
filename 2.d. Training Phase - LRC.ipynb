{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5874f36f-b0cf-42ae-bd25-24d8eb148a8b",
   "metadata": {},
   "source": [
    "# Loan Approval Prediction Kaggle Competition\n",
    "## October 28, 2024\n",
    "DICHOSO, Aaron Gabrielle C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daccc002-f6d7-4c45-aca3-66958914286d",
   "metadata": {},
   "source": [
    "This Notebook is part of a series of notebooks that will contain documentation and methods used for training a Logistic Regression Classifier (LRC) used in the <a href=\"https://www.kaggle.com/competitions/playground-series-s4e10/\"><b>2024 Loan Approval Prediction Kaggle Playground Series</b></a>. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e3ced-f659-4669-b964-0eb7a2b168fb",
   "metadata": {},
   "source": [
    "For this notebook, I will focus on the methods that I utilized for model training and hyperparameter training.\n",
    "\n",
    "To view the data cleaning itself, feel free to visit the following notebook: \n",
    "\n",
    "<ul>\n",
    "    <li>1. Data Exploration, Cleaning, and Transformations</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b88cb2-d5b6-4f4e-8642-800b1ade77ff",
   "metadata": {},
   "source": [
    "I chose to test the LRC because it inherently supports binary classification, which is exhibited by the dataset. Additionally, it is computationally efficient and low resource and will allow me to rapidly test it in my system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb91837-caa4-4e90-b3c0-6c1ad3a2be2e",
   "metadata": {},
   "source": [
    "# 1. Import Cleaned Datasets\n",
    "\n",
    "We first import the cleaned datasets from the previous notebook first. In this repository, the cleaned datasets are saved in the <b>./output</b> directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b42ef0-d8b5-4504-b913-bc514293d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8591ee1-527b-4f37-aac5-83ab037d21ea",
   "metadata": {},
   "source": [
    "As observed, there are two kinds of training datasets used, the train set without oversampling, and the dataset that underwent ADASYN oversampling. I wish to test the performance of the model comparing these two methods during the hyperparameter tuning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b701978-d1eb-49fe-90be-05b1af92ee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>PERSON_HOME_OWNERSHIP_MORTGAGE</th>\n",
       "      <th>...</th>\n",
       "      <th>LOAN_GRADE_B</th>\n",
       "      <th>LOAN_GRADE_C</th>\n",
       "      <th>LOAN_GRADE_D</th>\n",
       "      <th>LOAN_GRADE_E</th>\n",
       "      <th>LOAN_GRADE_F</th>\n",
       "      <th>LOAN_GRADE_G</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_11_17</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_18_above</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_5_10</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_5_below</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.569797</td>\n",
       "      <td>-1.081318</td>\n",
       "      <td>-1.896898</td>\n",
       "      <td>-0.578305</td>\n",
       "      <td>0.390423</td>\n",
       "      <td>0.117380</td>\n",
       "      <td>0</td>\n",
       "      <td>1.719062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.921741</td>\n",
       "      <td>-0.052550</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>-0.937769</td>\n",
       "      <td>0.896212</td>\n",
       "      <td>-0.973222</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.364513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.240977</td>\n",
       "      <td>-1.508084</td>\n",
       "      <td>0.923860</td>\n",
       "      <td>-0.578305</td>\n",
       "      <td>-0.470628</td>\n",
       "      <td>0.553620</td>\n",
       "      <td>0</td>\n",
       "      <td>1.185873</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407079</td>\n",
       "      <td>0.435878</td>\n",
       "      <td>1.579649</td>\n",
       "      <td>0.500086</td>\n",
       "      <td>0.277050</td>\n",
       "      <td>0.117380</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.921741</td>\n",
       "      <td>0.098465</td>\n",
       "      <td>-0.486519</td>\n",
       "      <td>-0.578305</td>\n",
       "      <td>-1.318902</td>\n",
       "      <td>-0.646041</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.721995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income  person_emp_length  loan_amnt  loan_int_rate  \\\n",
       "0    1.569797      -1.081318          -1.896898  -0.578305       0.390423   \n",
       "1   -0.921741      -0.052550           0.601227  -0.937769       0.896212   \n",
       "2    0.240977      -1.508084           0.923860  -0.578305      -0.470628   \n",
       "3    0.407079       0.435878           1.579649   0.500086       0.277050   \n",
       "4   -0.921741       0.098465          -0.486519  -0.578305      -1.318902   \n",
       "\n",
       "   loan_percent_income  cb_person_default_on_file  cb_person_cred_hist_length  \\\n",
       "0             0.117380                          0                    1.719062   \n",
       "1            -0.973222                          0                   -1.364513   \n",
       "2             0.553620                          0                    1.185873   \n",
       "3             0.117380                          0                    0.087481   \n",
       "4            -0.646041                          0                   -0.721995   \n",
       "\n",
       "   loan_status  PERSON_HOME_OWNERSHIP_MORTGAGE  ...  LOAN_GRADE_B  \\\n",
       "0            0                               0  ...             1   \n",
       "1            0                               0  ...             0   \n",
       "2            0                               0  ...             0   \n",
       "3            0                               0  ...             1   \n",
       "4            0                               0  ...             0   \n",
       "\n",
       "   LOAN_GRADE_C  LOAN_GRADE_D  LOAN_GRADE_E  LOAN_GRADE_F  LOAN_GRADE_G  \\\n",
       "0             0             0             0             0             0   \n",
       "1             1             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   CB_PERSON_CRED_HIST_LENGTH_11_17  CB_PERSON_CRED_HIST_LENGTH_18_above  \\\n",
       "0                                 1                                    0   \n",
       "1                                 0                                    0   \n",
       "2                                 0                                    0   \n",
       "3                                 0                                    0   \n",
       "4                                 0                                    0   \n",
       "\n",
       "   CB_PERSON_CRED_HIST_LENGTH_5_10  CB_PERSON_CRED_HIST_LENGTH_5_below  \n",
       "0                                0                                   0  \n",
       "1                                0                                   1  \n",
       "2                                1                                   0  \n",
       "3                                1                                   0  \n",
       "4                                0                                   1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Import Training Dataset\n",
    "loans_train_df = pd.read_csv('./outputs/cleaned_loans_train.csv')\n",
    "loans_train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584ddd0d-0824-4353-9e4c-2b5808e7380d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>PERSON_HOME_OWNERSHIP_MORTGAGE</th>\n",
       "      <th>PERSON_HOME_OWNERSHIP_OTHER</th>\n",
       "      <th>...</th>\n",
       "      <th>LOAN_GRADE_C</th>\n",
       "      <th>LOAN_GRADE_D</th>\n",
       "      <th>LOAN_GRADE_E</th>\n",
       "      <th>LOAN_GRADE_F</th>\n",
       "      <th>LOAN_GRADE_G</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_11_17</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_18_above</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_5_10</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_5_below</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.569797</td>\n",
       "      <td>-1.081318</td>\n",
       "      <td>-1.896898</td>\n",
       "      <td>-0.578305</td>\n",
       "      <td>0.390423</td>\n",
       "      <td>0.117380</td>\n",
       "      <td>0</td>\n",
       "      <td>1.719062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.921741</td>\n",
       "      <td>-0.052550</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>-0.937769</td>\n",
       "      <td>0.896212</td>\n",
       "      <td>-0.973222</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.364513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.240977</td>\n",
       "      <td>-1.508084</td>\n",
       "      <td>0.923860</td>\n",
       "      <td>-0.578305</td>\n",
       "      <td>-0.470628</td>\n",
       "      <td>0.553620</td>\n",
       "      <td>0</td>\n",
       "      <td>1.185873</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407079</td>\n",
       "      <td>0.435878</td>\n",
       "      <td>1.579649</td>\n",
       "      <td>0.500086</td>\n",
       "      <td>0.277050</td>\n",
       "      <td>0.117380</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.921741</td>\n",
       "      <td>0.098465</td>\n",
       "      <td>-0.486519</td>\n",
       "      <td>-0.578305</td>\n",
       "      <td>-1.318902</td>\n",
       "      <td>-0.646041</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.721995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income  person_emp_length  loan_amnt  loan_int_rate  \\\n",
       "0    1.569797      -1.081318          -1.896898  -0.578305       0.390423   \n",
       "1   -0.921741      -0.052550           0.601227  -0.937769       0.896212   \n",
       "2    0.240977      -1.508084           0.923860  -0.578305      -0.470628   \n",
       "3    0.407079       0.435878           1.579649   0.500086       0.277050   \n",
       "4   -0.921741       0.098465          -0.486519  -0.578305      -1.318902   \n",
       "\n",
       "   loan_percent_income  cb_person_default_on_file  cb_person_cred_hist_length  \\\n",
       "0             0.117380                          0                    1.719062   \n",
       "1            -0.973222                          0                   -1.364513   \n",
       "2             0.553620                          0                    1.185873   \n",
       "3             0.117380                          0                    0.087481   \n",
       "4            -0.646041                          0                   -0.721995   \n",
       "\n",
       "   PERSON_HOME_OWNERSHIP_MORTGAGE  PERSON_HOME_OWNERSHIP_OTHER  ...  \\\n",
       "0                               0                            0  ...   \n",
       "1                               0                            0  ...   \n",
       "2                               0                            0  ...   \n",
       "3                               0                            0  ...   \n",
       "4                               0                            0  ...   \n",
       "\n",
       "   LOAN_GRADE_C  LOAN_GRADE_D  LOAN_GRADE_E  LOAN_GRADE_F  LOAN_GRADE_G  \\\n",
       "0             0             0             0             0             0   \n",
       "1             1             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   CB_PERSON_CRED_HIST_LENGTH_11_17  CB_PERSON_CRED_HIST_LENGTH_18_above  \\\n",
       "0                                 1                                    0   \n",
       "1                                 0                                    0   \n",
       "2                                 0                                    0   \n",
       "3                                 0                                    0   \n",
       "4                                 0                                    0   \n",
       "\n",
       "   CB_PERSON_CRED_HIST_LENGTH_5_10  CB_PERSON_CRED_HIST_LENGTH_5_below  \\\n",
       "0                                0                                   0   \n",
       "1                                0                                   1   \n",
       "2                                1                                   0   \n",
       "3                                1                                   0   \n",
       "4                                0                                   1   \n",
       "\n",
       "   loan_status  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_train_ada_df = pd.read_csv('./outputs/cleaned_loans_train_ada.csv')\n",
    "loans_train_ada_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe935b2-2b7e-40b3-a68f-997c9bc585d9",
   "metadata": {},
   "source": [
    "# 2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21be5a-772c-4cec-876d-515514b8187f",
   "metadata": {},
   "source": [
    "The LRC has several hyperparameters that should be tuned to maximize its performance.\n",
    "\n",
    "In this notebook, I will focus on tuning the following <a href=\"https://scikit-learn.org/dev/modules/generated/sklearn.linear_model.LogisticRegression.html\">hyperparameters of the LRC</a>:\n",
    "<ol>\n",
    "    <li><b>C:</b> The inverse regularization strength</li>\n",
    "    <li><b>tol:</b> The tolerance used for stopping the training</li>\n",
    "    <li><b>solver:</b> The solver used for optimization</li>\n",
    "    <li><b>oversampling_method:</b> The type of oversampling done in the dataset used.</li>\n",
    "</ol>\n",
    "\n",
    "The range of follows I chose for these hyperparameters are as follows:\n",
    "<ol>\n",
    "    <li><b>C:</b>[0.001, 100]</li>\n",
    "    <li><b>tol:</b>[0.00001, 0.1]</li>\n",
    "    <li><b>solver:</b> all the possible values for the solver specified in <a href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">scikit-learn</a></li>\n",
    "    <li><b>oversampling_method:</b> Either using the ADASYN oversampled data set or the unbalanced labels dataset.</li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb8e823-e7ef-4f41-9edd-e8a3c8039166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>tol</th>\n",
       "      <th>solver</th>\n",
       "      <th>oversampling_method</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [C, tol, solver, oversampling_method, roc_auc]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyper_tuning = pd.DataFrame(columns=['C', 'tol', 'solver', 'oversampling_method', 'roc_auc'])\n",
    "df_hyper_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053aa20-971f-48f0-8758-626e3dff1293",
   "metadata": {},
   "source": [
    "For the specific method of hyperparameter tuning, I chose to perform bayesian optimization, which is a hyperparameter tuning method that involves observing the past iterations of the tuning process to influence the configurations to test later on. I chose this method over GridSearch because of the numerous possible configurations that I would need to search through not being a feasible method for my system. Additionally, I chose it over RandomSearch because bayesian optimization would be able to utilize my system resources more effectively by searching in areas with higher probabilities of giving me high performances as opposed to randomly testing configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65caba48-edaa-4ebd-807f-81ef38d65c29",
   "metadata": {},
   "source": [
    "To perform bayesian optimization, I utilized the <a href=\"https://scikit-optimize.github.io/stable/modules/generated/skopt.gp_minimize.html\">gp_minimize()</a> function provided by the scikit-optimize library.\n",
    "\n",
    "Following the instructions found in the documentations, I first initialized the search space to be used in the optimization process. This involved creating an array that pertains to the hyperparameters to tune, the data type of the hyperparameters, and the range of possible values to test in the hyperparameter tuning process.\n",
    "\n",
    "Afterwards, I created the objective function that the gp_minimize() function will execute. The objective function will use the search space defined earlier and test different values for the hyperparameters. It will then return the negative value of the Area Under the ROC (AUC) obtained from 3-fold cross validation, as this value will be minimized by the gp_minimize() function. Invalid configurations during hyperparameter tuning process will be given a positive value, allowing the bayesian optimization process to avoid such configurations.\n",
    "\n",
    "I also limit the number of calls performed by the function due to my limited resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23925d52-e297-48f0-82ca-2f510b643f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 61.38813373267659\n",
      "Tolerance: 0.07506231648759176\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.9039113112458258\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 52.423256744926704\n",
      "Tolerance: 0.07538787067366931\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Results: -0.7910640337424818\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 14.57621637433194\n",
      "Tolerance: 0.06082289193828174\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n",
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 7 epochs took 0 seconds\n",
      "Results: -0.9041687679408238\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 28.560003742694672\n",
      "Tolerance: 0.02387808242280019\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640532014334877 <= 0.02387808242280019\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705059556339698 <= 0.02387808242280019\n",
      "    2. Newton decrement 0.028505192116137792 <= 0.02387808242280019\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001767300076442146 <= 0.02387808242280019\n",
      "    2. Newton decrement 0.0035046102328160898 <= 0.02387808242280019\n",
      "  Solver did converge at loss = 0.38790011448262907.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467100149188656 <= 0.02387808242280019\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015048756186849109 <= 0.02387808242280019\n",
      "    2. Newton decrement 0.029018079888902832 <= 0.02387808242280019\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018119234443773075 <= 0.02387808242280019\n",
      "    2. Newton decrement 0.0037051160441567157 <= 0.02387808242280019\n",
      "  Solver did converge at loss = 0.38731146296975055.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0624158533103637 <= 0.02387808242280019\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153161350485634 <= 0.02387808242280019\n",
      "    2. Newton decrement 0.028156586316989238 <= 0.02387808242280019\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017032792407467028 <= 0.02387808242280019\n",
      "    2. Newton decrement 0.003526627775154699 <= 0.02387808242280019\n",
      "  Solver did converge at loss = 0.39103394670402675.\n",
      "Results: -0.9045820824110861\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 25.89927902567722\n",
      "Tolerance: 0.08400424195537848\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "Results: -0.9042979375506408\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 89.17194772682063\n",
      "Tolerance: 0.07274928067601948\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405393869091529 <= 0.07274928067601948\n",
      "    2. Newton decrement 0.2363460734542028 <= 0.07274928067601948\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705704678430909 <= 0.07274928067601948\n",
      "    2. Newton decrement 0.028507023043477256 <= 0.07274928067601948\n",
      "  Solver did converge at loss = 0.39173080601352495.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467172471076657 <= 0.07274928067601948\n",
      "    2. Newton decrement 0.23586000913948488 <= 0.07274928067601948\n",
      "Newton iter=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049381149119858 <= 0.07274928067601948\n",
      "    2. Newton decrement 0.029019968762957565 <= 0.07274928067601948\n",
      "  Solver did converge at loss = 0.391375131219619.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0624165931720591 <= 0.07274928067601948\n",
      "    2. Newton decrement 0.233943222006158 <= 0.07274928067601948\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153769011991753 <= 0.07274928067601948\n",
      "    2. Newton decrement 0.028158612125828184 <= 0.07274928067601948\n",
      "  Solver did converge at loss = 0.39490111593248484.\n",
      "Results: -0.9043098802335255\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 68.06393505876494\n",
      "Tolerance: 0.09358955728534335\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear]Results: -0.8743605430393425\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 32.2316593363366\n",
      "Tolerance: 0.06521172649335567\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Results: -0.7950924614862158\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 72.51072309248043\n",
      "Tolerance: 0.0144420977331066\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8360968155355843\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 10.608586111795326\n",
      "Tolerance: 0.00813090098762674\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.9039608079185495\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 93.47798829753708\n",
      "Tolerance: 0.0006129796131966009\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046188860069727\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.953168993343809\n",
      "Tolerance: 0.08801685626500391\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044493732173252\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 20.160906272741077\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8869606603108631\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.044158685725476945\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890853709743\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.1\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8722073959969611\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 12.508553571711852\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046195783549805\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 7.496159746819083\n",
      "Tolerance: 0.056757899730662496\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405015761018971 <= 0.056757899730662496\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014702402403046138 <= 0.056757899730662496\n",
      "    2. Newton decrement 0.028497640607482586 <= 0.056757899730662496\n",
      "  Solver did converge at loss = 0.39175573443194234.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06466801616590077 <= 0.056757899730662496\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015046181518232714 <= 0.056757899730662496\n",
      "    2. Newton decrement 0.029010293229139842 <= 0.056757899730662496\n",
      "  Solver did converge at loss = 0.39139995535093436.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241280085880368 <= 0.056757899730662496\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014150659440958181 <= 0.056757899730662496\n",
      "    2. Newton decrement 0.028148247759514102 <= 0.056757899730662496\n",
      "  Solver did converge at loss = 0.3949279297663795.\n",
      "Results: -0.9043103802729661\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.91517326438365\n",
      "Tolerance: 0.06654992577339888\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8766984406718609\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 3.154526780158579\n",
      "Tolerance: 0.019827023678918726\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8887428298284621\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 98.49351813945135\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 59 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 132 epochs took 2 seconds\n",
      "Results: -0.9046185360820936\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 33.97613816457028\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046226577657537\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 35.84610335142041\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.064053421860314 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705252373347041 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017674741008245583 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.650183302787805e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.2486637752283846e-07 <= 1e-05\n",
      "    2. Newton decrement 1.7806284491459263e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3877997681308538.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467121771607134 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015048942983820533 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018120713754648209 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.562362618991519e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.920312541296014e-08 <= 1e-05\n",
      "    2. Newton decrement 2.2288810044431693e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38719482362929375.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241607449466461 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415334296171762 <= 1e-05\n",
      "Newton iter=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017035413211490152 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.51834512827081e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.953728429933045e-07 <= 1e-05\n",
      "    2. Newton decrement 3.3118133227887156e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.39091944508777965.\n",
      "Results: -0.9046189717711294\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 12.741480149569492\n",
      "Tolerance: 1e-05\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n",
      "Results: -0.9046207074642617\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 23.844414619130657\n",
      "Tolerance: 0.03005107566748732\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 0 seconds\n",
      "Results: -0.8859200770821536\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 90.88048166377607\n",
      "Tolerance: 0.1\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.8838044508349489\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.030073343137610047\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 6 epochs took 1 seconds\n",
      "Results: -0.8961537737324009\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 80.4836452479668\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405390118048732 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705671841153192 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017678541260932857 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.662538196974982e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.3136808840575882e-07 <= 1e-05\n",
      "    2. Newton decrement 1.816831875868568e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3877955568044453.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467168791335884 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049349339243099 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001812394272041676 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.5672897507581545e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.957570520524954e-08 <= 1e-05\n",
      "    2. Newton decrement 2.2402047731275998e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3871905653770446.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241655552425177 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153738079328551 <= 1e-05\n",
      "Newton iter=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017041158707188611 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.5418162726903124e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.1440402036127788e-07 <= 1e-05\n",
      "    2. Newton decrement 3.419574962735607e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.39091460843425735.\n",
      "Results: -0.9046185574979854\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 88.54471040917299\n",
      "Tolerance: 1e-05\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 11 seconds\n",
      "Results: -0.8869668044241167\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 98.39261612040436\n",
      "Tolerance: 0.04204173604894134\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8852227042019596\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046171572548597\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 67.0561048811803\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185218041191\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 89.57182334907972\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185646637253\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 32.32306071767738\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046192574033887\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.06712973066319955\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8960656331654512\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.1\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044545813496984\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.025752170796517548\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8960656331654512\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.1\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 2 epochs took 0 seconds\n",
      "Results: -0.9038401260555626\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.904618564672286\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 5.289930722984281\n",
      "Tolerance: 0.06548759873119481\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.8850004624111971\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [63.99084038301082, 0.06170187310118028, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 63.99084038301082\n",
      "Tolerance: 0.06170187310118028\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.904526061898001\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [8.258791768949353, 0.06915369965660927, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 8.258791768949353\n",
      "Tolerance: 0.06915369965660927\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044538240477505\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.02528651896454708\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0377238249797234 <= 0.02528651896454708\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009979258476086106 <= 0.02528651896454708\n",
      "    2. Newton decrement 0.030950753145539044 <= 0.02528651896454708\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0022125388922124064 <= 0.02528651896454708\n",
      "    2. Newton decrement 0.007678255168268176 <= 0.02528651896454708\n",
      "  Solver did converge at loss = 0.4159271956075463.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129294271005852 <= 0.02528651896454708\n",
      "Newton iter=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.01049040036913165 <= 0.02528651896454708\n",
      "    2. Newton decrement 0.029645586301486122 <= 0.02528651896454708\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017256441127322317 <= 0.02528651896454708\n",
      "    2. Newton decrement 0.006531305744895619 <= 0.02528651896454708\n",
      "  Solver did converge at loss = 0.41474805653476626.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203901340427597 <= 0.02528651896454708\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010449381395664238 <= 0.02528651896454708\n",
      "    2. Newton decrement 0.030017973988133384 <= 0.02528651896454708\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001730075397076026 <= 0.02528651896454708\n",
      "    2. Newton decrement 0.006714017883133291 <= 0.02528651896454708\n",
      "  Solver did converge at loss = 0.4147216523557071.\n",
      "Results: -0.8863074965930794\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'lbfgs', 'none'] before, using random point [57.594480438817044, 0.030229498004170307, 'newton-cg', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.594480438817044\n",
      "Tolerance: 0.030229498004170307\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8887434084898618\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [86.09709470833307, 0.08630089794995444, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 86.09709470833307\n",
      "Tolerance: 0.08630089794995444\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 1 seconds\n",
      "Results: -0.9039890278932864\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [57.47385038082013, 0.013662451810283019, 'lbfgs', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.47385038082013\n",
      "Tolerance: 0.013662451810283019\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8360968378308579\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [69.84773116287103, 0.04176734984428081, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.84773116287103\n",
      "Tolerance: 0.04176734984428081\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.9045324562669022\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'lbfgs', 'none'] before, using random point [21.701248390309274, 0.04982516419833863, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 21.701248390309274\n",
      "Tolerance: 0.04982516419833863\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 7 epochs took 1 seconds\n",
      "Results: -0.8860864092749109\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'lbfgs', 'none'] before, using random point [91.65369903338055, 0.016315627435197464, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 91.65369903338055\n",
      "Tolerance: 0.016315627435197464\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 8 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 0 seconds\n",
      "Results: -0.9046123244829108\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [53.39016411183325, 0.0007374340166495701, 'newton-cg', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 53.39016411183325\n",
      "Tolerance: 0.0007374340166495701\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8869017619727435\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046189145714827\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [21.080206898244757, 0.05065880385132651, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 21.080206898244757\n",
      "Tolerance: 0.05065880385132651\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03771939620394339 <= 0.05065880385132651\n",
      "    2. Newton decrement 0.20079958735922376 <= 0.05065880385132651\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009970570014080913 <= 0.05065880385132651\n",
      "    2. Newton decrement 0.030906322932574386 <= 0.05065880385132651\n",
      "  Solver did converge at loss = 0.4254010552174812.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.041287901476739705 <= 0.05065880385132651\n",
      "    2. Newton decrement 0.20554698244726416 <= 0.05065880385132651\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010481861240301055 <= 0.05065880385132651\n",
      "    2. Newton decrement 0.02960847395587674 <= 0.05065880385132651\n",
      "  Solver did converge at loss = 0.42269080558424926.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.042034108906097774 <= 0.05065880385132651\n",
      "    2. Newton decrement 0.20479912468678502 <= 0.05065880385132651\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010441507234646971 <= 0.05065880385132651\n",
      "    2. Newton decrement 0.029984501973448582 <= 0.05065880385132651\n",
      "  Solver did converge at loss = 0.4228745336732781.\n",
      "Results: -0.884948512334968\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [46.580021655167776, 0.011665003898637333, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 46.580021655167776\n",
      "Tolerance: 0.011665003898637333\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890496642666\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [18.134528854756105, 0.0908408179647901, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 18.134528854756105\n",
      "Tolerance: 0.0908408179647901\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8743406321710935\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [87.57706335942129, 0.03630328980454606, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 87.57706335942129\n",
      "Tolerance: 0.03630328980454606\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 9 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 0 seconds\n",
      "Results: -0.8865343274753877\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [89.11955280875772, 0.07064247073192644, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 89.11955280875772\n",
      "Tolerance: 0.07064247073192644\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044545313414738\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [93.4874833407479, 0.09167143801091393, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 93.4874833407479\n",
      "Tolerance: 0.09167143801091393\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405395473127258 <= 0.09167143801091393\n",
      "    2. Newton decrement 0.2363461073512048 <= 0.09167143801091393\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705718720914687 <= 0.09167143801091393\n",
      "    2. Newton decrement 0.028507062886654506 <= 0.09167143801091393\n",
      "  Solver did converge at loss = 0.39173070019848066.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467174044626002 <= 0.09167143801091393\n",
      "    2. Newton decrement 0.23586004080174477 <= 0.09167143801091393\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049394752206678 <= 0.09167143801091393\n",
      "    2. Newton decrement 0.029020009871226514 <= 0.09167143801091393\n",
      "  Solver did converge at loss = 0.39137502580387606.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416609271323226 <= 0.09167143801091393\n",
      "    2. Newton decrement 0.23394325650990974 <= 0.09167143801091393\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153782240059755 <= 0.09167143801091393\n",
      "    2. Newton decrement 0.028158656227772673 <= 0.09167143801091393\n",
      "  Solver did converge at loss = 0.394901001925606.\n",
      "Results: -0.9043099302438903\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [20.03380627695541, 0.016435699743674512, 'newton-cg', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 20.03380627695541\n",
      "Tolerance: 0.016435699743674512\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8464728306021089\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 1e-05\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 172 epochs took 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 133 epochs took 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 245 epochs took 5 seconds\n",
      "Results: -0.9046185432242911\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [70.6933514934616, 0.013050801915437501, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 70.6933514934616\n",
      "Tolerance: 0.013050801915437501\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384786556438 <= 0.013050801915437501\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705625171036652 <= 0.013050801915437501\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017678117461106177 <= 0.013050801915437501\n",
      "    2. Newton decrement 0.0035056052013207094 <= 0.013050801915437501\n",
      "  Solver did converge at loss = 0.3878946281805987.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467163561210566 <= 0.013050801915437501\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049304129094143 <= 0.013050801915437501\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018123582729728355 <= 0.013050801915437501\n",
      "    2. Newton decrement 0.003706197962310913 <= 0.013050801915437501\n",
      "  Solver did converge at loss = 0.38730589159176193.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241650201496746 <= 0.013050801915437501\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153694116551633 <= 0.013050801915437501\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017040516451797048 <= 0.013050801915437501\n",
      "    2. Newton decrement 0.0035278894069846866 <= 0.013050801915437501\n",
      "  Solver did converge at loss = 0.39102776971562314.\n",
      "Results: -0.9045820253419915\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [57.37132322260594, 0.08168629092427221, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.37132322260594\n",
      "Tolerance: 0.08168629092427221\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.9044603610230424\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [0.668327885425539, 0.02508125723038816, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.668327885425539\n",
      "Tolerance: 0.02508125723038816\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06400861969567051 <= 0.02508125723038816\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014666995606700161 <= 0.02508125723038816\n",
      "    2. Newton decrement 0.028395691655106105 <= 0.02508125723038816\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017383844512133362 <= 0.02508125723038816\n",
      "    2. Newton decrement 0.0034405374466793576 <= 0.02508125723038816\n",
      "  Solver did converge at loss = 0.38826989810528684.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06462735463977176 <= 0.02508125723038816\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015011781441741437 <= 0.02508125723038816\n",
      "    2. Newton decrement 0.02890568719365965 <= 0.02508125723038816\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017866672504526608 <= 0.02508125723038816\n",
      "    2. Newton decrement 0.0036350069065600264 <= 0.02508125723038816\n",
      "  Solver did converge at loss = 0.38768645301951743.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062371458702010295 <= 0.02508125723038816\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014117471404134642 <= 0.02508125723038816\n",
      "    2. Newton decrement 0.02803783660787107 <= 0.02508125723038816\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0016663453184422867 <= 0.02508125723038816\n",
      "    2. Newton decrement 0.003450583244559719 <= 0.02508125723038816\n",
      "  Solver did converge at loss = 0.3914367968899718.\n",
      "Results: -0.9045857517649605\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [90.06996166372588, 0.08947183631707832, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 90.06996166372588\n",
      "Tolerance: 0.08947183631707832\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044545313414738\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [83.41351563524405, 0.044725878185286234, 'sag', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 83.41351563524405\n",
      "Tolerance: 0.044725878185286234\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 6 epochs took 0 seconds\n",
      "convergence after 9 epochs took 0 seconds\n",
      "Results: -0.9044156832663406\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [83.59049399541188, 0.0735371992095172, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 83.59049399541188\n",
      "Tolerance: 0.0735371992095172\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 6 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.8861606677480891\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [21.532889709840923, 0.024768868345230288, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 21.532889709840923\n",
      "Tolerance: 0.024768868345230288\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03771951542198105 <= 0.024768868345230288\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009970814682714775 <= 0.024768868345230288\n",
      "    2. Newton decrement 0.030907483423877256 <= 0.024768868345230288\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.002191733604134905 <= 0.024768868345230288\n",
      "    2. Newton decrement 0.007626787675255623 <= 0.024768868345230288\n",
      "  Solver did converge at loss = 0.41610184361063535.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04128803554163032 <= 0.024768868345230288\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010482088176887306 <= 0.024768868345230288\n",
      "    2. Newton decrement 0.029609458275794788 <= 0.024768868345230288\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017053657731111692 <= 0.024768868345230288\n",
      "    2. Newton decrement 0.0064858123925062615 <= 0.024768868345230288\n",
      "  Solver did converge at loss = 0.4148951039821673.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.042034239382580496 <= 0.024768868345230288\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01044171637336112 <= 0.024768868345230288\n",
      "    2. Newton decrement 0.029985390449227524 <= 0.024768868345230288\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017108287046989634 <= 0.024768868345230288\n",
      "    2. Newton decrement 0.006672104664564576 <= 0.024768868345230288\n",
      "  Solver did converge at loss = 0.4148570301306836.\n",
      "Results: -0.8864337253982296\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [20.21737627735544, 0.054522040410433806, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 20.21737627735544\n",
      "Tolerance: 0.054522040410433806\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.8849872859134106\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [13.877182195568334, 0.00703481695472929, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 13.877182195568334\n",
      "Tolerance: 0.00703481695472929\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 26 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 31 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 27 epochs took 1 seconds\n",
      "Results: -0.8868296483813646\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [27.983116644114954, 0.020117721433407804, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 27.983116644114954\n",
      "Tolerance: 0.020117721433407804\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640531790787557 <= 0.020117721433407804\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705040004667925 <= 0.020117721433407804\n",
      "    2. Newton decrement 0.028505136611040746 <= 0.020117721433407804\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017672824534475118 <= 0.020117721433407804\n",
      "    2. Newton decrement 0.0035045758691980523 <= 0.020117721433407804\n",
      "  Solver did converge at loss = 0.38790030412371457.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467097956362365 <= 0.020117721433407804\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504873724535107 <= 0.020117721433407804\n",
      "    2. Newton decrement 0.029018022632879642 <= 0.020117721433407804\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018119084614058312 <= 0.020117721433407804\n",
      "    2. Newton decrement 0.0037050786723451653 <= 0.020117721433407804\n",
      "  Solver did converge at loss = 0.38731165555054825.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062415830879818446 <= 0.020117721433407804\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153142935528395 <= 0.020117721433407804\n",
      "    2. Newton decrement 0.02815652492907193 <= 0.020117721433407804\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017032527361635738 <= 0.020117721433407804\n",
      "    2. Newton decrement 0.0035265842709683594 <= 0.020117721433407804\n",
      "  Solver did converge at loss = 0.39103416005360037.\n",
      "Results: -0.9045820824110861\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [86.1841866573752, 0.024251553010874737, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 86.1841866573752\n",
      "Tolerance: 0.024251553010874737\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 11 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 0 seconds\n",
      "Results: -0.886107784597383\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [24.92632292761637, 0.054129216422556914, 'newton-cg', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 24.92632292761637\n",
      "Tolerance: 0.054129216422556914\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8807637832162429\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [24.024273036187722, 0.037913192955762565, 'sag', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 24.024273036187722\n",
      "Tolerance: 0.037913192955762565\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 7 epochs took 1 seconds\n",
      "convergence after 8 epochs took 0 seconds\n",
      "Results: -0.9045715721338722\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [50.92347937732947, 0.014213469311232855, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 50.92347937732947\n",
      "Tolerance: 0.014213469311232855\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 13 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 17 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 0 seconds\n",
      "Results: -0.8869040806311689\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [85.1751295696793, 0.09789556827718626, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 85.1751295696793\n",
      "Tolerance: 0.09789556827718626\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8743619699379761\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [24.7618336736061, 0.08700577739451493, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 24.7618336736061\n",
      "Tolerance: 0.08700577739451493\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044543455972516\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [60.05372320803758, 0.051593095535079354, 'lbfgs', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 60.05372320803758\n",
      "Tolerance: 0.051593095535079354\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8722073888526234\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [12.409196940398324, 0.06507693928543476, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 12.409196940398324\n",
      "Tolerance: 0.06507693928543476\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405179079288086 <= 0.06507693928543476\n",
      "    2. Newton decrement 0.23634153313621628 <= 0.06507693928543476\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470382686863827 <= 0.06507693928543476\n",
      "    2. Newton decrement 0.028501690901328383 <= 0.06507693928543476\n",
      "  Solver did converge at loss = 0.3917449705099164.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06466961785429992 <= 0.06507693928543476\n",
      "    2. Newton decrement 0.23585576849289455 <= 0.06507693928543476\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015047561875612578 <= 0.06507693928543476\n",
      "    2. Newton decrement 0.02901446888396501 <= 0.06507693928543476\n",
      "  Solver did converge at loss = 0.39138923893547467.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241443824771165 <= 0.06507693928543476\n",
      "    2. Newton decrement 0.23393860141800993 <= 0.06507693928543476\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415200049164402 <= 0.06507693928543476\n",
      "    2. Newton decrement 0.028152716878036554 <= 0.06507693928543476\n",
      "  Solver did converge at loss = 0.3949163624681287.\n",
      "Results: -0.9043104231668156\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [82.29240831988305, 0.016776654617057952, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 82.29240831988305\n",
      "Tolerance: 0.016776654617057952\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045893497050526\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [31.835503841475518, 0.07650226396648085, 'newton-cg', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 31.835503841475518\n",
      "Tolerance: 0.07650226396648085\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.876698433527523\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [6.430788642854505, 0.04876557997826921, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 6.430788642854505\n",
      "Tolerance: 0.04876557997826921\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06404947477093705 <= 0.04876557997826921\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014701807672480508 <= 0.04876557997826921\n",
      "    2. Newton decrement 0.028495948196921576 <= 0.04876557997826921\n",
      "  Solver did converge at loss = 0.3917602332908713.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06466734656747337 <= 0.04876557997826921\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015045605126875222 <= 0.04876557997826921\n",
      "    2. Newton decrement 0.029008548952941877 <= 0.04876557997826921\n",
      "  Solver did converge at loss = 0.39140443325747665.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241211654941318 <= 0.04876557997826921\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415009966824619 <= 0.04876557997826921\n",
      "    2. Newton decrement 0.028146382574825105 <= 0.04876557997826921\n",
      "  Solver did converge at loss = 0.3949327596841316.\n",
      "Results: -0.9043103445491368\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [64.99904871616457, 0.0441608241777266, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 64.99904871616457\n",
      "Tolerance: 0.0441608241777266\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640538094700558 <= 0.0441608241777266\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705591562835916 <= 0.0441608241777266\n",
      "    2. Newton decrement 0.028506702080041312 <= 0.0441608241777266\n",
      "  Solver did converge at loss = 0.39173165843845303.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467159794677257 <= 0.0441608241777266\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049271572081982 <= 0.0441608241777266\n",
      "    2. Newton decrement 0.02901963761474883 <= 0.0441608241777266\n",
      "  Solver did converge at loss = 0.3913759804142963.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241646348014223 <= 0.0441608241777266\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153662458257124 <= 0.0441608241777266\n",
      "    2. Newton decrement 0.02815825688308339 <= 0.0441608241777266\n",
      "  Solver did converge at loss = 0.3949020342898446.\n",
      "Results: -0.9043098802463666\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 45.917353758338685\n",
      "Tolerance: 0.08666879298242049\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405361139815377 <= 0.08666879298242049\n",
      "    2. Newton decrement 0.23634538177680758 <= 0.08666879298242049\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470541821331544 <= 0.08666879298242049\n",
      "    2. Newton decrement 0.02850621014522394 <= 0.08666879298242049\n",
      "  Solver did converge at loss = 0.39173296498291826.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467140364385401 <= 0.08666879298242049\n",
      "    2. Newton decrement 0.2358593630708468 <= 0.08666879298242049\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504910364231525 <= 0.08666879298242049\n",
      "    2. Newton decrement 0.029019130091941635 <= 0.08666879298242049\n",
      "  Solver did converge at loss = 0.3913772819608729.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241626469825204 <= 0.08666879298242049\n",
      "    2. Newton decrement 0.23394251797213292 <= 0.08666879298242049\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415349917011678 <= 0.08666879298242049\n",
      "    2. Newton decrement 0.028157712505210607 <= 0.08666879298242049\n",
      "  Solver did converge at loss = 0.39490344168689295.\n",
      "Results: -0.9043101088330737\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [63.53321218810329, 0.002710736682278122, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 63.53321218810329\n",
      "Tolerance: 0.002710736682278122\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 97 epochs took 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 51 epochs took 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 69 epochs took 2 seconds\n",
      "Results: -0.8870148777168554\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [54.34329425147949, 0.009975421202902261, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 54.34329425147949\n",
      "Tolerance: 0.009975421202902261\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 21 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 24 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 19 epochs took 1 seconds\n",
      "Results: -0.8866669749272577\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [75.45253988580306, 0.031496295321909965, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 75.45253988580306\n",
      "Tolerance: 0.031496295321909965\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8853597675105161\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [57.27485456249457, 0.04841239872829572, 'lbfgs', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.27485456249457\n",
      "Tolerance: 0.04841239872829572\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8722073888526234\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [32.91719464376894, 0.09066311593822246, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 32.91719464376894\n",
      "Tolerance: 0.09066311593822246\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772142631369214 <= 0.09066311593822246\n",
      "    2. Newton decrement 0.2008106153346119 <= 0.09066311593822246\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009974663358192956 <= 0.09066311593822246\n",
      "    2. Newton decrement 0.03092633636545833 <= 0.09066311593822246\n",
      "  Solver did converge at loss = 0.42535397648941853.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0412901963667791 <= 0.09066311593822246\n",
      "    2. Newton decrement 0.2055551209061859 <= 0.09066311593822246\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010485747036307327 <= 0.09066311593822246\n",
      "    2. Newton decrement 0.02962534306487099 <= 0.09066311593822246\n",
      "  Solver did converge at loss = 0.4226523979584145.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.042036342010268714 <= 0.09066311593822246\n",
      "    2. Newton decrement 0.20480694672340505 <= 0.09066311593822246\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010445089203324176 <= 0.09066311593822246\n",
      "    2. Newton decrement 0.029999723199658504 <= 0.09066311593822246\n",
      "  Solver did converge at loss = 0.4228392797964845.\n",
      "Results: -0.8849227495589006\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [52.68745650953867, 0.024916337428577726, 'newton-cg', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 52.68745650953867\n",
      "Tolerance: 0.024916337428577726\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8189424474249988\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405397631677248 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705737618328735 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017679138987479386 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.664506874269676e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.324328048491303e-07 <= 1e-05\n",
      "    2. Newton decrement 1.8227121301321343e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38779489620817714.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467176162154314 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049413058271706 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018124450408189593 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.5680724454707625e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.963426299769283e-08 <= 1e-05\n",
      "    2. Newton decrement 2.2420021009865438e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.387189897550552.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241663093624492 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153800041555552 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017042065196178789 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.545590132960241e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.175929657257487e-07 <= 1e-05\n",
      "    2. Newton decrement 3.4374720546750545e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3909138487931094.\n",
      "Results: -0.9046185003625448\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [81.04840696434081, 0.02441864871758643, 'newton-cg', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 81.04840696434081\n",
      "Tolerance: 0.02441864871758643\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8189424591593545\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [31.389361658044418, 0.010881064522473434, 'sag', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 31.389361658044418\n",
      "Tolerance: 0.010881064522473434\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 14 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 10 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 1 seconds\n",
      "Results: -0.9045983420525081\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [70.22824004729333, 0.05915986715807399, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 70.22824004729333\n",
      "Tolerance: 0.05915986715807399\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8829031886508149\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [30.732045542544924, 0.018268129997556164, 'newton-cg', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 30.732045542544924\n",
      "Tolerance: 0.018268129997556164\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8464728470302796\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 99.33066193619291\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405397422876587 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705735790323164 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017679122369482075 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.664452046653533e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.3240304439801554e-07 <= 1e-05\n",
      "    2. Newton decrement 1.8225479461574118e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38779491456752524.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646717595732157 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049411287471143 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001812443629412226 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.568050656285846e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.963263514714472e-08 <= 1e-05\n",
      "    2. Newton decrement 2.2419520706773073e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38718991611035525.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241662884054812 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153798319558254 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001704203998362768 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.545484904890304e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.1750355437297964e-07 <= 1e-05\n",
      "    2. Newton decrement 3.4369708462719925e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.39091386990868643.\n",
      "Results: -0.9046184860760094\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [52.01119378836533, 0.0825777863373898, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 52.01119378836533\n",
      "Tolerance: 0.0825777863373898\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8841514874146027\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [90.6845442271009, 0.007061386962934689, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 90.6845442271009\n",
      "Tolerance: 0.007061386962934689\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046323943574603\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [9.217241906518458, 0.015938447839357155, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 9.217241906518458\n",
      "Tolerance: 0.015938447839357155\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 13 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 0 seconds\n",
      "Results: -0.8868931136738855\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [36.27915988000924, 0.08803880040852653, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 36.27915988000924\n",
      "Tolerance: 0.08803880040852653\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "Results: -0.9044689206239255\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [35.882744584926016, 0.051054985110118925, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 35.882744584926016\n",
      "Tolerance: 0.051054985110118925\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.904588942494919\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [57.42079389793829, 0.05705005223127997, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.42079389793829\n",
      "Tolerance: 0.05705005223127997\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045889639150912\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [34.53845943716326, 0.09575149707477067, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 34.53845943716326\n",
      "Tolerance: 0.09575149707477067\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.9044708604876245\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [26.06800258114061, 0.04910936561577195, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 26.06800258114061\n",
      "Tolerance: 0.04910936561577195\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 7 epochs took 1 seconds\n",
      "Results: -0.8866187724975848\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [80.03906608953766, 0.013670346758652389, 'sag', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 80.03906608953766\n",
      "Tolerance: 0.013670346758652389\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 13 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 12 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 0 seconds\n",
      "Results: -0.9045664862403262\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 93.42595525094245\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405395451299152 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705718529819313 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017678965476787504 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.6639346784326365e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.321225221181929e-07 <= 1e-05\n",
      "    2. Newton decrement 1.8209998451136638e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38779508791901424.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467174023212759 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049394567090934 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018124303039465898 <= 1e-05\n",
      "Newton iter=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 4.567845022730972e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.961726590753725e-08 <= 1e-05\n",
      "    2. Newton decrement 2.241479900235266e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3871900913559473.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416609052239926 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153782060046909 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017041801977775394 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.5444923002742244e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.1666154023328408e-07 <= 1e-05\n",
      "    2. Newton decrement 3.4322491571461376e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3909140692748006.\n",
      "Results: -0.9046185289356158\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [95.68017653731005, 0.058807524193284035, 'sag', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 95.68017653731005\n",
      "Tolerance: 0.058807524193284035\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 7 epochs took 0 seconds\n",
      "convergence after 8 epochs took 1 seconds\n",
      "convergence after 7 epochs took 0 seconds\n",
      "Results: -0.9047075404148085\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [16.007640651889556, 0.09735254210951415, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 16.007640651889556\n",
      "Tolerance: 0.09735254210951415\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.037717591486216874 <= 0.09735254210951415\n",
      "    2. Newton decrement 0.20078991134490487 <= 0.09735254210951415\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009966812025285094 <= 0.09735254210951415\n",
      "    2. Newton decrement 0.03088896136873532 <= 0.09735254210951415\n",
      "  Solver did converge at loss = 0.4254420118290142.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.041285882157048044 <= 0.09735254210951415\n",
      "    2. Newton decrement 0.20553981800438553 <= 0.09735254210951415\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010478444098081645 <= 0.09735254210951415\n",
      "    2. Newton decrement 0.02959366508418644 <= 0.09735254210951415\n",
      "  Solver did converge at loss = 0.42272453483159267.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203214332064728 <= 0.09735254210951415\n",
      "    2. Newton decrement 0.20479223772314986 <= 0.09735254210951415\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010438358862638848 <= 0.09735254210951415\n",
      "    2. Newton decrement 0.02997113042038368 <= 0.09735254210951415\n",
      "  Solver did converge at loss = 0.42290551345771354.\n",
      "Results: -0.8849689629685473\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [6.346895009485101, 0.06623339812508623, 'newton-cg', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 6.346895009485101\n",
      "Tolerance: 0.06623339812508623\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.876698390670057\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [67.66291756213789, 0.07586339273353838, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 67.66291756213789\n",
      "Tolerance: 0.07586339273353838\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.8839762208578916\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [16.8363151695804, 0.024659615371572175, 'lbfgs', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 16.8363151695804\n",
      "Tolerance: 0.024659615371572175\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Results: -0.801726626226318\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [35.85822365238481, 0.024892386655374216, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 35.85822365238481\n",
      "Tolerance: 0.024892386655374216\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.904588921098289\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [83.2492745989974, 0.014725169594065949, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 83.2492745989974\n",
      "Tolerance: 0.014725169594065949\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 13 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 17 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 0 seconds\n",
      "Results: -0.8868897294963659\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [18.669732879292546, 0.028576956125055588, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 18.669732879292546\n",
      "Tolerance: 0.028576956125055588\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 9 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 10 epochs took 0 seconds\n",
      "Results: -0.8859510698983541\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [91.13956515162165, 0.08150516733240702, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 91.13956515162165\n",
      "Tolerance: 0.08150516733240702\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.9040220056784873\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [76.9795591768437, 0.02354599938240123, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 76.9795591768437\n",
      "Tolerance: 0.02354599938240123\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772347489188458 <= 0.02354599938240123\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009978606842398213 <= 0.02354599938240123\n",
      "    2. Newton decrement 0.030947131784639672 <= 0.02354599938240123\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0022108581894551282 <= 0.02354599938240123\n",
      "    2. Newton decrement 0.007673860660250255 <= 0.02354599938240123\n",
      "  Solver did converge at loss = 0.4159419144609937.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.041292539387172034 <= 0.02354599938240123\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010489716782624104 <= 0.02354599938240123\n",
      "    2. Newton decrement 0.029642609592008477 <= 0.02354599938240123\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017239546330535798 <= 0.02354599938240123\n",
      "    2. Newton decrement 0.0065275244247432074 <= 0.02354599938240123\n",
      "  Solver did converge at loss = 0.41476023014639446.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203862115732968 <= 0.02354599938240123\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010448750669277175 <= 0.02354599938240123\n",
      "    2. Newton decrement 0.030015291288226026 <= 0.02354599938240123\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017284750359496913 <= 0.02354599938240123\n",
      "    2. Newton decrement 0.006710541387429241 <= 0.02354599938240123\n",
      "  Solver did converge at loss = 0.4147328434520124.\n",
      "Results: -0.8863212328293631\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [20.76033040616742, 0.038057677292685686, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 20.76033040616742\n",
      "Tolerance: 0.038057677292685686\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.885432775102517\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [2.546721588392942, 0.047960209758713984, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 2.546721588392942\n",
      "Tolerance: 0.047960209758713984\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.9044551471998287\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [85.6762024943388, 0.0679631549432138, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 85.6762024943388\n",
      "Tolerance: 0.0679631549432138\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405392451314901 <= 0.0679631549432138\n",
      "    2. Newton decrement 0.2363460434931678 <= 0.0679631549432138\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705692266785265 <= 0.0679631549432138\n",
      "    2. Newton decrement 0.02850698782713884 <= 0.0679631549432138\n",
      "  Solver did converge at loss = 0.39173089954098406.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467171080248404 <= 0.0679631549432138\n",
      "    2. Newton decrement 0.2358599811537352 <= 0.0679631549432138\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504936912582101 <= 0.0679631549432138\n",
      "    2. Newton decrement 0.029019932428583684 <= 0.0679631549432138\n",
      "  Solver did converge at loss = 0.3913752243938352.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416578942306296 <= 0.0679631549432138\n",
      "    2. Newton decrement 0.2339431915089187 <= 0.0679631549432138\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153757320214051 <= 0.0679631549432138\n",
      "    2. Newton decrement 0.02815857314591456 <= 0.0679631549432138\n",
      "  Solver did converge at loss = 0.39490121669916045.\n",
      "Results: -0.9043098588026522\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [11.401320728995659, 0.07661229471776576, 'lbfgs', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 11.401320728995659\n",
      "Tolerance: 0.07661229471776576\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Results: -0.7910640337424818\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [81.38644167126354, 0.08095068457826898, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 81.38644167126354\n",
      "Tolerance: 0.08095068457826898\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405390545098114 <= 0.08095068457826898\n",
      "    2. Newton decrement 0.23634600321003627 <= 0.08095068457826898\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705675579538498 <= 0.08095068457826898\n",
      "    2. Newton decrement 0.028506940478795133 <= 0.08095068457826898\n",
      "  Solver did converge at loss = 0.39173102528906323.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467169210266997 <= 0.08095068457826898\n",
      "    2. Newton decrement 0.23585994352645537 <= 0.08095068457826898\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049352960669888 <= 0.08095068457826898\n",
      "    2. Newton decrement 0.029019883577257672 <= 0.08095068457826898\n",
      "  Solver did converge at loss = 0.39137534966652004.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241655981035955 <= 0.08095068457826898\n",
      "    2. Newton decrement 0.2339431505049882 <= 0.08095068457826898\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153741600869832 <= 0.08095068457826898\n",
      "    2. Newton decrement 0.028158520738388905 <= 0.08095068457826898\n",
      "  Solver did converge at loss = 0.3949013521783936.\n",
      "Results: -0.9043098730934681\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [33.17130324652451, 0.006897640849051079, 'sag', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 33.17130324652451\n",
      "Tolerance: 0.006897640849051079\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 16 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 22 epochs took 0 seconds\n",
      "Results: -0.9046228149390453\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [46.91882592781495, 0.04949135622309575, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 46.91882592781495\n",
      "Tolerance: 0.04949135622309575\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772249707344088 <= 0.04949135622309575\n",
      "    2. Newton decrement 0.20081649736986898 <= 0.04949135622309575\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009976751013005117 <= 0.04949135622309575\n",
      "    2. Newton decrement 0.03093712452651197 <= 0.04949135622309575\n",
      "  Solver did converge at loss = 0.42532865827639993.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129141745933676 <= 0.04949135622309575\n",
      "    2. Newton decrement 0.20555944970922088 <= 0.04949135622309575\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010487815613547098 <= 0.04949135622309575\n",
      "    2. Newton decrement 0.029634336186362277 <= 0.04949135622309575\n",
      "  Solver did converge at loss = 0.42263192846402936.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203752991448117 <= 0.04949135622309575\n",
      "    2. Newton decrement 0.20481110669322627 <= 0.04949135622309575\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010446996865222944 <= 0.04949135622309575\n",
      "    2. Newton decrement 0.030007833187935585 <= 0.04949135622309575\n",
      "  Solver did converge at loss = 0.42282050113730163.\n",
      "Results: -0.8849079865669776\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [79.11587543970384, 0.049248266821023304, 'newton-cg', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 79.11587543970384\n",
      "Tolerance: 0.049248266821023304\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8887434299250153\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [20.327304036683923, 0.09499639297742074, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 20.327304036683923\n",
      "Tolerance: 0.09499639297742074\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.884993819916131\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [94.47866417727602, 0.05428895380549954, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 94.47866417727602\n",
      "Tolerance: 0.05428895380549954\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.885016491554086\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [68.97628244149043, 0.021666364382644722, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 68.97628244149043\n",
      "Tolerance: 0.021666364382644722\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772329818625882 <= 0.021666364382644722\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009978275296769498 <= 0.021666364382644722\n",
      "    2. Newton decrement 0.030945311785869414 <= 0.021666364382644722\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.002210007388957151 <= 0.021666364382644722\n",
      "    2. Newton decrement 0.007671662391784668 <= 0.021666364382644722\n",
      "  Solver did converge at loss = 0.41594929728573726.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129233614347345 <= 0.021666364382644722\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010489372334208321 <= 0.021666364382644722\n",
      "    2. Newton decrement 0.029641110060280917 <= 0.021666364382644722\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017231048492680236 <= 0.021666364382644722\n",
      "    2. Newton decrement 0.006525621862982865 <= 0.021666364382644722\n",
      "  Solver did converge at loss = 0.4147663586007968.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203842348603692 <= 0.021666364382644722\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010448432881822659 <= 0.021666364382644722\n",
      "    2. Newton decrement 0.030013939731120088 <= 0.021666364382644722\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017276698578623535 <= 0.021666364382644722\n",
      "    2. Newton decrement 0.006708791693139541 <= 0.021666364382644722\n",
      "  Solver did converge at loss = 0.4147384784344793.\n",
      "Results: -0.8863277360090424\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [10.806976024266898, 0.062181726618901256, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 10.806976024266898\n",
      "Tolerance: 0.062181726618901256\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.9044995908698272\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cg', 'none'] before, using random point [94.3147647630586, 0.04212736098136392, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 94.3147647630586\n",
      "Tolerance: 0.04212736098136392\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 8 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 1 seconds\n",
      "Results: -0.8867112134958702\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [57.81476953830057, 0.059929600122849334, 'newton-cg', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.81476953830057\n",
      "Tolerance: 0.059929600122849334\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.795092463833087\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [55.414956245183646, 0.04644953404757215, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 55.414956245183646\n",
      "Tolerance: 0.04644953404757215\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8846698165672388\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [54.72348655820515, 0.07642641007470372, 'lbfgs', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 54.72348655820515\n",
      "Tolerance: 0.07642641007470372\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8722073888526234\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [38.13922140757804, 0.0712599131582851, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 38.13922140757804\n",
      "Tolerance: 0.0712599131582851\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772191831318513 <= 0.0712599131582851\n",
      "    2. Newton decrement 0.2008133122386817 <= 0.0712599131582851\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009975629383543887 <= 0.0712599131582851\n",
      "    2. Newton decrement 0.030931272166829206 <= 0.0712599131582851\n",
      "  Solver did converge at loss = 0.42534238779268263.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.041290756493438385 <= 0.0712599131582851\n",
      "    2. Newton decrement 0.20555710670754734 <= 0.0712599131582851\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010486695829456223 <= 0.0712599131582851\n",
      "    2. Newton decrement 0.02962946680391877 <= 0.0712599131582851\n",
      "  Solver did converge at loss = 0.42264301128061094.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203688694011724 <= 0.0712599131582851\n",
      "    2. Newton decrement 0.2048088551197205 <= 0.0712599131582851\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010445964116457391 <= 0.0712599131582851\n",
      "    2. Newton decrement 0.03000344238364313 <= 0.0712599131582851\n",
      "  Solver did converge at loss = 0.42283066761479277.\n",
      "Results: -0.8849160809250284\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [2.2381756843556238, 0.0726502960664661, 'sag', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 2.2381756843556238\n",
      "Tolerance: 0.0726502960664661\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 6 epochs took 0 seconds\n",
      "convergence after 6 epochs took 0 seconds\n",
      "convergence after 8 epochs took 0 seconds\n",
      "Results: -0.903518125623621\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [61.26470621280732, 0.0441553815696338, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 61.26470621280732\n",
      "Tolerance: 0.0441553815696338\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772308402286816 <= 0.0441553815696338\n",
      "    2. Newton decrement 0.20081974186091828 <= 0.0441553815696338\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009977871159550719 <= 0.0441553815696338\n",
      "    2. Newton decrement 0.03094311292235822 <= 0.0441553815696338\n",
      "  Solver did converge at loss = 0.42531462195372477.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129209011198798 <= 0.0441553815696338\n",
      "    2. Newton decrement 0.20556183380208548 <= 0.0441553815696338\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010488955394917813 <= 0.0441553815696338\n",
      "    2. Newton decrement 0.02963929528870845 <= 0.0441553815696338\n",
      "  Solver did converge at loss = 0.4226206427012175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.042038184192005695 <= 0.0441553815696338\n",
      "    2. Newton decrement 0.20481339764355158 <= 0.0441553815696338\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010448048237186541 <= 0.0441553815696338\n",
      "    2. Newton decrement 0.03001230392208713 <= 0.0441553815696338\n",
      "  Solver did converge at loss = 0.42281015060574856.\n",
      "Results: -0.8848995378313997\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [0.021750054621104208, 0.014660217027069293, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.021750054621104208\n",
      "Tolerance: 0.014660217027069293\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 6 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n",
      "Results: -0.8760995875372256\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [58.123688896587666, 0.0339174237000457, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 58.123688896587666\n",
      "Tolerance: 0.0339174237000457\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 6 epochs took 1 seconds\n",
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.9046142328497276\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [38.186899601126775, 0.030881534699302573, 'lbfgs', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 38.186899601126775\n",
      "Tolerance: 0.030881534699302573\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Results: -0.8017266203591374\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [53.916092915450925, 0.05321157708946323, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 53.916092915450925\n",
      "Tolerance: 0.05321157708946323\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 1 seconds\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.885070185634223\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [31.350129925781697, 0.0827326736844162, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 31.350129925781697\n",
      "Tolerance: 0.0827326736844162\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.886282924474454\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [8.64529551299818, 0.061298053463018656, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 8.64529551299818\n",
      "Tolerance: 0.061298053463018656\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.037711098473563 <= 0.061298053463018656\n",
      "    2. Newton decrement 0.20075596729572964 <= 0.061298053463018656\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009952763677274554 <= 0.061298053463018656\n",
      "    2. Newton decrement 0.030829173922230585 <= 0.061298053463018656\n",
      "  Solver did converge at loss = 0.4255838143427253.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.041278757911502054 <= 0.061298053463018656\n",
      "    2. Newton decrement 0.20551451736873372 <= 0.061298053463018656\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010466404560792578 <= 0.061298053463018656\n",
      "    2. Newton decrement 0.0295416726864255 <= 0.061298053463018656\n",
      "  Solver did converge at loss = 0.4228430483655712.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04202520395240761 <= 0.061298053463018656\n",
      "    2. Newton decrement 0.2047679089869315 <= 0.061298053463018656\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010427276847018677 <= 0.061298053463018656\n",
      "    2. Newton decrement 0.02992411579695768 <= 0.061298053463018656\n",
      "  Solver did converge at loss = 0.4230145137404577.\n",
      "Results: -0.8850266126791969\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [86.80114337812941, 0.08020979310167213, 'newton-cg', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 86.80114337812941\n",
      "Tolerance: 0.08020979310167213\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8766984406718609\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [18.625433139696227, 0.029781048582539292, 'sag', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 18.625433139696227\n",
      "Tolerance: 0.029781048582539292\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 9 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 10 epochs took 1 seconds\n",
      "Results: -0.9044744013564815\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [97.09947950054627, 0.0071946494795169305, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 97.09947950054627\n",
      "Tolerance: 0.0071946494795169305\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 50 epochs took 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 30 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 22 epochs took 1 seconds\n",
      "Results: -0.8869686137699855\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [81.4275007862718, 0.035058763169565854, 'sag', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 81.4275007862718\n",
      "Tolerance: 0.035058763169565854\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 7 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 0 seconds\n",
      "Results: -0.9044846159253983\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [0.6828439201394634, 0.07930782390648895, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.6828439201394634\n",
      "Tolerance: 0.07930782390648895\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.8850289137804673\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [20.573172137371465, 0.09052122837847784, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 20.573172137371465\n",
      "Tolerance: 0.09052122837847784\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8743439400881553\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [43.458512815598105, 0.05431281148221071, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 43.458512815598105\n",
      "Tolerance: 0.05431281148221071\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n",
      "Results: -0.8851127133468925\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [57.51781461616202, 0.010293476875753639, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.51781461616202\n",
      "Tolerance: 0.010293476875753639\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045888782365425\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [91.48227602247906, 0.021660744002883755, 'lbfgs', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 91.48227602247906\n",
      "Tolerance: 0.021660744002883755\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8894381197302653\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [39.90427489969206, 0.06754485999173959, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 39.90427489969206\n",
      "Tolerance: 0.06754485999173959\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772205527501285 <= 0.06754485999173959\n",
      "    2. Newton decrement 0.20081406474444422 <= 0.06754485999173959\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00997589628941329 <= 0.06754485999173959\n",
      "    2. Newton decrement 0.030932652528648928 <= 0.06754485999173959\n",
      "  Solver did converge at loss = 0.425339148406879.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129091270556347 <= 0.06754485999173959\n",
      "    2. Newton decrement 0.20555766048012858 <= 0.06754485999173959\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010486960460750329 <= 0.06754485999173959\n",
      "    2. Newton decrement 0.029630617311859894 <= 0.06754485999173959\n",
      "  Solver did converge at loss = 0.42264039258967306.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203703890588985 <= 0.06754485999173959\n",
      "    2. Newton decrement 0.20480938729283907 <= 0.06754485999173959\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010446208163593429 <= 0.06754485999173959\n",
      "    2. Newton decrement 0.03000447990134511 <= 0.06754485999173959\n",
      "  Solver did converge at loss = 0.4228282652547854.\n",
      "Results: -0.8849141987344945\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [7.539837931486306, 0.008030468046339364, 'newton-cg', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 7.539837931486306\n",
      "Tolerance: 0.008030468046339364\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8807241109232317\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [19.667804293165037, 0.04738890333555427, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 19.667804293165037\n",
      "Tolerance: 0.04738890333555427\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405271125121385 <= 0.04738890333555427\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014704630964093125 <= 0.04738890333555427\n",
      "    2. Newton decrement 0.02850397518326974 <= 0.04738890333555427\n",
      "  Solver did converge at loss = 0.3917389016209698.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467052067175401 <= 0.04738890333555427\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015048340959279814 <= 0.04738890333555427\n",
      "    2. Newton decrement 0.02901682464470328 <= 0.04738890333555427\n",
      "  Solver did converge at loss = 0.3913831951801503.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241536150815737 <= 0.04738890333555427\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014152757695082436 <= 0.04738890333555427\n",
      "    2. Newton decrement 0.02815524074145248 <= 0.04738890333555427\n",
      "  Solver did converge at loss = 0.3949098334780622.\n",
      "Results: -0.9043104945673898\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [6.001103265730829, 0.09947015378752881, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 6.001103265730829\n",
      "Tolerance: 0.09947015378752881\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8742924027629672\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [36.22167222204342, 0.014799288532886487, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 36.22167222204342\n",
      "Tolerance: 0.014799288532886487\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890925345739\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'saga', 'none'] before, using random point [31.772668758773754, 0.015254043473815803, 'lbfgs', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 31.772668758773754\n",
      "Tolerance: 0.015254043473815803\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8971829968084412\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [38.681669320781886, 0.06330809307497258, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 38.681669320781886\n",
      "Tolerance: 0.06330809307497258\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8829083998784402\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [58.74628199779373, 0.040170327735786, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 58.74628199779373\n",
      "Tolerance: 0.040170327735786\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405375873632094 <= 0.040170327735786\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705547157298049 <= 0.040170327735786\n",
      "    2. Newton decrement 0.028506576071862574 <= 0.040170327735786\n",
      "  Solver did converge at loss = 0.39173199310179424.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467154817806482 <= 0.040170327735786\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049228555233728 <= 0.040170327735786\n",
      "    2. Newton decrement 0.02901950761119777 <= 0.040170327735786\n",
      "  Solver did converge at loss = 0.39137631380284693.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416412563162556 <= 0.040170327735786\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415362062944558 <= 0.040170327735786\n",
      "    2. Newton decrement 0.028158117430629695 <= 0.040170327735786\n",
      "  Solver did converge at loss = 0.39490239480952266.\n",
      "Results: -0.9043098159537469\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [2.401699773028909, 0.09092073694861813, 'newton-cg', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 2.401699773028909\n",
      "Tolerance: 0.09092073694861813\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Results: -0.7950924485784246\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [84.9456091356988, 0.01921089906237294, 'lbfgs', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 84.9456091356988\n",
      "Tolerance: 0.01921089906237294\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Results: -0.806331848342437\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [66.09157215809276, 0.05705707268048532, 'lbfgs', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 66.09157215809276\n",
      "Tolerance: 0.05705707268048532\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8722073888526234\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [73.35235250956885, 0.07983390868218461, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 73.35235250956885\n",
      "Tolerance: 0.07983390868218461\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.9043106414121005\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [6.634255065524382, 0.05132485379136867, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 6.634255065524382\n",
      "Tolerance: 0.05132485379136867\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n",
      "Results: -0.8850878118603118\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [67.62377653978415, 0.08306057343905619, 'saga', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 67.62377653978415\n",
      "Tolerance: 0.08306057343905619\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.8838962827389302\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [8.400905957921763, 0.030950432092381477, 'lbfgs', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 8.400905957921763\n",
      "Tolerance: 0.030950432092381477\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8017266121450907\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [15.060821530526033, 0.07770555147285352, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 15.060821530526033\n",
      "Tolerance: 0.07770555147285352\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 1 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.9033882341782525\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [67.50214515495325, 0.026905274940328787, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 67.50214515495325\n",
      "Tolerance: 0.026905274940328787\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 5 epochs took 1 seconds\n",
      "convergence after 6 epochs took 0 seconds\n",
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.9045774778980271\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [57.72476994253443, 0.012080586271589885, 'lbfgs', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.72476994253443\n",
      "Tolerance: 0.012080586271589885\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8360968319636792\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [17.865556566915853, 0.012908830561949115, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 17.865556566915853\n",
      "Tolerance: 0.012908830561949115\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 10 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 0 seconds\n",
      "Results: -0.9046101969855024\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [85.62439928230734, 0.030886188287178293, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 85.62439928230734\n",
      "Tolerance: 0.030886188287178293\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8848952970745408\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [80.64599785161194, 0.0893193580185191, 'newton-cholesky', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 80.64599785161194\n",
      "Tolerance: 0.0893193580185191\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772354408393356 <= 0.0893193580185191\n",
      "    2. Newton decrement 0.2008222952445235 <= 0.0893193580185191\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009978736187440848 <= 0.0893193580185191\n",
      "    2. Newton decrement 0.030947845863112326 <= 0.0893193580185191\n",
      "  Solver did converge at loss = 0.4253035369588103.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129261903110614 <= 0.0893193580185191\n",
      "    2. Newton decrement 0.20556370821966624 <= 0.0893193580185191\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010489851764503594 <= 0.0893193580185191\n",
      "    2. Newton decrement 0.029643197296317526 <= 0.0893193580185191\n",
      "  Solver did converge at loss = 0.42261176352888175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203869861598974 <= 0.0893193580185191\n",
      "    2. Newton decrement 0.2048151987521226 <= 0.0893193580185191\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010448875207964569 <= 0.0893193580185191\n",
      "    2. Newton decrement 0.03001582097304182 <= 0.0893193580185191\n",
      "  Solver did converge at loss = 0.4228020087360142.\n",
      "Results: -0.8848927635883005\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [29.868659308710285, 0.061258013969369474, 'saga', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 29.868659308710285\n",
      "Tolerance: 0.061258013969369474\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.9045078840045687\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [45.67201614221773, 0.07868482490781922, 'newton-cg', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 45.67201614221773\n",
      "Tolerance: 0.07868482490781922\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.795092463833087\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [17.752860547685756, 0.08528365712224212, 'sag', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 17.752860547685756\n",
      "Tolerance: 0.08528365712224212\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.8859190573171697\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [69.58135285781484, 0.022144700453966815, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.58135285781484\n",
      "Tolerance: 0.022144700453966815\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384086129255 <= 0.022144700453966815\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619039963853 <= 0.022144700453966815\n",
      "    2. Newton decrement 0.028506780048674723 <= 0.022144700453966815\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017678061804710684 <= 0.022144700453966815\n",
      "    2. Newton decrement 0.0035055944072832725 <= 0.022144700453966815\n",
      "  Solver did converge at loss = 0.3878946876517097.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162874102525 <= 0.022144700453966815\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298189797892 <= 0.022144700453966815\n",
      "    2. Newton decrement 0.02901971805642903 <= 0.022144700453966815\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018123535451343173 <= 0.022144700453966815\n",
      "    2. Newton decrement 0.003706186226553455 <= 0.022144700453966815\n",
      "  Solver did converge at loss = 0.3873059519853814.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649498523997 <= 0.022144700453966815\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688341177929 <= 0.022144700453966815\n",
      "    2. Newton decrement 0.028158343174303855 <= 0.022144700453966815\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017040432134782892 <= 0.022144700453966815\n",
      "    2. Newton decrement 0.0035278756990322225 <= 0.022144700453966815\n",
      "  Solver did converge at loss = 0.39102783672395025.\n",
      "Results: -0.904582096770388\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [70.36364878633712, 0.03734334197817553, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 70.36364878633712\n",
      "Tolerance: 0.03734334197817553\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8852235314730482\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [87.88852569478873, 0.007356286997800973, 'liblinear', 'none']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 87.88852569478873\n",
      "Tolerance: 0.007356286997800973\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046321228640629\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [48.667105259554845, 0.02699741065788103, 'newton-cg', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 48.667105259554845\n",
      "Tolerance: 0.02699741065788103\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8887434084877216\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [49.301843287899246, 0.09876473882390516, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 49.301843287899246\n",
      "Tolerance: 0.09876473882390516\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8743577385264464\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [88.34995337941079, 0.07132782027043498, 'lbfgs', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 88.34995337941079\n",
      "Tolerance: 0.07132782027043498\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Results: -0.7910640337424818\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'newton-cholesky', 'none'] before, using random point [36.829973441322785, 0.04799868237376555, 'lbfgs', 'ada']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 36.829973441322785\n",
      "Tolerance: 0.04799868237376555\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8017266203591374\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.1\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 7 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 6 epochs took 0 seconds\n",
      "Results: -0.9031164868483234\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 8.516025378081993\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405065142459143 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470283280763508 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017653195317936271 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.585087725450022e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 9.540657964601319e-08 <= 1e-05\n",
      "    2. Newton decrement 1.6086707970446801e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38782401816747697.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06466850043156158 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015046598622618887 <= 1e-05\n",
      "Newton iter=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.001810236817506581 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.535930514975354e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.708559811786223e-08 <= 1e-05\n",
      "    2. Newton decrement 2.1676753313872457e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38721936894870534.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241329584213812 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014151064594939816 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001700340712523303 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.4007091028656496e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.1895138815929227e-07 <= 1e-05\n",
      "    2. Newton decrement 2.8558926875426976e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3909471115895542.\n",
      "Results: -0.9046209144981043\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 31.852727193858193\n",
      "Tolerance: 0.0073529230093569\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405331353297102 <= 0.0073529230093569\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705157607973335 <= 0.0073529230093569\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017673885198429772 <= 0.0073529230093569\n",
      "    2. Newton decrement 0.00350478259604795 <= 0.0073529230093569\n",
      "  Solver did converge at loss = 0.38789916342816716.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467111145351816 <= 0.0073529230093569\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015048851177742559 <= 0.0073529230093569\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018119986318566152 <= 0.0073529230093569\n",
      "    2. Newton decrement 0.003705303490883104 <= 0.0073529230093569\n",
      "  Solver did converge at loss = 0.38731049717144606.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241596579281332 <= 0.0073529230093569\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153253702738003 <= 0.0073529230093569\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017034123564516309 <= 0.0073529230093569\n",
      "    2. Newton decrement 0.003526846055557075 <= 0.0073529230093569\n",
      "  Solver did converge at loss = 0.39103287658490626.\n",
      "Results: -0.9045820752710286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 94.51917200890252\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185217891377\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 29.054062052091\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405321987311821 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705075684239236 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017673146165975199 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.6450803266469336e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.2227016972988932e-07 <= 1e-05\n",
      "    2. Newton decrement 1.766022442435705e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3878015413451051.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467101957977342 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015048771811388952 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018119358060066254 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.5603197639732024e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.904663815564314e-08 <= 1e-05\n",
      "    2. Newton decrement 2.224180494407334e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3871966170217729.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241587181266957 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153176540787054 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017033011137337342 <= 1e-05\n",
      "Newton iter=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 4.508757692032221e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.879872926756533e-07 <= 1e-05\n",
      "    2. Newton decrement 3.269514619012126e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.39092147853188247.\n",
      "Results: -0.9046191003285462\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 63.36780221227319\n",
      "Tolerance: 0.005283816159339996\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405379719957036 <= 0.005283816159339996\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705580822629504 <= 0.005283816159339996\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001767771497303814 <= 0.005283816159339996\n",
      "    2. Newton decrement 0.0035055271283218874 <= 0.005283816159339996\n",
      "  Solver did converge at loss = 0.3878950583572683.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467158590966678 <= 0.005283816159339996\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049261167775165 <= 0.005283816159339996\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018123240818848055 <= 0.005283816159339996\n",
      "    2. Newton decrement 0.0037061130770980584 <= 0.005283816159339996\n",
      "  Solver did converge at loss = 0.3873063284411451.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241645116524918 <= 0.005283816159339996\n",
      "Newton iter=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153652341235227 <= 0.005283816159339996\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017039906848957881 <= 0.005283816159339996\n",
      "    2. Newton decrement 0.0035277902681675566 <= 0.005283816159339996\n",
      "  Solver did converge at loss = 0.3910282543867558.\n",
      "Results: -0.9045821110440823\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 79.33141724422386\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405389558893942 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470566694634926 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017678496800817693 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.6623920415332334e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.3128936133969845e-07 <= 1e-05\n",
      "    2. Newton decrement 1.816396555791977e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.387795605960318.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467168242810976 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049344597574578 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018123904955583048 <= 1e-05\n",
      "Newton iter=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 4.567231617057402e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.957134904840834e-08 <= 1e-05\n",
      "    2. Newton decrement 2.2400712640064302e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38719061507236785.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241654991227006 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153733468450847 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00170410913112451 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.541536471251552e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.1416902962160796e-07 <= 1e-05\n",
      "    2. Newton decrement 3.418254416970696e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3909146649496753.\n",
      "Results: -0.9046185575022658\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 49.85705424594057\n",
      "Tolerance: 0.0037363201631430776\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405366471048654 <= 0.0037363201631430776\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705464867182891 <= 0.0037363201631430776\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017676663659974042 <= 0.0037363201631430776\n",
      "    2. Newton decrement 0.003505323043421569 <= 0.0037363201631430776\n",
      "  Solver did converge at loss = 0.3878961831094937.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467145594137642 <= 0.0037363201631430776\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049148837921602 <= 0.0037363201631430776\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001812234762895094 <= 0.0037363201631430776\n",
      "    2. Newton decrement 0.003705891176382781 <= 0.0037363201631430776\n",
      "  Solver did converge at loss = 0.387307470638538.\n",
      "Newton iter=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241631820024805 <= 0.0037363201631430776\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153543115511426 <= 0.0037363201631430776\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017038316174560631 <= 0.0037363201631430776\n",
      "    2. Newton decrement 0.003527531231017059 <= 0.0037363201631430776\n",
      "  Solver did converge at loss = 0.39102952134799285.\n",
      "Results: -0.9045819681402046\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 63.53158979088351\n",
      "Tolerance: 0.0033225843124756564\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405379846005858 <= 0.0033225843124756564\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0147055819259116 <= 0.0033225843124756564\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017677724983274658 <= 0.0033225843124756564\n",
      "    2. Newton decrement 0.003505529070466546 <= 0.0033225843124756564\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.6598609455703234e-05 <= 0.0033225843124756564\n",
      "    2. Newton decrement 9.610758342142489e-05 <= 0.0033225843124756564\n",
      "  Solver did converge at loss = 0.3877966415333429.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467158714618021 <= 0.0033225843124756564\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049262236552846 <= 0.0033225843124756564\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018123249322750065 <= 0.0033225843124756564\n",
      "    2. Newton decrement 0.003706115188725315 <= 0.0033225843124756564\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.566224291848115e-05 <= 0.0033225843124756564\n",
      "    2. Newton decrement 0.00011168233317989798 <= 0.0033225843124756564\n",
      "  Solver did converge at loss = 0.3871917025013851.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241645243029646 <= 0.0033225843124756564\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153653380499833 <= 0.0033225843124756564\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017039922006129766 <= 0.0033225843124756564\n",
      "    2. Newton decrement 0.0035277927340516004 <= 0.0033225843124756564\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.536699059801413e-05 <= 0.0033225843124756564\n",
      "    2. Newton decrement 0.000109014953077842 <= 0.0033225843124756564\n",
      "  Solver did converge at loss = 0.39091598865047383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046186069882829\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 24.1912785079283\n",
      "Tolerance: 0.00250694630027294\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405300561913983 <= 0.00250694630027294\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014704888313849388 <= 0.00250694630027294\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017671458700678694 <= 0.00250694630027294\n",
      "    2. Newton decrement 0.0035043093272430254 <= 0.00250694630027294\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.6397328161335586e-05 <= 0.00250694630027294\n",
      "    2. Newton decrement 9.589990181465655e-05 <= 0.00250694630027294\n",
      "  Solver did converge at loss = 0.3878035972210855.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467080941475185 <= 0.00250694630027294\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015048590286919829 <= 0.00250694630027294\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018117923241227846 <= 0.00250694630027294\n",
      "    2. Newton decrement 0.0037047887856247394 <= 0.00250694630027294\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.5581740068894245e-05 <= 0.00250694630027294\n",
      "    2. Newton decrement 0.00011148851389805057 <= 0.00250694630027294\n",
      "  Solver did converge at loss = 0.3871987410576892.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062415656838227744 <= 0.00250694630027294\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415300006666431 <= 0.00250694630027294\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017030475392805738 <= 0.00250694630027294\n",
      "    2. Newton decrement 0.0035262469854801036 <= 0.00250694630027294\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.4987778109268676e-05 <= 0.00250694630027294\n",
      "    2. Newton decrement 0.0001086632581174224 <= 0.00250694630027294\n",
      "  Solver did converge at loss = 0.39092395740120817.\n",
      "Results: -0.9046189568789188\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 43.15310286653867\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046186932018804\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 7.104292941233418\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046212645492547\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 88.10663077423017\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185075090226\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [23.7072917423797, 0.015082406834393155, 'newton-cholesky', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 23.7072917423797\n",
      "Tolerance: 0.015082406834393155\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405297948753019 <= 0.015082406834393155\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014704865464566853 <= 0.015082406834393155\n",
      "    2. Newton decrement 0.02850464107068464 <= 0.015082406834393155\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001767125318465028 <= 0.015082406834393155\n",
      "    2. Newton decrement 0.003504269188088392 <= 0.015082406834393155\n",
      "  Solver did converge at loss = 0.38790199705958717.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467078378214912 <= 0.015082406834393155\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015048568150230812 <= 0.015082406834393155\n",
      "    2. Newton decrement 0.029017511475474416 <= 0.015082406834393155\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018117748467483654 <= 0.015082406834393155\n",
      "    2. Newton decrement 0.003704745129142208 <= 0.015082406834393155\n",
      "  Solver did converge at loss = 0.3873133747259917.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062415630619909714 <= 0.015082406834393155\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014152978546668573 <= 0.015082406834393155\n",
      "    2. Newton decrement 0.02815597693294655 <= 0.015082406834393155\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017030166973459864 <= 0.015082406834393155\n",
      "    2. Newton decrement 0.0035261962166860737 <= 0.015082406834393155\n",
      "  Solver did converge at loss = 0.39103606415085945.\n",
      "Results: -0.9045819609594834\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 75.64862859551519\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405387657494849 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705650301887646 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017678345637450537 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.661895404544547e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.3102217401871076e-07 <= 1e-05\n",
      "    2. Newton decrement 1.8149186063682114e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38779577310923014.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467166377560868 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049328473817628 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018123776553960593 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.567034051380883e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.955653769592115e-08 <= 1e-05\n",
      "    2. Newton decrement 2.2396175215562108e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3871907840571059.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241653082888115 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415371778950052 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017040862198207233 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.540586088143519e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.1337233573515317e-07 <= 1e-05\n",
      "    2. Newton decrement 3.4137755629875056e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.39091485711301227.\n",
      "Results: -0.9046185503579282\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 90.40359365724449\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185289420362\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 87.13948717834617\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.904618578933139\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 88.66367654294417\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185289420362\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 72.37752108389111\n",
      "Tolerance: 0.0006503161445567172\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405385806406441 <= 0.0006503161445567172\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705634098221615 <= 0.0006503161445567172\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017678198507554818 <= 0.0006503161445567172\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.6614124465390364e-05 <= 0.0006503161445567172\n",
      "    2. Newton decrement 9.612337550565421e-05 <= 0.0006503161445567172\n",
      "  Solver did converge at loss = 0.38779611810757686.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467164561668252 <= 0.0006503161445567172\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504931277703361 <= 0.0006503161445567172\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018123651575406216 <= 0.0006503161445567172\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.566841887172637e-05 <= 0.0006503161445567172\n",
      "    2. Newton decrement 0.00011169698238738959 <= 0.0006503161445567172\n",
      "  Solver did converge at loss = 0.38719117297306277.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241651225056498 <= 0.0006503161445567172\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415370252583325 <= 0.0006503161445567172\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017040639245470303 <= 0.0006503161445567172\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.5396624502539285e-05 <= 0.0006503161445567172\n",
      "    2. Newton decrement 0.00010904196569162806 <= 0.0006503161445567172\n",
      "  Solver did converge at loss = 0.3909153879441044.\n",
      "Results: -0.9046185641436578\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 90.31400158654583\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185217976984\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 55.49407111533196\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046186717817081\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 78.00565905273575\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185289356156\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 61.116729018703595\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640537791912131 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705565060436116 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017677571975449698 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.6593605455482034e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.2966630295502825e-07 <= 1e-05\n",
      "    2. Newton decrement 1.8074055960636614e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3877966290720148.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467156824384683 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049245898518256 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018123119337931527 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.566025013488482e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.948072006230879e-08 <= 1e-05\n",
      "    2. Newton decrement 2.2372997111446563e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3871916494569383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241643309182027 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153637493664767 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017039690350042567 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.535744521870591e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.0934916156544934e-07 <= 1e-05\n",
      "    2. Newton decrement 3.391115494518393e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3909158409115889.\n",
      "Results: -0.9046185360350093\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [26.06036901926941, 0.03947657691486864, 'newton-cg', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 26.06036901926941\n",
      "Tolerance: 0.03947657691486864\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8887433441951017\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 18.114752326525014\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046200789444513\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 93.4407569253271\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405395456552918 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705718575813735 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017678965894817047 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.663936056283477e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.3212326847361767e-07 <= 1e-05\n",
      "    2. Newton decrement 1.8210039651636312e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.387795087457087.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467174028366678 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049394611646153 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001812430339451804 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.5678455704317637e-05 <= 1e-05\n",
      "Newton iter=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 7.961730685860039e-08 <= 1e-05\n",
      "    2. Newton decrement 2.241481157886579e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3871900908889695.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241660910497064 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153782103373853 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017041802611855214 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.544494942916562e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.1666377860965652e-07 <= 1e-05\n",
      "    2. Newton decrement 3.432261713084175e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.39091406874357665.\n",
      "Results: -0.9046185289356158\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 56.44226404877208\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405373720839741 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470552831549082 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017677238727507433 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.658272252123819e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.290882076561211e-07 <= 1e-05\n",
      "    2. Newton decrement 1.8041956394717175e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38779699802089673.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467152705970604 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504921030259036 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018122836222331448 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.565591465624523e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.944805607263612e-08 <= 1e-05\n",
      "    2. Newton decrement 2.236303624297045e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38719202249191026.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416390957771836 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153602881102706 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017039185980577867 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.533670625153865e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.0764386389818088e-07 <= 1e-05\n",
      "    2. Newton decrement 3.381488764182995e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.39091626482751085.\n",
      "Results: -0.9046185788946156\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 71.44525182031228\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185075004619\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [30.494730243458243, 0.06996157438685023, 'liblinear', 'ada']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 30.494730243458243\n",
      "Tolerance: 0.06996157438685023\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.880971781779972\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 19.172249247910475\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046199003552678\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 89.18471072133354\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185146533605\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 93.88119231884234\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185860967387\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100.0, 1e-05, 'liblinear', 'none'] before, using random point [75.31999804362934, 0.07254684793312283, 'newton-cg', 'none']\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 75.31999804362934\n",
      "Tolerance: 0.07254684793312283\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8766984406718609\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 86.48751698749336\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.90461848608243\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 82.3682960991432\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185003732456\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.024284330677251345 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0019652921539758325 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.645782097606935e-05 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.2216484733540423e-09 <= 1e-05\n",
      "    2. Newton decrement 2.3996944908851676e-09 <= 1e-05\n",
      "  Solver did converge at loss = 0.5413619839810033.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.029468401117769674 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0029167530203005696 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 3.815662626776607e-05 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 6.913611195688563e-09 <= 1e-05\n",
      "    2. Newton decrement 1.2856621755166046e-08 <= 1e-05\n",
      "  Solver did converge at loss = 0.5216880895930593.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.029910317805469506 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.002910873984257918 <= 1e-05\n",
      "Newton iter=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 3.8863729797387545e-05 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.3286330823374435e-09 <= 1e-05\n",
      "    2. Newton decrement 1.3869372126217123e-08 <= 1e-05\n",
      "  Solver did converge at loss = 0.5224606990786768.\n",
      "Results: -0.833161631481238\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.1\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.05186203634440163 <= 0.1\n",
      "    2. Newton decrement 0.20767985489620477 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.007249616090545148 <= 0.1\n",
      "    2. Newton decrement 0.012750422867504321 <= 0.1\n",
      "  Solver did converge at loss = 0.45032380345548073.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.05247707992458321 <= 0.1\n",
      "    2. Newton decrement 0.20803159320045814 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.007426829197471726 <= 0.1\n",
      "    2. Newton decrement 0.01302862997173326 <= 0.1\n",
      "  Solver did converge at loss = 0.4494214977059654.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0506987542749328 <= 0.1\n",
      "    2. Newton decrement 0.20554952195130852 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.007001481368019539 <= 0.1\n",
      "    2. Newton decrement 0.012448079895292426 <= 0.1\n",
      "  Solver did converge at loss = 0.4531318008282994.\n",
      "Results: -0.8966323603994977\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.001006332571499498\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046229082648777\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.023786081018344216\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 10 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 10 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 10 epochs took 0 seconds\n",
      "Results: -0.9045091125260295\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 38.140765856919515\n",
      "Tolerance: 1e-05\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 142 epochs took 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 258 epochs took 6 seconds\n",
      "Results: -0.9046189289265044\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 11.125293038215\n",
      "Tolerance: 0.09523760209746114\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 6 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n",
      "convergence after 6 epochs took 0 seconds\n",
      "Results: -0.9040095499240856\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.0008790104147172207\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046173785474151\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.022914474447135843\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890853709743\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.07424047130553216\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8960656331654512\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 98.50513029741667\n",
      "Tolerance: 0.08431865291106494\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 8 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 6 epochs took 0 seconds\n",
      "Results: -0.903849641366336\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 98.18629827893325\n",
      "Tolerance: 0.0527589420354566\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.9045101712131727\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 1.4070479783869265\n",
      "Tolerance: 0.09965934257755169\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8766982835242517\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 36.923254196844645\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046222145407244\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.02852161415045027\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890853709743\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.0012793404778418\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046258151393056\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.7670589601769006\n",
      "Tolerance: 0.09805748829909937\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044471298567305\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.05557749731888867\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 3 epochs took 0 seconds\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 3 epochs took 0 seconds\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 2 epochs took 0 seconds\n",
      "Results: -0.8961007853616811\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.00714934366999519\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 17 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 17 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 26 epochs took 0 seconds\n",
      "Results: -0.9046192207271728\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 99.17902477716883\n",
      "Tolerance: 0.06979792973755031\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n",
      "Results: -0.9038156194701256\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.001168054458158863\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046258151393056\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 98.54482637193935\n",
      "Tolerance: 0.055809783014922176\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405397174114902 <= 0.055809783014922176\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705733612473513 <= 0.055809783014922176\n",
      "    2. Newton decrement 0.028507105138428558 <= 0.055809783014922176\n",
      "  Solver did converge at loss = 0.3917305879871321.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467175713287239 <= 0.055809783014922176\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049409177773804 <= 0.055809783014922176\n",
      "    2. Newton decrement 0.029020053464760876 <= 0.055809783014922176\n",
      "  Solver did converge at loss = 0.3913749140155597.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0624166263437713 <= 0.055809783014922176\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153796268005638 <= 0.055809783014922176\n",
      "    2. Newton decrement 0.028158702996601198 <= 0.055809783014922176\n",
      "  Solver did converge at loss = 0.3949008810254639.\n",
      "Results: -0.9043099659591586\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 6.233561085038475\n",
      "Tolerance: 0.0007558142831993669\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 33 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 27 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 45 epochs took 1 seconds\n",
      "Results: -0.9046214715253121\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 1.4178809432222337\n",
      "Tolerance: 0.012906586456803947\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8865998743433551\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.0009671585972382441\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046229082648777\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.1\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8719669930907488\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 18.00524784933379\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046196289196556\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.1\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.8965172458466842\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 73.33999224159533\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046192145587638\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.023823865170951093\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8887434442115506\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 99.23526791522924\n",
      "Tolerance: 0.03137009937483711\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405397392889041 <= 0.03137009937483711\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705735527788899 <= 0.03137009937483711\n",
      "    2. Newton decrement 0.028507110572708563 <= 0.03137009937483711\n",
      "  Solver did converge at loss = 0.3917305735549199.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646717592790389 <= 0.03137009937483711\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049411033152478 <= 0.03137009937483711\n",
      "    2. Newton decrement 0.029020059071627875 <= 0.03137009937483711\n",
      "  Solver did converge at loss = 0.3913748996377259.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241662853956835 <= 0.03137009937483711\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415379807224865 <= 0.03137009937483711\n",
      "    2. Newton decrement 0.02815870901191207 <= 0.03137009937483711\n",
      "  Solver did converge at loss = 0.3949008654755979.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.904309980245694\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8331624118165064\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.006585028156519158\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.9004763023106214\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.021486160908034232\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 10 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 12 epochs took 1 seconds\n",
      "Results: -0.9045918741595922\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 78.98310488066042\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046190074328928\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.02911957726792783\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8821010800161379\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 99.94388020578424\n",
      "Tolerance: 0.06187890647483986\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045571954736182\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 63.4664106386244\n",
      "Tolerance: 0.1\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405379795922732 <= 0.1\n",
      "    2. Newton decrement 0.236345776049214 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705581487543097 <= 0.1\n",
      "    2. Newton decrement 0.028506673490112936 <= 0.1\n",
      "  Solver did converge at loss = 0.39173173436970354.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646715866548749 <= 0.1\n",
      "    2. Newton decrement 0.23585973134326108 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049261811894045 <= 0.1\n",
      "    2. Newton decrement 0.029019608118159144 <= 0.1\n",
      "  Solver did converge at loss = 0.39137605605663717.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416451927653854 <= 0.1\n",
      "    2. Newton decrement 0.23394291928244246 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415365296756749 <= 0.1\n",
      "    2. Newton decrement 0.028158225242120437 <= 0.1\n",
      "  Solver did converge at loss = 0.39490211608902454.\n",
      "Results: -0.904309844528958\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8331609567554515\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 49.8721960418752\n",
      "Tolerance: 0.1\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044543741810234\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.0028333275040621406\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8856807210191402\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 44.690174895037\n",
      "Tolerance: 0.06855325024308943\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 7 epochs took 0 seconds\n",
      "convergence after 6 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.9037041855330171\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.07694930116929627\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.05186203634440163 <= 0.07694930116929627\n",
      "    2. Newton decrement 0.20767985489620477 <= 0.07694930116929627\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.007249616090545148 <= 0.07694930116929627\n",
      "    2. Newton decrement 0.012750422867504321 <= 0.07694930116929627\n",
      "  Solver did converge at loss = 0.45032380345548073.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.05247707992458321 <= 0.07694930116929627\n",
      "    2. Newton decrement 0.20803159320045814 <= 0.07694930116929627\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.007426829197471726 <= 0.07694930116929627\n",
      "    2. Newton decrement 0.01302862997173326 <= 0.07694930116929627\n",
      "  Solver did converge at loss = 0.4494214977059654.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0506987542749328 <= 0.07694930116929627\n",
      "    2. Newton decrement 0.20554952195130852 <= 0.07694930116929627\n",
      "Newton iter=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.007001481368019539 <= 0.07694930116929627\n",
      "    2. Newton decrement 0.012448079895292426 <= 0.07694930116929627\n",
      "  Solver did converge at loss = 0.4531318008282994.\n",
      "Results: -0.8966323603994977\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.1\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.7910640337424818\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 75.00418064633352\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405387305577491 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470564722131864 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017678317663474721 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.661803546747731e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.309728106013313e-07 <= 1e-05\n",
      "    2. Newton decrement 1.814645460418022e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3877958040448598.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467166032334462 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049325489617366 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018123752791876792 <= 1e-05\n",
      "Newton iter=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 4.56699750512195e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.955379665028842e-08 <= 1e-05\n",
      "    2. Newton decrement 2.2395335843285988e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3871908153327588.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416527296878015 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153714887635636 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017040819804385562 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.540410370600317e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.132252848727992e-07 <= 1e-05\n",
      "    2. Newton decrement 3.4129485707680603e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3909148926764286.\n",
      "Results: -0.9046185575001257\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.0076327815831929565\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9039616794892383\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 62.2626121571304\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405378852085145 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470557322635337 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017677646054679028 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.659602759200061e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.297952935642101e-07 <= 1e-05\n",
      "    2. Newton decrement 1.808121286855606e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.38779654707716327.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467157739602213 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504925380906379 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018123182270906087 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.5661214775392534e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 7.948798058902466e-08 <= 1e-05\n",
      "    2. Newton decrement 2.237521322529283e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3871915665554991.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416442455155506 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153645185736806 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017039802500843013 <= 1e-05\n",
      "Newton iter=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 4.536206481324946e-05 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.0973048506021287e-07 <= 1e-05\n",
      "    2. Newton decrement 3.393266342059569e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.3909157466899426.\n",
      "Results: -0.9046184931775433\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.032792173084959506\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.9046038418938881\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 54.339938900315005\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046214863939804\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.03426111052862787\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.05186203634440163 <= 0.03426111052862787\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.007249616090545148 <= 0.03426111052862787\n",
      "    2. Newton decrement 0.012750422867504321 <= 0.03426111052862787\n",
      "  Solver did converge at loss = 0.45032380345548073.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.05247707992458321 <= 0.03426111052862787\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.007426829197471726 <= 0.03426111052862787\n",
      "    2. Newton decrement 0.01302862997173326 <= 0.03426111052862787\n",
      "  Solver did converge at loss = 0.4494214977059654.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0506987542749328 <= 0.03426111052862787\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.007001481368019539 <= 0.03426111052862787\n",
      "    2. Newton decrement 0.012448079895292426 <= 0.03426111052862787\n",
      "  Solver did converge at loss = 0.4531318008282994.\n",
      "Results: -0.8966323603994977\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 68.83926970141798\n",
      "Tolerance: 0.1\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 8 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.9037087305981858\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.1\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0377238249797234 <= 0.1\n",
      "    2. Newton decrement 0.20082385877696945 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009979258476086106 <= 0.1\n",
      "    2. Newton decrement 0.030950753145539044 <= 0.1\n",
      "  Solver did converge at loss = 0.42529673152891556.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129294271005852 <= 0.1\n",
      "    2. Newton decrement 0.20556485519037207 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01049040036913165 <= 0.1\n",
      "    2. Newton decrement 0.029645586301486122 <= 0.1\n",
      "  Solver did converge at loss = 0.42260632763837985.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203901340427597 <= 0.1\n",
      "    2. Newton decrement 0.2048163008303116 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010449381395664238 <= 0.1\n",
      "    2. Newton decrement 0.030017973988133384 <= 0.1\n",
      "  Solver did converge at loss = 0.422797024880788.\n",
      "Results: -0.8848886870734113\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 19.65351294090431\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.904620121712029\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 28.249601616253617\n",
      "Tolerance: 0.1\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405318951863552 <= 0.1\n",
      "    2. Newton decrement 0.23634449011722938 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705049135422593 <= 0.1\n",
      "    2. Newton decrement 0.028505162532384633 <= 0.1\n",
      "  Solver did converge at loss = 0.39173574756402035.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467098980433238 <= 0.1\n",
      "    2. Newton decrement 0.2358585302298821 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504874609115659 <= 0.1\n",
      "    2. Newton decrement 0.02901804937187872 <= 0.1\n",
      "  Solver did converge at loss = 0.39138005370976103.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241584135508085 <= 0.1\n",
      "    2. Newton decrement 0.23394161045145084 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415315153541985 <= 0.1\n",
      "    2. Newton decrement 0.0281565535975591 <= 0.1\n",
      "  Solver did converge at loss = 0.3949064382344395.\n",
      "Results: -0.9043104017145405\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 16.227727033071385\n",
      "Tolerance: 0.09473310101132769\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044542884382688\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 27.84606911037926\n",
      "Tolerance: 0.09784511114877975\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044543813060995\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 59.10895901594329\n",
      "Tolerance: 1e-05\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 183 epochs took 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 137 epochs took 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 251 epochs took 6 seconds\n",
      "Results: -0.9046185360478506\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 39.47360014095723\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046204789738637\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 77.65637372491422\n",
      "Tolerance: 1e-05\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 177 epochs took 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 132 epochs took 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 247 epochs took 5 seconds\n",
      "Results: -0.9046185432200108\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 9.102126752049106\n",
      "Tolerance: 0.022203818034984276\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405088519977284 <= 0.022203818034984276\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014703036654970273 <= 0.022203818034984276\n",
      "    2. Newton decrement 0.02849944459889815 <= 0.022203818034984276\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017654986674053034 <= 0.022203818034984276\n",
      "    2. Newton decrement 0.0035010650653511818 <= 0.022203818034984276\n",
      "  Solver did converge at loss = 0.3879197343148125.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06466872969415383 <= 0.022203818034984276\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015046796162511672 <= 0.022203818034984276\n",
      "    2. Newton decrement 0.02901215283966635 <= 0.022203818034984276\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018103896025180324 <= 0.022203818034984276\n",
      "    2. Newton decrement 0.003701258753146854 <= 0.022203818034984276\n",
      "  Solver did converge at loss = 0.3873313864511024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062413530201745435 <= 0.022203818034984276\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014151256497252969 <= 0.022203818034984276\n",
      "    2. Newton decrement 0.028150237357962113 <= 0.022203818034984276\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001700603218436025 <= 0.022203818034984276\n",
      "    2. Newton decrement 0.00352216309779288 <= 0.022203818034984276\n",
      "  Solver did converge at loss = 0.3910559629170866.\n",
      "Results: -0.9045825823370963\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8868034539873794\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.05186203634440163 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.007249616090545148 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00021486164704725627 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.1222001156742665e-07 <= 1e-05\n",
      "    2. Newton decrement 3.5786196765749195e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.4499627015944314.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.05247707992458321 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.007426829197471726 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.000226076254083378 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.3632611962851047e-07 <= 1e-05\n",
      "    2. Newton decrement 3.9967972407084456e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.44904094232150027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0506987542749328 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.007001481368019539 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00020134573393909908 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.8611539059562587e-07 <= 1e-05\n",
      "    2. Newton decrement 3.1580971362216834e-07 <= 1e-05\n",
      "  Solver did converge at loss = 0.45279064310267003.\n",
      "Results: -0.8961284233446948\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.1\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.8338342015289545\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.06750552188513533\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.9044447434039208\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 42.409453086679385\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772222995575716 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0099762353865083 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0022048417961685884 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0009610934795035858 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0003711646817787309 <= 1e-05\n",
      "Newton iter=6\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0001290430333456341 <= 1e-05\n",
      "Newton iter=7\n",
      "  Check Convergence\n",
      "    1. max |gradient| 3.660367520060687e-05 <= 1e-05\n",
      "Newton iter=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 6.721365492403167e-06 <= 1e-05\n",
      "    2. Newton decrement 8.76202712085644e-06 <= 1e-05\n",
      "  Solver did converge at loss = 0.4123735617875193.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129111212038797 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010487298295421244 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017180092953030315 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0007724282350710168 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00029397300646814666 <= 1e-05\n",
      "Newton iter=6\n",
      "  Check Convergence\n",
      "    1. max |gradient| 9.586260627287083e-05 <= 1e-05\n",
      "Newton iter=7\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.4985996059058088e-05 <= 1e-05\n",
      "Newton iter=8\n",
      "  Check Convergence\n",
      "    1. max |gradient| 3.861738976684501e-06 <= 1e-05\n",
      "    2. Newton decrement 4.747492888846979e-06 <= 1e-05\n",
      "  Solver did converge at loss = 0.4122375584710666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203723289479999 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010446519734083403 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001722838701096515 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0007890051505781322 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0003028206045214959 <= 1e-05\n",
      "Newton iter=6\n",
      "  Check Convergence\n",
      "    1. max |gradient| 9.931867239804451e-05 <= 1e-05\n",
      "Newton iter=7\n",
      "  Check Convergence\n",
      "    1. max |gradient| 2.6120316184360948e-05 <= 1e-05\n",
      "Newton iter=8\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.07588495191652e-06 <= 1e-05\n",
      "    2. Newton decrement 4.996310804698339e-06 <= 1e-05\n",
      "  Solver did converge at loss = 0.41215108690043734.\n",
      "Results: -0.8868915754765044\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 65.74573400249176\n",
      "Tolerance: 0.1\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.903194519068761\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.1\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.795092463833087\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 99.49564097224996\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.037723819050915874 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009979247499327323 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0022125104902173225 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0009718966062728512 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0003833840643452345 <= 1e-05\n",
      "Newton iter=6\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00014101681708833698 <= 1e-05\n",
      "Newton iter=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 4.6285533721360586e-05 <= 1e-05\n",
      "Newton iter=8\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.2197326734582348e-05 <= 1e-05\n",
      "Newton iter=9\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.911893622415922e-06 <= 1e-05\n",
      "    2. Newton decrement 2.3665372681845255e-06 <= 1e-05\n",
      "  Solver did converge at loss = 0.41219186227800897.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129293587236919 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010490388779442344 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017256154353776521 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0007828047773307915 <= 1e-05\n",
      "Newton iter=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.00030556470079151285 <= 1e-05\n",
      "Newton iter=6\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00010682185434281177 <= 1e-05\n",
      "Newton iter=7\n",
      "  Check Convergence\n",
      "    1. max |gradient| 3.337036476668345e-05 <= 1e-05\n",
      "Newton iter=8\n",
      "  Check Convergence\n",
      "    1. max |gradient| 8.028638098796226e-06 <= 1e-05\n",
      "    2. Newton decrement 1.0274254480806596e-05 <= 1e-05\n",
      "Newton iter=9\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.0364102223762994e-06 <= 1e-05\n",
      "    2. Newton decrement 1.2412358333642019e-06 <= 1e-05\n",
      "  Solver did converge at loss = 0.4120861325168503.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.042039006754559724 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010449370701612337 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017300482372808838 <= 1e-05\n",
      "Newton iter=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.000798974479344329 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00031416425114308075 <= 1e-05\n",
      "Newton iter=6\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00011025900697585536 <= 1e-05\n",
      "Newton iter=7\n",
      "  Check Convergence\n",
      "    1. max |gradient| 3.4636458537660314e-05 <= 1e-05\n",
      "Newton iter=8\n",
      "  Check Convergence\n",
      "    1. max |gradient| 8.416666041210705e-06 <= 1e-05\n",
      "    2. Newton decrement 1.0760587860951685e-05 <= 1e-05\n",
      "Newton iter=9\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.093013676616017e-06 <= 1e-05\n",
      "    2. Newton decrement 1.3067806441509934e-06 <= 1e-05\n",
      "  Solver did converge at loss = 0.41200533470259787.\n",
      "Results: -0.8868058630515061\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.0639636562325511\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0377238249797234 <= 0.0639636562325511\n",
      "    2. Newton decrement 0.20082385877696945 <= 0.0639636562325511\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009979258476086106 <= 0.0639636562325511\n",
      "    2. Newton decrement 0.030950753145539044 <= 0.0639636562325511\n",
      "  Solver did converge at loss = 0.42529673152891556.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129294271005852 <= 0.0639636562325511\n",
      "    2. Newton decrement 0.20556485519037207 <= 0.0639636562325511\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01049040036913165 <= 0.0639636562325511\n",
      "    2. Newton decrement 0.029645586301486122 <= 0.0639636562325511\n",
      "  Solver did converge at loss = 0.42260632763837985.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203901340427597 <= 0.0639636562325511\n",
      "    2. Newton decrement 0.2048163008303116 <= 0.0639636562325511\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010449381395664238 <= 0.0639636562325511\n",
      "    2. Newton decrement 0.030017973988133384 <= 0.0639636562325511\n",
      "  Solver did converge at loss = 0.422797024880788.\n",
      "Results: -0.8848886870734113\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 63.93374572919803\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n",
      "Results: -0.9046185432093098\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 51.781192682155954\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n",
      "Results: -0.9046186217692034\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 47.35542583978401\n",
      "Tolerance: 0.06146760738461431\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405363188603548 <= 0.06146760738461431\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705436141982445 <= 0.06146760738461431\n",
      "    2. Newton decrement 0.02850626102685291 <= 0.06146760738461431\n",
      "  Solver did converge at loss = 0.3917328298421613.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467142374171314 <= 0.06146760738461431\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504912101061743 <= 0.06146760738461431\n",
      "    2. Newton decrement 0.02901918258462735 <= 0.06146760738461431\n",
      "  Solver did converge at loss = 0.39137714733968726.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241628525889598 <= 0.06146760738461431\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153516057886253 <= 0.06146760738461431\n",
      "    2. Newton decrement 0.028157768805719494 <= 0.06146760738461431\n",
      "  Solver did converge at loss = 0.3949032961260404.\n",
      "Results: -0.9043100588248492\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 64.25332009089963\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 296 epochs took 5 seconds\n",
      "Results: -0.9046185574979856\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 22.366295555152558\n",
      "Tolerance: 0.07078299207796734\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 7 epochs took 0 seconds\n",
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.9039044034394964\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.1\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8766984478161985\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 55.228167038477444\n",
      "Tolerance: 0.011742710451819793\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 0 seconds\n",
      "Results: -0.9046177483986103\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.033099626022401366\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 10 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 10 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 0 seconds\n",
      "Results: -0.9045674733613662\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.016752941833145886\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405397631677248 <= 0.016752941833145886\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705737618328735 <= 0.016752941833145886\n",
      "    2. Newton decrement 0.028507116504139358 <= 0.016752941833145886\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017679138987479386 <= 0.016752941833145886\n",
      "    2. Newton decrement 0.003505803204842954 <= 0.016752941833145886\n",
      "  Solver did converge at loss = 0.3878935374413302.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467176162154314 <= 0.016752941833145886\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049413058271706 <= 0.016752941833145886\n",
      "    2. Newton decrement 0.02902006519143834 <= 0.016752941833145886\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018124450408189593 <= 0.016752941833145886\n",
      "    2. Newton decrement 0.0037064132344201643 <= 0.016752941833145886\n",
      "  Solver did converge at loss = 0.3873047839320521.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241663093624492 <= 0.016752941833145886\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153800041555552 <= 0.016752941833145886\n",
      "    2. Newton decrement 0.028158715577544995 <= 0.016752941833145886\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017042065196178789 <= 0.016752941833145886\n",
      "    2. Newton decrement 0.003528140945221309 <= 0.016752941833145886\n",
      "  Solver did converge at loss = 0.3910265405414873.\n",
      "Results: -0.9045821396406953\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 37.48133635515232\n",
      "Tolerance: 0.048603923822900866\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 6 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.9045947348246419\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.0637030974925522\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8719669930907488\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 45.89579684960667\n",
      "Tolerance: 0.07374825660083484\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405361108127249 <= 0.07374825660083484\n",
      "    2. Newton decrement 0.23634538110710385 <= 0.07374825660083484\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705417936020591 <= 0.07374825660083484\n",
      "    2. Newton decrement 0.02850620935825403 <= 0.07374825660083484\n",
      "  Solver did converge at loss = 0.391732967073102.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467140333300535 <= 0.07374825660083484\n",
      "    2. Newton decrement 0.23585936244531053 <= 0.07374825660083484\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049103373687084 <= 0.07374825660083484\n",
      "    2. Newton decrement 0.029019129280056243 <= 0.07374825660083484\n",
      "  Solver did converge at loss = 0.3913772840430158.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416264380246646 <= 0.07374825660083484\n",
      "    2. Newton decrement 0.2339425172904874 <= 0.07374825660083484\n",
      "Newton iter=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153498908921602 <= 0.07374825660083484\n",
      "    2. Newton decrement 0.02815771163443847 <= 0.07374825660083484\n",
      "  Solver did converge at loss = 0.3949034439382206.\n",
      "Results: -0.9043101088309333\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.009269309997685308\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8943119897578321\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.15290636164285\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046190216809048\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 33.47587498397328\n",
      "Tolerance: 0.0692548906691196\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044543884418764\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.1\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405397631677248 <= 0.1\n",
      "    2. Newton decrement 0.236346152966152 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705737618328735 <= 0.1\n",
      "    2. Newton decrement 0.028507116504139358 <= 0.1\n",
      "  Solver did converge at loss = 0.3917305578023965.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467176162154314 <= 0.1\n",
      "    2. Newton decrement 0.2358600834094754 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049413058271706 <= 0.1\n",
      "    2. Newton decrement 0.02902006519143834 <= 0.1\n",
      "  Solver did converge at loss = 0.39137488394454784.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241663093624492 <= 0.1\n",
      "    2. Newton decrement 0.23394330294153098 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153800041555552 <= 0.1\n",
      "    2. Newton decrement 0.028158715577544995 <= 0.1\n",
      "  Solver did converge at loss = 0.3949008485031391.\n",
      "Results: -0.9043100016765674\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.04332924697042027\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405397631677248 <= 0.04332924697042027\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705737618328735 <= 0.04332924697042027\n",
      "    2. Newton decrement 0.028507116504139358 <= 0.04332924697042027\n",
      "  Solver did converge at loss = 0.3917305578023965.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467176162154314 <= 0.04332924697042027\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049413058271706 <= 0.04332924697042027\n",
      "    2. Newton decrement 0.02902006519143834 <= 0.04332924697042027\n",
      "  Solver did converge at loss = 0.39137488394454784.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241663093624492 <= 0.04332924697042027\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153800041555552 <= 0.04332924697042027\n",
      "    2. Newton decrement 0.028158715577544995 <= 0.04332924697042027\n",
      "  Solver did converge at loss = 0.3949008485031391.\n",
      "Results: -0.9043100016765674\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 55.17031047772194\n",
      "Tolerance: 0.008979322570501417\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9039615008872138\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 95.09201939995903\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 53 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 123 epochs took 3 seconds\n",
      "Results: -0.9046185217912779\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 72.26935708857266\n",
      "Tolerance: 0.00367168589624869\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640538574233582 <= 0.00367168589624869\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705633537380403 <= 0.00367168589624869\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00176781934156292 <= 0.00367168589624869\n",
      "    2. Newton decrement 0.0035056199309731117 <= 0.00367168589624869\n",
      "  Solver did converge at loss = 0.3878945470274123.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467164498815887 <= 0.00367168589624869\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049312233736003 <= 0.00367168589624869\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018123647250048408 <= 0.00367168589624869\n",
      "    2. Newton decrement 0.0037062139769883473 <= 0.00367168589624869\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.566835238974861e-05 <= 0.00367168589624869\n",
      "    2. Newton decrement 0.0001116968248583457 <= 0.00367168589624869\n",
      "  Solver did converge at loss = 0.38719117866545494.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241651160752692 <= 0.00367168589624869\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153701997528334 <= 0.00367168589624869\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017040631530268165 <= 0.00367168589624869\n",
      "    2. Newton decrement 0.0035279081137438288 <= 0.00367168589624869\n",
      "  Solver did converge at loss = 0.3910276782754978.\n",
      "Results: -0.9046021223663822\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 70.88534551504458\n",
      "Tolerance: 0.039549656542824975\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890710951398\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 66.13489235869282\n",
      "Tolerance: 0.05404872965915056\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 8 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 7 epochs took 0 seconds\n",
      "Results: -0.904491748649039\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.007787919006060121\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 7 epochs took 1 seconds\n",
      "Results: -0.8961425788079677\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 35.09840558843203\n",
      "Tolerance: 0.02180959529142161\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n",
      "convergence after 7 epochs took 0 seconds\n",
      "Results: -0.9046275823871675\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.08672425639386783\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.8962358398619025\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 59.01474948719249\n",
      "Tolerance: 0.09771083659602363\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405376113546034 <= 0.09771083659602363\n",
      "    2. Newton decrement 0.23634569822855978 <= 0.09771083659602363\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470554925711993 <= 0.09771083659602363\n",
      "    2. Newton decrement 0.028506582030565136 <= 0.09771083659602363\n",
      "  Solver did converge at loss = 0.391731977276074.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467155053156351 <= 0.09771083659602363\n",
      "    2. Newton decrement 0.23585965865402628 <= 0.09771083659602363\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049230589393468 <= 0.09771083659602363\n",
      "    2. Newton decrement 0.029019513758794933 <= 0.09771083659602363\n",
      "  Solver did converge at loss = 0.39137629803749324.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241641497094573 <= 0.09771083659602363\n",
      "    2. Newton decrement 0.23394284007147215 <= 0.09771083659602363\n",
      "Newton iter=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153622607411267 <= 0.09771083659602363\n",
      "    2. Newton decrement 0.028158124024915982 <= 0.09771083659602363\n",
      "  Solver did converge at loss = 0.3949023777614616.\n",
      "Results: -0.9043098159537469\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 98.78391854229143\n",
      "Tolerance: 0.03850312898049871\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 1 seconds\n",
      "Results: -0.8857793375149758\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.030699894810561804\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890853709743\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 61.73046958904678\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n",
      "Results: -0.9046185217741561\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.438695896783635\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n",
      "Results: -0.9046185574765834\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 99.02211211686799\n",
      "Tolerance: 0.06282508870707232\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640539732567374 <= 0.06282508870707232\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470573493933445 <= 0.06282508870707232\n",
      "    2. Newton decrement 0.028507108903101416 <= 0.06282508870707232\n",
      "  Solver did converge at loss = 0.3917305779890161.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646717586196591 <= 0.06282508870707232\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049410463112896 <= 0.06282508870707232\n",
      "    2. Newton decrement 0.02902005734899538 <= 0.06282508870707232\n",
      "  Solver did converge at loss = 0.391374904055116.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416627864940046 <= 0.06282508870707232\n",
      "    2. Newton decrement 0.23394329635922784 <= 0.06282508870707232\n",
      "Newton iter=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153797517919632 <= 0.06282508870707232\n",
      "    2. Newton decrement 0.028158707163789713 <= 0.06282508870707232\n",
      "  Solver did converge at loss = 0.3949008702530809.\n",
      "Results: -0.9043099659591586\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 74.31639352500217\n",
      "Tolerance: 0.0028477941420863595\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405386923261742 <= 0.0028477941420863595\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705643874667598 <= 0.0028477941420863595\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017678287274486238 <= 0.0028477941420863595\n",
      "    2. Newton decrement 0.003505638131142296 <= 0.0028477941420863595\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.661703776066686e-05 <= 0.0028477941420863595\n",
      "    2. Newton decrement 9.612633745382314e-05 <= 0.0028477941420863595\n",
      "  Solver did converge at loss = 0.38779602002037594.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467165657287749 <= 0.0028477941420863595\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049322247657404 <= 0.0028477941420863595\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00181237269782723 <= 0.0028477941420863595\n",
      "    2. Newton decrement 0.003706233764864079 <= 0.0028477941420863595\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.566957809045897e-05 <= 0.0028477941420863595\n",
      "    2. Newton decrement 0.0001116997285810536 <= 0.0028477941420863595\n",
      "  Solver did converge at loss = 0.38719107374440903.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241652345978782 <= 0.0028477941420863595\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153711735126324 <= 0.0028477941420863595\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017040773752571242 <= 0.0028477941420863595\n",
      "    2. Newton decrement 0.0035279312292772454 <= 0.0028477941420863595\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 4.540219539241123e-05 <= 0.0028477941420863595\n",
      "    2. Newton decrement 0.00010904703648483146 <= 0.0028477941420863595\n",
      "  Solver did converge at loss = 0.39091527535823867.\n",
      "Results: -0.9046185998589262\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 66.47770610107843\n",
      "Tolerance: 0.082878459284018\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044545099170213\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 89.68130001594741\n",
      "Tolerance: 0.00605365871220846\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.903961665202703\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.886805474641251\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 98.31410925448277\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 49 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 131 epochs took 3 seconds\n",
      "Results: -0.9046185646594448\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 63.59711454885724\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.904621222179753\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.009442449611219395\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8960656331654512\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 59.63888517977505\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n",
      "Results: -0.9046185431964687\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 58.70891234772002\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046171358325471\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.042770888599656734\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.9045816432670416\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 65.9619291765647\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 218 epochs took 5 seconds\n",
      "Results: -0.9046185003539841\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 24.33241446169541\n",
      "Tolerance: 0.03935126428977162\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.9045157417845117\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 58.56754121795\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046197646235505\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 66.31922427658141\n",
      "Tolerance: 0.0978653856943472\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405381895874741 <= 0.0978653856943472\n",
      "    2. Newton decrement 0.23634582042771968 <= 0.0978653856943472\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705599868286687 <= 0.0978653856943472\n",
      "    2. Newton decrement 0.028506725647636327 <= 0.0978653856943472\n",
      "  Solver did converge at loss = 0.39173159584603623.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467160725500275 <= 0.0978653856943472\n",
      "    2. Newton decrement 0.23585977279557982 <= 0.0978653856943472\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049279617770037 <= 0.0978653856943472\n",
      "    2. Newton decrement 0.029019661929801557 <= 0.0978653856943472\n",
      "  Solver did converge at loss = 0.39137591805989264.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241647300321215 <= 0.0978653856943472\n",
      "    2. Newton decrement 0.2339429644540608 <= 0.0978653856943472\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153670281813413 <= 0.0978653856943472\n",
      "    2. Newton decrement 0.028158282966039814 <= 0.0978653856943472\n",
      "  Solver did converge at loss = 0.3949019668596878.\n",
      "Results: -0.9043098445246777\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 56.64749061375864\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n",
      "Results: -0.9046185289035127\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.02369951124973\n",
      "Tolerance: 0.09373282384368267\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044545242035565\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.04723113376066335\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8722073959969611\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 65.33452231109132\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 247 epochs took 4 seconds\n",
      "Results: -0.9046185289291951\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 1e-05\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 19 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 21 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 19 epochs took 0 seconds\n",
      "Results: -0.8331616044921993\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.08287636644409888\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.024284330677251345 <= 0.08287636644409888\n",
      "    2. Newton decrement 0.1370206533891737 <= 0.08287636644409888\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0019652921539758325 <= 0.08287636644409888\n",
      "    2. Newton decrement 0.004246881486894676 <= 0.08287636644409888\n",
      "  Solver did converge at loss = 0.5413947671859272.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.029468401117769674 <= 0.08287636644409888\n",
      "    2. Newton decrement 0.15214554125430127 <= 0.08287636644409888\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0029167530203005696 <= 0.08287636644409888\n",
      "    2. Newton decrement 0.006044026040531253 <= 0.08287636644409888\n",
      "  Solver did converge at loss = 0.521760612349928.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.029910317805469506 <= 0.08287636644409888\n",
      "    2. Newton decrement 0.1512447219563892 <= 0.08287636644409888\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.002910873984257918 <= 0.08287636644409888\n",
      "    2. Newton decrement 0.006124313374916275 <= 0.08287636644409888\n",
      "  Solver did converge at loss = 0.5225359888991837.\n",
      "Results: -0.8335438899415434\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 66.54078656955507\n",
      "Tolerance: 0.07511631468526521\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.9043979351693778\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 50.19079612212621\n",
      "Tolerance: 0.1\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772266066110949 <= 0.1\n",
      "    2. Newton decrement 0.2008174001745915 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00997706501248278 <= 0.1\n",
      "    2. Newton decrement 0.03093878804807844 <= 0.1\n",
      "  Solver did converge at loss = 0.42532475787373625.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129160469438602 <= 0.1\n",
      "    2. Newton decrement 0.2055601133632844 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010488132855440159 <= 0.1\n",
      "    2. Newton decrement 0.029635716201042644 <= 0.1\n",
      "  Solver did converge at loss = 0.4226287877445272.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203771204139138 <= 0.1\n",
      "    2. Newton decrement 0.20481174443066963 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01044728948121813 <= 0.1\n",
      "    2. Newton decrement 0.03000907739849091 <= 0.1\n",
      "  Solver did converge at loss = 0.42281762046943466.\n",
      "Results: -0.8849057453051925\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.7810958133675\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.904619636179564\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 69.1570483684658\n",
      "Tolerance: 0.0769803543802167\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.904525961518086\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.02665546814070843\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 0 seconds\n",
      "Results: -0.9045443968320949\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 61.28599297396739\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.904618850343069\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 72.12166584421654\n",
      "Tolerance: 0.07635696968814806\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.9045348680871377\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 49.07582901584009\n",
      "Tolerance: 0.03289484321751013\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 8 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 8 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9045658521335057\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 63.86994876699952\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046195579278588\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 94.59627308262952\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046196648575044\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 81.58347459658522\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 69 epochs took 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 132 epochs took 2 seconds\n",
      "Results: -0.9046184932246275\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 90.77772326680852\n",
      "Tolerance: 0.04653491220293702\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045892782595343\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 69.45077305138567\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046190718261017\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.07750352103930261\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8722073959969611\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.040652117291381774\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 3 epochs took 0 seconds\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 2 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 2 epochs took 0 seconds\n",
      "Results: -0.8960403157845657\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.896128466204301\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.04608113391252167\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0377238249797234 <= 0.04608113391252167\n",
      "    2. Newton decrement 0.20082385877696945 <= 0.04608113391252167\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009979258476086106 <= 0.04608113391252167\n",
      "    2. Newton decrement 0.030950753145539044 <= 0.04608113391252167\n",
      "  Solver did converge at loss = 0.42529673152891556.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129294271005852 <= 0.04608113391252167\n",
      "    2. Newton decrement 0.20556485519037207 <= 0.04608113391252167\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01049040036913165 <= 0.04608113391252167\n",
      "    2. Newton decrement 0.029645586301486122 <= 0.04608113391252167\n",
      "  Solver did converge at loss = 0.42260632763837985.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203901340427597 <= 0.04608113391252167\n",
      "    2. Newton decrement 0.2048163008303116 <= 0.04608113391252167\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010449381395664238 <= 0.04608113391252167\n",
      "    2. Newton decrement 0.030017973988133384 <= 0.04608113391252167\n",
      "  Solver did converge at loss = 0.422797024880788.\n",
      "Results: -0.8848886870734113\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 54.820196266949544\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n",
      "Results: -0.9046185217698759\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 98.3196008847448\n",
      "Tolerance: 0.014427504211511429\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 13 epochs took 0 seconds\n",
      "Results: -0.9045513117302962\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 56.44491237696431\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046173429006329\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.08176431555383967\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405397631677248 <= 0.08176431555383967\n",
      "    2. Newton decrement 0.236346152966152 <= 0.08176431555383967\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705737618328735 <= 0.08176431555383967\n",
      "    2. Newton decrement 0.028507116504139358 <= 0.08176431555383967\n",
      "  Solver did converge at loss = 0.3917305578023965.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467176162154314 <= 0.08176431555383967\n",
      "    2. Newton decrement 0.2358600834094754 <= 0.08176431555383967\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049413058271706 <= 0.08176431555383967\n",
      "    2. Newton decrement 0.02902006519143834 <= 0.08176431555383967\n",
      "  Solver did converge at loss = 0.39137488394454784.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241663093624492 <= 0.08176431555383967\n",
      "    2. Newton decrement 0.23394330294153098 <= 0.08176431555383967\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153800041555552 <= 0.08176431555383967\n",
      "    2. Newton decrement 0.028158715577544995 <= 0.08176431555383967\n",
      "  Solver did converge at loss = 0.3949008485031391.\n",
      "Results: -0.9043100016765674\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.03660026472782127\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.024284330677251345 <= 0.03660026472782127\n",
      "    2. Newton decrement 0.1370206533891737 <= 0.03660026472782127\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0019652921539758325 <= 0.03660026472782127\n",
      "    2. Newton decrement 0.004246881486894676 <= 0.03660026472782127\n",
      "  Solver did converge at loss = 0.5413947671859272.\n",
      "Newton iter=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.029468401117769674 <= 0.03660026472782127\n",
      "    2. Newton decrement 0.15214554125430127 <= 0.03660026472782127\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0029167530203005696 <= 0.03660026472782127\n",
      "    2. Newton decrement 0.006044026040531253 <= 0.03660026472782127\n",
      "  Solver did converge at loss = 0.521760612349928.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.029910317805469506 <= 0.03660026472782127\n",
      "    2. Newton decrement 0.1512447219563892 <= 0.03660026472782127\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.002910873984257918 <= 0.03660026472782127\n",
      "    2. Newton decrement 0.006124313374916275 <= 0.03660026472782127\n",
      "  Solver did converge at loss = 0.5225359888991837.\n",
      "Results: -0.8335438899415434\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 54.352754701358194\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n",
      "Results: -0.9046185289077929\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 98.32636309277294\n",
      "Tolerance: 0.012143148860029984\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8994878688863658\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 64.74577450726906\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 274 epochs took 7 seconds\n",
      "Results: -0.9046185503600682\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 62.972920401693294\n",
      "Tolerance: 0.009926647941147799\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.9004763094528191\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 50.75712099205712\n",
      "Tolerance: 0.1\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8766984406718609\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.040699522392251386\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8887434442115506\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.023401526036674968\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 6 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "convergence after 8 epochs took 1 seconds\n",
      "Results: -0.9046227975406663\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 16.717432904373446\n",
      "Tolerance: 0.09061226363665177\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405243347298112 <= 0.09061226363665177\n",
      "    2. Newton decrement 0.23634289193293664 <= 0.09061226363665177\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014704388204840067 <= 0.09061226363665177\n",
      "    2. Newton decrement 0.028503285708920398 <= 0.09061226363665177\n",
      "  Solver did converge at loss = 0.39174073328660636.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467024820889018 <= 0.09061226363665177\n",
      "    2. Newton decrement 0.23585703753539833 <= 0.09061226363665177\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015048105759729324 <= 0.09061226363665177\n",
      "    2. Newton decrement 0.029016113536014243 <= 0.09061226363665177\n",
      "  Solver did converge at loss = 0.39138501938668385.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241508285137842 <= 0.09061226363665177\n",
      "    2. Newton decrement 0.23393998402975041 <= 0.09061226363665177\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014152529077935145 <= 0.09061226363665177\n",
      "    2. Newton decrement 0.028154478694148215 <= 0.09061226363665177\n",
      "  Solver did converge at loss = 0.3949118045573486.\n",
      "Results: -0.9043105016967461\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.08261605188484399\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8719669930907488\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.0779905943354591\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0377238249797234 <= 0.0779905943354591\n",
      "    2. Newton decrement 0.20082385877696945 <= 0.0779905943354591\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009979258476086106 <= 0.0779905943354591\n",
      "    2. Newton decrement 0.030950753145539044 <= 0.0779905943354591\n",
      "  Solver did converge at loss = 0.42529673152891556.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129294271005852 <= 0.0779905943354591\n",
      "    2. Newton decrement 0.20556485519037207 <= 0.0779905943354591\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01049040036913165 <= 0.0779905943354591\n",
      "    2. Newton decrement 0.029645586301486122 <= 0.0779905943354591\n",
      "  Solver did converge at loss = 0.42260632763837985.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203901340427597 <= 0.0779905943354591\n",
      "    2. Newton decrement 0.2048163008303116 <= 0.0779905943354591\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010449381395664238 <= 0.0779905943354591\n",
      "    2. Newton decrement 0.030017973988133384 <= 0.0779905943354591\n",
      "  Solver did converge at loss = 0.422797024880788.\n",
      "Results: -0.8848886870734113\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.011179926210820937\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 20 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 22 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 18 epochs took 1 seconds\n",
      "Results: -0.8866203284993445\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 76.16763102241525\n",
      "Tolerance: 0.03358065389967793\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405387936580931 <= 0.03358065389967793\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705652744925444 <= 0.03358065389967793\n",
      "    2. Newton decrement 0.02850687568686439 <= 0.03358065389967793\n",
      "  Solver did converge at loss = 0.39173119736482664.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467166651340817 <= 0.03358065389967793\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049330840429757 <= 0.03358065389967793\n",
      "    2. Newton decrement 0.029019816729032106 <= 0.03358065389967793\n",
      "  Solver did converge at loss = 0.39137552109089524.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241653362991979 <= 0.03358065389967793\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153720090818955 <= 0.03358065389967793\n",
      "    2. Newton decrement 0.028158449025175915 <= 0.03358065389967793\n",
      "  Solver did converge at loss = 0.3949015375667058.\n",
      "Results: -0.9043098373803398\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.05896282433297319\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8766984478161985\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 54.809967752776366\n",
      "Tolerance: 0.021123033204583155\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 10 epochs took 0 seconds\n",
      "convergence after 9 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 0 seconds\n",
      "Results: -0.9046696740147153\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.06969586426320801\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.896169774133838\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 49.22879084759052\n",
      "Tolerance: 0.1\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8722073888526234\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.568541417382846\n",
      "Tolerance: 0.008270252814853909\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.880734872504195\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 68.55027653385396\n",
      "Tolerance: 0.0734237787768077\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405383416372895 <= 0.0734237787768077\n",
      "    2. Newton decrement 0.2363458525604108 <= 0.0734237787768077\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705613177413883 <= 0.0734237787768077\n",
      "    2. Newton decrement 0.028506763413352176 <= 0.0734237787768077\n",
      "  Solver did converge at loss = 0.39173149554556713.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162217082506 <= 0.0734237787768077\n",
      "    2. Newton decrement 0.23585980280957713 <= 0.0734237787768077\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0150492925106209 <= 0.0734237787768077\n",
      "    2. Newton decrement 0.02901970089340308 <= 0.0734237787768077\n",
      "  Solver did converge at loss = 0.3913758181405539.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241648826335246 <= 0.0734237787768077\n",
      "    2. Newton decrement 0.23394299716113193 <= 0.0734237787768077\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153682818756182 <= 0.0734237787768077\n",
      "    2. Newton decrement 0.028158324763035408 <= 0.0734237787768077\n",
      "  Solver did converge at loss = 0.3949018588058542.\n",
      "Results: -0.9043098516668753\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 30.012801324703148\n",
      "Tolerance: 0.007537061916281146\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9039613151558328\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.08390820946620921\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.8841907988551232\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 15.49130642035429\n",
      "Tolerance: 0.05399676195207126\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.9046766227184593\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 71.33653911527303\n",
      "Tolerance: 0.05213440670328341\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 3 epochs took 1 seconds\n",
      "Results: -0.9043429836095839\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.03222667229286385\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890853709743\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 77.8636951594553\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185432242911\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 46.266501704509686\n",
      "Tolerance: 0.1\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044543813232212\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 29.713023164297695\n",
      "Tolerance: 0.016046333352258683\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 14 epochs took 0 seconds\n",
      "Results: -0.8863806330892515\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 70.35766408408043\n",
      "Tolerance: 0.05537874736593383\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640538457744585 <= 0.05537874736593383\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705623340616262 <= 0.05537874736593383\n",
      "    2. Newton decrement 0.028506792251971842 <= 0.05537874736593383\n",
      "  Solver did converge at loss = 0.3917314189544511.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467163356076344 <= 0.05537874736593383\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049302355928957 <= 0.05537874736593383\n",
      "    2. Newton decrement 0.0290197306468569 <= 0.05537874736593383\n",
      "  Solver did converge at loss = 0.39137574184025054.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416499916260165 <= 0.05537874736593383\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153692392323811 <= 0.05537874736593383\n",
      "    2. Newton decrement 0.02815835668047953 <= 0.05537874736593383\n",
      "  Solver did converge at loss = 0.39490177629315604.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9043098302338618\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.6390422552694004\n",
      "Tolerance: 0.045930424083878006\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8722069316685085\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 56.14549304145429\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n",
      "Results: -0.9046185360499908\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 83.3648416718471\n",
      "Tolerance: 0.0493872251721164\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 7 epochs took 1 seconds\n",
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9045871224559074\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 63 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 134 epochs took 3 seconds\n",
      "Results: -0.904618528939896\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 44.25924597747271\n",
      "Tolerance: 0.046401486034040734\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 7 epochs took 0 seconds\n",
      "Results: -0.9043769340760474\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.07790297993465674\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044545813496984\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.09221604764746645\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "Results: -0.9037966289625082\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 35.57327823101363\n",
      "Tolerance: 0.013048941061295715\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.037721694760601755 <= 0.013048941061295715\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009975191828242354 <= 0.013048941061295715\n",
      "    2. Newton decrement 0.030929025080701045 <= 0.013048941061295715\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0022022477745077713 <= 0.013048941061295715\n",
      "    2. Newton decrement 0.0076522065232056055 <= 0.013048941061295715\n",
      "  Solver did converge at loss = 0.4160150973306827.\n",
      "Newton iter=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129050178786953 <= 0.013048941061295715\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010486264368666743 <= 0.013048941061295715\n",
      "    2. Newton decrement 0.029627591309432145 <= 0.013048941061295715\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017154825861929544 <= 0.013048941061295715\n",
      "    2. Newton decrement 0.006508538190561441 <= 0.013048941061295715\n",
      "  Solver did converge at loss = 0.414821487888635.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.042036639150641236 <= 0.013048941061295715\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010445566237157955 <= 0.013048941061295715\n",
      "    2. Newton decrement 0.030001750966538274 <= 0.013048941061295715\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001720441153211568 <= 0.013048941061295715\n",
      "    2. Newton decrement 0.006693065663108642 <= 0.013048941061295715\n",
      "  Solver did converge at loss = 0.41478920272637104.\n",
      "Results: -0.8863808844239962\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 1.441317850539058\n",
      "Tolerance: 0.042178326889001284\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8887423655149909\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.06195201243229783\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n",
      "Results: -0.8861171497985417\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 99.9720635529295\n",
      "Tolerance: 0.08300451985539163\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.8857052667562524\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 31.090727661863884\n",
      "Tolerance: 0.007147059837153275\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 18 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 26 epochs took 0 seconds\n",
      "Results: -0.9046192491161867\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.08475323167355983\n",
      "Solver: newton-cg\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8764315292372213\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.1\n",
      "Solver: lbfgs\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Results: -0.7910640337424818\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.008363151390071318\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405397631677248 <= 0.008363151390071318\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705737618328735 <= 0.008363151390071318\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017679138987479386 <= 0.008363151390071318\n",
      "    2. Newton decrement 0.003505803204842954 <= 0.008363151390071318\n",
      "  Solver did converge at loss = 0.3878935374413302.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467176162154314 <= 0.008363151390071318\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049413058271706 <= 0.008363151390071318\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0018124450408189593 <= 0.008363151390071318\n",
      "    2. Newton decrement 0.0037064132344201643 <= 0.008363151390071318\n",
      "  Solver did converge at loss = 0.3873047839320521.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241663093624492 <= 0.008363151390071318\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153800041555552 <= 0.008363151390071318\n",
      "Newton iter=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017042065196178789 <= 0.008363151390071318\n",
      "    2. Newton decrement 0.003528140945221309 <= 0.008363151390071318\n",
      "  Solver did converge at loss = 0.3910265405414873.\n",
      "Results: -0.9045821396406953\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.029342125377624467\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 3 epochs took 0 seconds\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.8331339747798916\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 71.49592198904394\n",
      "Tolerance: 0.0693513258226383\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405385278545345 <= 0.0693513258226383\n",
      "    2. Newton decrement 0.23634589191352778 <= 0.0693513258226383\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705629477612286 <= 0.0693513258226383\n",
      "    2. Newton decrement 0.02850680966590151 <= 0.0693513258226383\n",
      "  Solver did converge at loss = 0.39173137270572234.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467164043844238 <= 0.0693513258226383\n",
      "    2. Newton decrement 0.2358598395679623 <= 0.0693513258226383\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049308300959793 <= 0.0693513258226383\n",
      "    2. Newton decrement 0.029019748613244908 <= 0.0693513258226383\n",
      "  Solver did converge at loss = 0.39137569576703185.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241650695274791 <= 0.0693513258226383\n",
      "    2. Newton decrement 0.23394303721783175 <= 0.0693513258226383\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415369817328272 <= 0.0693513258226383\n",
      "    2. Newton decrement 0.028158375953722288 <= 0.0693513258226383\n",
      "  Solver did converge at loss = 0.3949017264683307.\n",
      "Results: -0.9043098302402824\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 70.58312000153646\n",
      "Tolerance: 0.073474091853123\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384718108952 <= 0.073474091853123\n",
      "    2. Newton decrement 0.2363458800698985 <= 0.073474091853123\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705624571890652 <= 0.073474091853123\n",
      "    2. Newton decrement 0.02850679574576083 <= 0.073474091853123\n",
      "  Solver did converge at loss = 0.3917314096754771.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467163494064664 <= 0.073474091853123\n",
      "    2. Newton decrement 0.23585982850523238 <= 0.073474091853123\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049303548689497 <= 0.073474091853123\n",
      "    2. Newton decrement 0.029019734251483912 <= 0.073474091853123\n",
      "  Solver did converge at loss = 0.39137573259649516.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241650132800429 <= 0.073474091853123\n",
      "    2. Newton decrement 0.23394302516243773 <= 0.073474091853123\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0141536935521653 <= 0.073474091853123\n",
      "    2. Newton decrement 0.02815836054729418 <= 0.073474091853123\n",
      "  Solver did converge at loss = 0.3949017662967277.\n",
      "Results: -0.9043098230916642\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 70.5868303197398\n",
      "Tolerance: 0.0734243139235182\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384720416328 <= 0.0734243139235182\n",
      "    2. Newton decrement 0.23634588011865995 <= 0.0734243139235182\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705624592087912 <= 0.0734243139235182\n",
      "    2. Newton decrement 0.028506795803071333 <= 0.0734243139235182\n",
      "  Solver did converge at loss = 0.3917314095232691.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467163496328156 <= 0.0734243139235182\n",
      "    2. Newton decrement 0.23585982855077892 <= 0.0734243139235182\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504930356825494 <= 0.0734243139235182\n",
      "    2. Newton decrement 0.029019734310612562 <= 0.0734243139235182\n",
      "  Solver did converge at loss = 0.39137573244486484.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416501351161974 <= 0.0734243139235182\n",
      "    2. Newton decrement 0.23394302521207105 <= 0.0734243139235182\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153693571190786 <= 0.0734243139235182\n",
      "    2. Newton decrement 0.028158360610723705 <= 0.0734243139235182\n",
      "  Solver did converge at loss = 0.39490176613275074.\n",
      "Results: -0.9043098230916642\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 71.30563773009831\n",
      "Tolerance: 0.06915225747942726\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405385162899441 <= 0.06915225747942726\n",
      "    2. Newton decrement 0.23634588946959934 <= 0.06915225747942726\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705628465315045 <= 0.06915225747942726\n",
      "    2. Newton decrement 0.028506806793480527 <= 0.06915225747942726\n",
      "  Solver did converge at loss = 0.3917313803344271.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467163930397347 <= 0.06915225747942726\n",
      "    2. Newton decrement 0.23585983728517165 <= 0.06915225747942726\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049307320327584 <= 0.06915225747942726\n",
      "    2. Newton decrement 0.02901974564969385 <= 0.06915225747942726\n",
      "  Solver did converge at loss = 0.3913757033667913.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241650579208253 <= 0.06915225747942726\n",
      "    2. Newton decrement 0.2339430347302045 <= 0.06915225747942726\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153697219713176 <= 0.06915225747942726\n",
      "    2. Newton decrement 0.028158372774598307 <= 0.06915225747942726\n",
      "  Solver did converge at loss = 0.39490173468693224.\n",
      "Results: -0.9043098373824799\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 70.5201322910056\n",
      "Tolerance: 0.07342830361714384\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772333540936993 <= 0.07342830361714384\n",
      "    2. Newton decrement 0.20082113594576784 <= 0.07342830361714384\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009978345281577646 <= 0.07342830361714384\n",
      "    2. Newton decrement 0.030945694736227384 <= 0.07342830361714384\n",
      "  Solver did converge at loss = 0.42530857416790696.\n",
      "Newton iter=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129237893844699 <= 0.07342830361714384\n",
      "    2. Newton decrement 0.2055628573898848 <= 0.07342830361714384\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010489444859747546 <= 0.07342830361714384\n",
      "    2. Newton decrement 0.029641425773669926 <= 0.07342830361714384\n",
      "  Solver did converge at loss = 0.42261579460177084.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203846510818726 <= 0.07342830361714384\n",
      "    2. Newton decrement 0.2048143812071193 <= 0.07342830361714384\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010448499792329409 <= 0.07342830361714384\n",
      "    2. Newton decrement 0.03001422429720186 <= 0.07342830361714384\n",
      "  Solver did converge at loss = 0.4228057049154136.\n",
      "Results: -0.8848956830958032\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 90.99593136808883\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046185717845209\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 73.19358843620493\n",
      "Tolerance: 0.0751319323734472\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405386283698616 <= 0.0751319323734472\n",
      "    2. Newton decrement 0.23634591315525655 <= 0.0751319323734472\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705638276204252 <= 0.0751319323734472\n",
      "    2. Newton decrement 0.028506834632042344 <= 0.0751319323734472\n",
      "  Solver did converge at loss = 0.3917313063996058.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467165029885064 <= 0.0751319323734472\n",
      "    2. Newton decrement 0.23585985940914728 <= 0.0751319323734472\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504931682432397 <= 0.0751319323734472\n",
      "    2. Newton decrement 0.029019774371496998 <= 0.0751319323734472\n",
      "  Solver did converge at loss = 0.3913756297124174.\n",
      "Newton iter=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241651704086126 <= 0.0751319323734472\n",
      "    2. Newton decrement 0.23394305883939737 <= 0.0751319323734472\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153706461439486 <= 0.0751319323734472\n",
      "    2. Newton decrement 0.028158403585792788 <= 0.0751319323734472\n",
      "  Solver did converge at loss = 0.39490165503467534.\n",
      "Results: -0.9043098302402823\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 41.26681562868912\n",
      "Tolerance: 0.05244347102609744\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640535353701047 <= 0.05244347102609744\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470535168626315 <= 0.05244347102609744\n",
      "    2. Newton decrement 0.028506021334552857 <= 0.05244347102609744\n",
      "  Solver did converge at loss = 0.39173346646637136.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467132906347646 <= 0.05244347102609744\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049039194232778 <= 0.05244347102609744\n",
      "    2. Newton decrement 0.029018935305476293 <= 0.05244347102609744\n",
      "  Solver did converge at loss = 0.39137778151100794.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241618840155333 <= 0.05244347102609744\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415343650607769 <= 0.05244347102609744\n",
      "    2. Newton decrement 0.02815750359711254 <= 0.05244347102609744\n",
      "  Solver did converge at loss = 0.3949039818143969.\n",
      "Results: -0.904310180270031\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 58.435048746405\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 8 seconds\n",
      "Results: -0.9046185289077932\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 59.02086929139102\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n",
      "Results: -0.9046185503343859\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 72.25501276708233\n",
      "Tolerance: 0.074660657552211\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.064053857338246 <= 0.074660657552211\n",
      "    2. Newton decrement 0.23634590153487214 <= 0.074660657552211\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705633462877645 <= 0.074660657552211\n",
      "    2. Newton decrement 0.028506820974176193 <= 0.074660657552211\n",
      "  Solver did converge at loss = 0.3917313426727167.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467164490466498 <= 0.074660657552211\n",
      "    2. Newton decrement 0.2358598485549348 <= 0.074660657552211\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049312161563739 <= 0.074660657552211\n",
      "    2. Newton decrement 0.029019760280293527 <= 0.074660657552211\n",
      "  Solver did converge at loss = 0.39137566584796085.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241651152210482 <= 0.074660657552211\n",
      "    2. Newton decrement 0.23394304701121607 <= 0.074660657552211\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153701927347603 <= 0.074660657552211\n",
      "    2. Newton decrement 0.028158388469477855 <= 0.074660657552211\n",
      "  Solver did converge at loss = 0.39490169411291254.\n",
      "Results: -0.9043098230980848\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 5.109089841600911\n",
      "Tolerance: 0.0674268389717327\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8809546766112514\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.01513809342867372\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 11 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 12 epochs took 0 seconds\n",
      "convergence after 12 epochs took 0 seconds\n",
      "Results: -0.904654466005987\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.014985723375983582\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8971830968206097\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.13382642181218857\n",
      "Tolerance: 0.0026823110994017626\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 10 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 12 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 11 epochs took 0 seconds\n",
      "Results: -0.8850916442142082\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 82.27851116548153\n",
      "Tolerance: 0.07683471546475794\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044545456301495\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 58.48334298159399\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 4 seconds\n",
      "Results: -0.9046185217634554\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 57.55501415590799\n",
      "Tolerance: 0.1\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405374782069702 <= 0.1\n",
      "    2. Newton decrement 0.2363456700899254 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705537603591556 <= 0.1\n",
      "    2. Newton decrement 0.02850654896100469 <= 0.1\n",
      "  Solver did converge at loss = 0.3917320651056399.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467153747010318 <= 0.1\n",
      "    2. Newton decrement 0.2358596323708752 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049219300267194 <= 0.1\n",
      "    2. Newton decrement 0.029019479640957822 <= 0.1\n",
      "  Solver did converge at loss = 0.3913763855319321.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416401608237825 <= 0.1\n",
      "    2. Newton decrement 0.23394281143026704 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415361163016878 <= 0.1\n",
      "    2. Newton decrement 0.028158087428213473 <= 0.1\n",
      "  Solver did converge at loss = 0.39490247237431536.\n",
      "Results: -0.9043098302360021\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.0518847875020972\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890853709743\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 20.25635466305061\n",
      "Tolerance: 0.004884871792572667\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8869855382571158\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 61.4080898590752\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n",
      "Results: -0.9046185074833404\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 63.37014657266515\n",
      "Tolerance: 0.1\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405379721765819 <= 0.1\n",
      "    2. Newton decrement 0.2363457744820438 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705580838461416 <= 0.1\n",
      "    2. Newton decrement 0.02850667164825271 <= 0.1\n",
      "  Solver did converge at loss = 0.3917317392614591.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467158592741055 <= 0.1\n",
      "    2. Newton decrement 0.2358597298794267 <= 0.1\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049261183111977 <= 0.1\n",
      "    2. Newton decrement 0.02901960621789182 <= 0.1\n",
      "  Solver did converge at loss = 0.39137606092977356.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241645118340249 <= 0.1\n",
      "    2. Newton decrement 0.2339429176872679 <= 0.1\n",
      "Newton iter=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153652356148514 <= 0.1\n",
      "    2. Newton decrement 0.02815822320371577 <= 0.1\n",
      "  Solver did converge at loss = 0.3949021213587839.\n",
      "Results: -0.9043098516732958\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 89.45038819737829\n",
      "Tolerance: 0.1\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 5 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n",
      "convergence after 6 epochs took 0 seconds\n",
      "Results: -0.9033689044321722\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 15.189316553161879\n",
      "Tolerance: 0.0780923800561235\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044541955597372\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 22.272951403647156\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8869515345040496\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 67.31758343225252\n",
      "Tolerance: 0.06676358925576487\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.037723256282610015 <= 0.06676358925576487\n",
      "    2. Newton decrement 0.20082069684809803 <= 0.06676358925576487\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00997819642023191 <= 0.06676358925576487\n",
      "    2. Newton decrement 0.03094488095722009 <= 0.06676358925576487\n",
      "  Solver did converge at loss = 0.4253104801665296.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129228797904971 <= 0.06676358925576487\n",
      "    2. Newton decrement 0.20556253504068095 <= 0.06676358925576487\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01048929070989938 <= 0.06676358925576487\n",
      "    2. Newton decrement 0.02964075475236432 <= 0.06676358925576487\n",
      "  Solver did converge at loss = 0.4226173215425922.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203837664126936 <= 0.06676358925576487\n",
      "    2. Newton decrement 0.2048140714646127 <= 0.06676358925576487\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010448357577888293 <= 0.06676358925576487\n",
      "    2. Newton decrement 0.030013619472023013 <= 0.06676358925576487\n",
      "  Solver did converge at loss = 0.4228071050722864.\n",
      "Results: -0.8848969175499387\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 66.86778866715909\n",
      "Tolerance: 0.06633600925388297\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772324455947464 <= 0.06633600925388297\n",
      "    2. Newton decrement 0.20082063181596552 <= 0.06633600925388297\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009978174336088571 <= 0.06633600925388297\n",
      "    2. Newton decrement 0.030944760478847276 <= 0.06633600925388297\n",
      "  Solver did converge at loss = 0.4253107623648205.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.041292274506591634 <= 0.06633600925388297\n",
      "    2. Newton decrement 0.20556248729537638 <= 0.06633600925388297\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010489267878288234 <= 0.06633600925388297\n",
      "    2. Newton decrement 0.02964065536970055 <= 0.06633600925388297\n",
      "  Solver did converge at loss = 0.4226175476945255.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203836353788232 <= 0.06633600925388297\n",
      "    2. Newton decrement 0.204814025586396 <= 0.06633600925388297\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010448336514357014 <= 0.06633600925388297\n",
      "    2. Newton decrement 0.03001352989191119 <= 0.06633600925388297\n",
      "  Solver did converge at loss = 0.42280731244984804.\n",
      "Results: -0.8848970959121251\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 61.544634889124495\n",
      "Tolerance: 0.06553324909481188\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772309274046322 <= 0.06553324909481188\n",
      "    2. Newton decrement 0.2008197901596061 <= 0.06553324909481188\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009977887658889108 <= 0.06553324909481188\n",
      "    2. Newton decrement 0.03094320228100376 <= 0.06553324909481188\n",
      "  Solver did converge at loss = 0.42531441259729263.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129210012049792 <= 0.06553324909481188\n",
      "    2. Newton decrement 0.20556186927283587 <= 0.06553324909481188\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010488972355408244 <= 0.06553324909481188\n",
      "    2. Newton decrement 0.029639369103665082 <= 0.06553324909481188\n",
      "  Solver did converge at loss = 0.4226204747251159.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203819392661018 <= 0.06553324909481188\n",
      "    2. Newton decrement 0.2048134317276737 <= 0.06553324909481188\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010448063883491954 <= 0.06553324909481188\n",
      "    2. Newton decrement 0.030012370460394094 <= 0.06553324909481188\n",
      "  Solver did converge at loss = 0.4228099965656531.\n",
      "Results: -0.8848994228347232\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 63.661236317815586\n",
      "Tolerance: 0.06541301755839107\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 4 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.8849603825967803\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 54.64125702276259\n",
      "Tolerance: 0.06245587460989226\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 6 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 7 epochs took 0 seconds\n",
      "convergence after 6 epochs took 0 seconds\n",
      "Results: -0.8863763054251507\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.014721455629290666\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890853709743\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 73.48909421991218\n",
      "Tolerance: 0.058785105757349236\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045891639779517\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 16.019267147066216\n",
      "Tolerance: 0.001629796430191634\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8870061238894896\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 70.04788573525641\n",
      "Tolerance: 1e-05\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9046187575843883\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 15.419616659136464\n",
      "Tolerance: 0.0020265450297636263\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8870729792065156\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 46.32648529403533\n",
      "Tolerance: 0.025984426145083388\n",
      "Solver: lbfgs\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Results: -0.8830669913873428\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 15.044423498797878\n",
      "Tolerance: 0.002238131355982754\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8870726541646151\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 80.99095715853969\n",
      "Tolerance: 0.06465510038579982\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044545456301495\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 41.09067589972011\n",
      "Tolerance: 1e-05\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9046187360251032\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 14.940178823096055\n",
      "Tolerance: 0.00218260096272527\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8870253541506736\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 59.745338600540414\n",
      "Tolerance: 1e-05\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n",
      "Results: -0.9046185431964687\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 87.49707182237202\n",
      "Tolerance: 0.061059847457532325\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "Results: -0.9045534239142428\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 82.52040800085565\n",
      "Tolerance: 0.06785028445156988\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044545527744873\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 15.478025019069536\n",
      "Tolerance: 0.0020210733889474202\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8870731716500573\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 24.870341708629475\n",
      "Tolerance: 0.08088344699776008\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640530405695487 <= 0.08088344699776008\n",
      "    2. Newton decrement 0.2363441752832806 <= 0.08088344699776008\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014704918875396678 <= 0.08088344699776008\n",
      "    2. Newton decrement 0.028504792718046536 <= 0.08088344699776008\n",
      "  Solver did converge at loss = 0.39173672989700103.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.064670843697851 <= 0.08088344699776008\n",
      "    2. Newton decrement 0.23585823617027604 <= 0.08088344699776008\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504861989525172 <= 0.08088344699776008\n",
      "    2. Newton decrement 0.029017667899182017 <= 0.08088344699776008\n",
      "  Solver did converge at loss = 0.3913810321576936.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241569190500225 <= 0.08088344699776008\n",
      "    2. Newton decrement 0.23394129003544975 <= 0.08088344699776008\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415302885042998 <= 0.08088344699776008\n",
      "    2. Newton decrement 0.028156144620625666 <= 0.08088344699776008\n",
      "  Solver did converge at loss = 0.39490749583785123.\n",
      "Results: -0.9043104445591652\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 62.47465404499515\n",
      "Tolerance: 0.0925514009749758\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.904149782192938\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 70.50402277568013\n",
      "Tolerance: 1e-05\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772333502941419 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00997834456759362 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.002210184901676541 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.000968570471144535 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00037954712158835835 <= 1e-05\n",
      "Newton iter=6\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00013712776278665406 <= 1e-05\n",
      "Newton iter=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 4.2952893082360416e-05 <= 1e-05\n",
      "Newton iter=8\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.0061114989908665e-05 <= 1e-05\n",
      "Newton iter=9\n",
      "  Check Convergence\n",
      "    1. max |gradient| 1.203852609679007e-06 <= 1e-05\n",
      "    2. Newton decrement 1.4678728432661257e-06 <= 1e-05\n",
      "  Solver did converge at loss = 0.41225063959267183.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129237850156683 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010489444119353531 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017232818657339707 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0007795970483863018 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0003019113390165685 <= 1e-05\n",
      "Newton iter=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.00010323479911030983 <= 1e-05\n",
      "Newton iter=7\n",
      "  Check Convergence\n",
      "    1. max |gradient| 3.044158593289853e-05 <= 1e-05\n",
      "Newton iter=8\n",
      "  Check Convergence\n",
      "    1. max |gradient| 6.3347020211358684e-06 <= 1e-05\n",
      "    2. Newton decrement 7.982922328241625e-06 <= 1e-05\n",
      "  Solver did converge at loss = 0.4121360101698468.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.042038464683281394 <= 1e-05\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010448499109254635 <= 1e-05\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017278375947280353 <= 1e-05\n",
      "Newton iter=4\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0007958974558248469 <= 1e-05\n",
      "Newton iter=5\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00031060191808487785 <= 1e-05\n",
      "Newton iter=6\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00010669541191173255 <= 1e-05\n",
      "Newton iter=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 3.1674834020776685e-05 <= 1e-05\n",
      "Newton iter=8\n",
      "  Check Convergence\n",
      "    1. max |gradient| 6.6649922134658784e-06 <= 1e-05\n",
      "    2. Newton decrement 8.38596914162814e-06 <= 1e-05\n",
      "  Solver did converge at loss = 0.4120534290799218.\n",
      "Results: -0.8868384341016516\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 28.213237621176308\n",
      "Tolerance: 0.0062130656247806225\n",
      "Solver: newton-cg\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8813855683368518\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 50.52093013129148\n",
      "Tolerance: 0.029933360998733963\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.064053672875674 <= 0.029933360998733963\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705472012853979 <= 0.029933360998733963\n",
      "    2. Newton decrement 0.028506362826252872 <= 0.029933360998733963\n",
      "  Solver did converge at loss = 0.3917325594665311.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646714639511617 <= 0.029933360998733963\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049155760216388 <= 0.029933360998733963\n",
      "    2. Newton decrement 0.029019287608139967 <= 0.029933360998733963\n",
      "  Solver did converge at loss = 0.3913768780017472.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416326394577136 <= 0.029933360998733963\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153549846384629 <= 0.029933360998733963\n",
      "    2. Newton decrement 0.02815788145046021 <= 0.029933360998733963\n",
      "  Solver did converge at loss = 0.39490300489502916.\n",
      "Results: -0.9043100516698104\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 84.004491859043\n",
      "Tolerance: 0.062081136284558455\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.904557174042745\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.01831400152787337\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890853709743\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 45.1386573693032\n",
      "Tolerance: 0.00021532934894681957\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 11 seconds\n",
      "Results: -0.8869810006464377\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 81.88393937534804\n",
      "Tolerance: 0.06179183723061507\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890068282025\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 51.54962660046029\n",
      "Tolerance: 0.07091491408562174\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9044544241828273\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 48.862108033094785\n",
      "Tolerance: 0.03032761652796554\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772259688962876 <= 0.03032761652796554\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.00997694276885335 <= 0.03032761652796554\n",
      "    2. Newton decrement 0.030938139058025456 <= 0.03032761652796554\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0022066191631763803 <= 0.03032761652796554\n",
      "    2. Newton decrement 0.007663053208307073 <= 0.03032761652796554\n",
      "  Solver did converge at loss = 0.415978322734479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129153168263623 <= 0.03032761652796554\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01048800914607137 <= 0.03032761652796554\n",
      "    2. Newton decrement 0.029635178034731934 <= 0.03032761652796554\n",
      "  Solver did converge at loss = 0.42263001252374127.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.042037641022153974 <= 0.03032761652796554\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010447175373108119 <= 0.03032761652796554\n",
      "    2. Newton decrement 0.030008592200949133 <= 0.03032761652796554\n",
      "  Solver did converge at loss = 0.42281874381726386.\n",
      "Results: -0.8852032288209538\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.07912467635149431\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 4 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 5 epochs took 0 seconds\n",
      "Results: -0.8332458536575765\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 17.673493805821042\n",
      "Tolerance: 0.0022097965622293303\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8870802087442456\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 54.335904563063785\n",
      "Tolerance: 0.1\n",
      "Solver: saga\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.8837109398029858\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.011738830361678675\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0377238249797234 <= 0.011738830361678675\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009979258476086106 <= 0.011738830361678675\n",
      "    2. Newton decrement 0.030950753145539044 <= 0.011738830361678675\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0022125388922124064 <= 0.011738830361678675\n",
      "    2. Newton decrement 0.007678255168268176 <= 0.011738830361678675\n",
      "  Solver did converge at loss = 0.4159271956075463.\n",
      "Newton iter=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.04129294271005852 <= 0.011738830361678675\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01049040036913165 <= 0.011738830361678675\n",
      "    2. Newton decrement 0.029645586301486122 <= 0.011738830361678675\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0017256441127322317 <= 0.011738830361678675\n",
      "    2. Newton decrement 0.006531305744895619 <= 0.011738830361678675\n",
      "  Solver did converge at loss = 0.41474805653476626.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.04203901340427597 <= 0.011738830361678675\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.010449381395664238 <= 0.011738830361678675\n",
      "    2. Newton decrement 0.030017973988133384 <= 0.011738830361678675\n",
      "Newton iter=3\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.001730075397076026 <= 0.011738830361678675\n",
      "    2. Newton decrement 0.006714017883133291 <= 0.011738830361678675\n",
      "  Solver did converge at loss = 0.4147216523557071.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.8863074965930794\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 100.0\n",
      "Tolerance: 0.021331819205274567\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.9045890853709743\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 10.570860884403535\n",
      "Tolerance: 0.08391294524139571\n",
      "Solver: sag\n",
      "Oversampling Method: none\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 1 seconds\n",
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n",
      "Results: -0.9042006618068976\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 28.87434737584867\n",
      "Tolerance: 0.07031879221750308\n",
      "Solver: saga\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "convergence after 4 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "Results: -0.9043429114760242\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 8.053992093193612\n",
      "Tolerance: 0.06577654324674723\n",
      "Solver: liblinear\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8809609427560776\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.06632726709638918\n",
      "Solver: sag\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 2 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 2 epochs took 0 seconds\n",
      "rescaling...\n",
      "rescaling...\n",
      "convergence after 2 epochs took 0 seconds\n",
      "Results: -0.8334959926162843\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 66.89932805295356\n",
      "Tolerance: 0.0671020489508036\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: ada\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.03772324538665842 <= 0.0671020489508036\n",
      "    2. Newton decrement 0.20082063640443473 <= 0.0671020489508036\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.009978175894592356 <= 0.0671020489508036\n",
      "    2. Newton decrement 0.03094476897905079 <= 0.0671020489508036\n",
      "  Solver did converge at loss = 0.42531074245450723.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0412922754571757 <= 0.0671020489508036\n",
      "    2. Newton decrement 0.20556249066417365 <= 0.0671020489508036\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01048926948922897 <= 0.0671020489508036\n",
      "    2. Newton decrement 0.029640662381853235 <= 0.0671020489508036\n",
      "  Solver did converge at loss = 0.4226175317378833.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.042038364462426536 <= 0.0671020489508036\n",
      "    2. Newton decrement 0.20481402882345595 <= 0.0671020489508036\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01044833800054371 <= 0.0671020489508036\n",
      "    2. Newton decrement 0.030013536212435694 <= 0.0671020489508036\n",
      "  Solver did converge at loss = 0.42280729781784576.\n",
      "Results: -0.8848970888715133\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 0.001\n",
      "Tolerance: 0.09225497727712387\n",
      "Solver: liblinear\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "[LibLinear][LibLinear][LibLinear]Results: -0.8960656331654512\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 69.94515235284136\n",
      "Tolerance: 0.06942751861338181\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384317730585 <= 0.06942751861338181\n",
      "    2. Newton decrement 0.2363458716087436 <= 0.06942751861338181\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705621067241539 <= 0.06942751861338181\n",
      "    2. Newton decrement 0.02850678580117313 <= 0.06942751861338181\n",
      "  Solver did converge at loss = 0.39173143608680266.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467163101299744 <= 0.06942751861338181\n",
      "    2. Newton decrement 0.2358598206019596 <= 0.06942751861338181\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049300153664102 <= 0.06942751861338181\n",
      "    2. Newton decrement 0.02901972399141452 <= 0.06942751861338181\n",
      "  Solver did converge at loss = 0.3913757589075682.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0624164973096685 <= 0.06942751861338181\n",
      "    2. Newton decrement 0.23394301655000538 <= 0.06942751861338181\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153690250840716 <= 0.06942751861338181\n",
      "    2. Newton decrement 0.028158349540955765 <= 0.06942751861338181\n",
      "  Solver did converge at loss = 0.3949017947501559.\n",
      "Results: -0.9043098230895241\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 69.8093086457697\n",
      "Tolerance: 0.06932145087212371\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384231532385 <= 0.06932145087212371\n",
      "    2. Newton decrement 0.2363458697871245 <= 0.06932145087212371\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705620312721423 <= 0.06932145087212371\n",
      "    2. Newton decrement 0.028506783660187017 <= 0.06932145087212371\n",
      "  Solver did converge at loss = 0.39173144177294217.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467163016740672 <= 0.06932145087212371\n",
      "    2. Newton decrement 0.23585981890044805 <= 0.06932145087212371\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049299422744765 <= 0.06932145087212371\n",
      "    2. Newton decrement 0.029019721782509236 <= 0.06932145087212371\n",
      "  Solver did converge at loss = 0.3913757645721213.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416496444554166 <= 0.06932145087212371\n",
      "    2. Newton decrement 0.23394301469581844 <= 0.06932145087212371\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153689540094917 <= 0.06932145087212371\n",
      "    2. Newton decrement 0.028158347171389802 <= 0.06932145087212371\n",
      "  Solver did converge at loss = 0.39490180087592996.\n",
      "Results: -0.9043098230895241\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.77272632982425\n",
      "Tolerance: 0.06929508432072583\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384208262088 <= 0.06929508432072583\n",
      "    2. Newton decrement 0.2363458692953556 <= 0.06929508432072583\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705620109029427 <= 0.06929508432072583\n",
      "    2. Newton decrement 0.02850678308220116 <= 0.06929508432072583\n",
      "  Solver did converge at loss = 0.39173144330798637.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162993912894 <= 0.06929508432072583\n",
      "    2. Newton decrement 0.23585981844110376 <= 0.06929508432072583\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049299225424093 <= 0.06929508432072583\n",
      "    2. Newton decrement 0.029019721186187928 <= 0.06929508432072583\n",
      "  Solver did converge at loss = 0.39137576610133773.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649621100578 <= 0.06929508432072583\n",
      "    2. Newton decrement 0.23394301419525743 <= 0.06929508432072583\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153689348220382 <= 0.06929508432072583\n",
      "    2. Newton decrement 0.028158346531696427 <= 0.06929508432072583\n",
      "  Solver did converge at loss = 0.3949018025296582.\n",
      "Results: -0.9043098302338618\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.75538567599536\n",
      "Tolerance: 0.06928482718433966\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384197223056 <= 0.06928482718433966\n",
      "    2. Newton decrement 0.23634586906206828 <= 0.06928482718433966\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705620012401268 <= 0.06928482718433966\n",
      "    2. Newton decrement 0.028506782808014122 <= 0.06928482718433966\n",
      "  Solver did converge at loss = 0.39173144403618637.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162983083762 <= 0.06928482718433966\n",
      "    2. Newton decrement 0.23585981822319851 <= 0.06928482718433966\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049299131818373 <= 0.06928482718433966\n",
      "    2. Newton decrement 0.029019720903302768 <= 0.06928482718433966\n",
      "  Solver did converge at loss = 0.3913757668267731.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649610021433 <= 0.06928482718433966\n",
      "    2. Newton decrement 0.23394301395779937 <= 0.06928482718433966\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153689257198142 <= 0.06928482718433966\n",
      "    2. Newton decrement 0.02815834622823639 <= 0.06928482718433966\n",
      "  Solver did converge at loss = 0.3949018033141598.\n",
      "Results: -0.9043098302338618\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 69.73865051819465\n",
      "Tolerance: 0.06927431765012626\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384186564257 <= 0.06927431765012626\n",
      "    2. Newton decrement 0.23634586883681702 <= 0.06927431765012626\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619919101564 <= 0.06927431765012626\n",
      "    2. Newton decrement 0.028506782543271807 <= 0.06927431765012626\n",
      "  Solver did converge at loss = 0.39173144473930255.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646716297262766 <= 0.06927431765012626\n",
      "    2. Newton decrement 0.23585981801279887 <= 0.06927431765012626\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049299041437095 <= 0.06927431765012626\n",
      "    2. Newton decrement 0.029019720630162008 <= 0.06927431765012626\n",
      "  Solver did converge at loss = 0.39137576752722.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649599323908 <= 0.06927431765012626\n",
      "    2. Newton decrement 0.233943013728521 <= 0.06927431765012626\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153689169311383 <= 0.06927431765012626\n",
      "    2. Newton decrement 0.028158345935229423 <= 0.06927431765012626\n",
      "  Solver did converge at loss = 0.3949018040716382.\n",
      "Results: -0.9043098302338618\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.73031325351296\n",
      "Tolerance: 0.06926992793037819\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384181252262 <= 0.06926992793037819\n",
      "    2. Newton decrement 0.23634586872455893 <= 0.06926992793037819\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619872604086 <= 0.06926992793037819\n",
      "    2. Newton decrement 0.02850678241133279 <= 0.06926992793037819\n",
      "  Solver did converge at loss = 0.3917314450897129.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162967416669 <= 0.06926992793037819\n",
      "    2. Newton decrement 0.23585981790794255 <= 0.06926992793037819\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298996393918 <= 0.06926992793037819\n",
      "    2. Newton decrement 0.02901972049403748 <= 0.06926992793037819\n",
      "  Solver did converge at loss = 0.39137576787629996.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649593992608 <= 0.06926992793037819\n",
      "    2. Newton decrement 0.23394301361425593 <= 0.06926992793037819\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153689125511494 <= 0.06926992793037819\n",
      "    2. Newton decrement 0.02815834578920422 <= 0.06926992793037819\n",
      "  Solver did converge at loss = 0.3949018044491409.\n",
      "Results: -0.9043098302338618\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.72125567788085\n",
      "Tolerance: 0.06926539033849446\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384175479892 <= 0.06926539033849446\n",
      "    2. Newton decrement 0.2363458686025717 <= 0.06926539033849446\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619822076767 <= 0.06926539033849446\n",
      "    2. Newton decrement 0.028506782267958948 <= 0.06926539033849446\n",
      "  Solver did converge at loss = 0.3917314454704926.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162961754068 <= 0.06926539033849446\n",
      "    2. Newton decrement 0.23585981779399864 <= 0.06926539033849446\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298947447066 <= 0.06926539033849446\n",
      "    2. Newton decrement 0.029019720346115396 <= 0.06926539033849446\n",
      "  Solver did converge at loss = 0.3913757682556339.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649588199268 <= 0.06926539033849446\n",
      "    2. Newton decrement 0.23394301349008792 <= 0.06926539033849446\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153689077915572 <= 0.06926539033849446\n",
      "    2. Newton decrement 0.028158345630523423 <= 0.06926539033849446\n",
      "  Solver did converge at loss = 0.3949018048593609.\n",
      "Results: -0.9043098302338618\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.71190340577597\n",
      "Tolerance: 0.06926054742087911\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384169518126 <= 0.06926054742087911\n",
      "    2. Newton decrement 0.23634586847658257 <= 0.06926054742087911\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619769891624 <= 0.06926054742087911\n",
      "    2. Newton decrement 0.028506782119881204 <= 0.06926054742087911\n",
      "  Solver did converge at loss = 0.39173144586376496.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162955905678 <= 0.06926054742087911\n",
      "    2. Newton decrement 0.23585981767631647 <= 0.06926054742087911\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298896894225 <= 0.06926054742087911\n",
      "    2. Newton decrement 0.029019720193340193 <= 0.06926054742087911\n",
      "  Solver did converge at loss = 0.3913757686474133.\n",
      "Newton iter=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416495822158476 <= 0.06926054742087911\n",
      "    2. Newton decrement 0.23394301336184603 <= 0.06926054742087911\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153689028758062 <= 0.06926054742087911\n",
      "    2. Newton decrement 0.028158345466636543 <= 0.06926054742087911\n",
      "  Solver did converge at loss = 0.3949018052830396.\n",
      "Results: -0.9043098302338618\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 69.70173973803696\n",
      "Tolerance: 0.06925555976441698\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384163037318 <= 0.06925555976441698\n",
      "    2. Newton decrement 0.23634586833962415 <= 0.06925555976441698\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619713163105 <= 0.06925555976441698\n",
      "    2. Newton decrement 0.028506781958911317 <= 0.06925555976441698\n",
      "  Solver did converge at loss = 0.3917314462912771.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646716294954811 <= 0.06925555976441698\n",
      "    2. Newton decrement 0.23585981754838825 <= 0.06925555976441698\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298841940173 <= 0.06925555976441698\n",
      "    2. Newton decrement 0.029019720027263888 <= 0.06925555976441698\n",
      "  Solver did converge at loss = 0.39137576907330224.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649575711487 <= 0.06925555976441698\n",
      "    2. Newton decrement 0.23394301322243904 <= 0.06925555976441698\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688975320756 <= 0.06925555976441698\n",
      "    2. Newton decrement 0.0281583452884811 <= 0.06925555976441698\n",
      "  Solver did converge at loss = 0.39490180574360506.\n",
      "Results: -0.9043098302338618\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.69187067264184\n",
      "Tolerance: 0.06925068075274311\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384156742548 <= 0.06925068075274311\n",
      "    2. Newton decrement 0.23634586820659728 <= 0.06925068075274311\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619658063138 <= 0.06925068075274311\n",
      "    2. Newton decrement 0.028506781802562407 <= 0.06925068075274311\n",
      "  Solver did converge at loss = 0.39173144670651666.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162943373049 <= 0.06925068075274311\n",
      "    2. Newton decrement 0.23585981742413253 <= 0.06925068075274311\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504929878856369 <= 0.06925068075274311\n",
      "    2. Newton decrement 0.029019719865955067 <= 0.06925068075274311\n",
      "  Solver did converge at loss = 0.39137576948696534.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0624164956939384 <= 0.06925068075274311\n",
      "    2. Newton decrement 0.2339430130870341 <= 0.06925068075274311\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688923417404 <= 0.06925068075274311\n",
      "    2. Newton decrement 0.028158345115439968 <= 0.06925068075274311\n",
      "  Solver did converge at loss = 0.3949018061909492.\n",
      "Results: -0.9043098373781996\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.69187242492335\n",
      "Tolerance: 0.06925117670754263\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384156743668 <= 0.06925117670754263\n",
      "    2. Newton decrement 0.23634586820662098 <= 0.06925117670754263\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619658072912 <= 0.06925117670754263\n",
      "    2. Newton decrement 0.028506781802590142 <= 0.06925117670754263\n",
      "  Solver did converge at loss = 0.39173144670644294.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162943374144 <= 0.06925117670754263\n",
      "    2. Newton decrement 0.23585981742415457 <= 0.06925117670754263\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298788573168 <= 0.06925117670754263\n",
      "    2. Newton decrement 0.029019719865983718 <= 0.06925117670754263\n",
      "  Solver did converge at loss = 0.3913757694868918.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649569394973 <= 0.06925117670754263\n",
      "    2. Newton decrement 0.2339430130870581 <= 0.06925117670754263\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688923426604 <= 0.06925117670754263\n",
      "    2. Newton decrement 0.0281583451154707 <= 0.06925117670754263\n",
      "  Solver did converge at loss = 0.39490180619086973.\n",
      "Results: -0.9043098373781996\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.67956464769433\n",
      "Tolerance: 0.06924417040695448\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640538414889092 <= 0.06924417040695448\n",
      "    2. Newton decrement 0.23634586804066968 <= 0.06924417040695448\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470561958933539 <= 0.06924417040695448\n",
      "    2. Newton decrement 0.02850678160754433 <= 0.06924417040695448\n",
      "  Solver did converge at loss = 0.39173144722445563.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162935670719 <= 0.06924417040695448\n",
      "    2. Newton decrement 0.2358598172691453 <= 0.06924417040695448\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298721985724 <= 0.06924417040695448\n",
      "    2. Newton decrement 0.029019719664750414 <= 0.06924417040695448\n",
      "  Solver did converge at loss = 0.391375770002938.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649561513695 <= 0.06924417040695448\n",
      "    2. Newton decrement 0.23394301291813985 <= 0.06924417040695448\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688858677132 <= 0.06924417040695448\n",
      "    2. Newton decrement 0.028158344899601277 <= 0.06924417040695448\n",
      "  Solver did converge at loss = 0.3949018067489331.\n",
      "Results: -0.9043098373781996\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.67564353808645\n",
      "Tolerance: 0.06924354640566273\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384146388558 <= 0.06924354640566273\n",
      "    2. Newton decrement 0.2363458679877871 <= 0.06924354640566273\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619567431466 <= 0.06924354640566273\n",
      "    2. Newton decrement 0.02850678154539059 <= 0.06924354640566273\n",
      "  Solver did converge at loss = 0.39173144738952675.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162933215936 <= 0.06924354640566273\n",
      "    2. Newton decrement 0.23585981721974963 <= 0.06924354640566273\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298700766841 <= 0.06924354640566273\n",
      "    2. Newton decrement 0.029019719600625007 <= 0.06924354640566273\n",
      "  Solver did converge at loss = 0.39137577016738234.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649559002236 <= 0.06924354640566273\n",
      "    2. Newton decrement 0.2339430128643119 <= 0.06924354640566273\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688838043826 <= 0.06924354640566273\n",
      "    2. Newton decrement 0.028158344830811928 <= 0.06924354640566273\n",
      "  Solver did converge at loss = 0.39490180692676674.\n",
      "Results: -0.9043098373781996\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 81.06450666341743\n",
      "Tolerance: 0.07605774337790003\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405390393904378 <= 0.07605774337790003\n",
      "    2. Newton decrement 0.23634600001492553 <= 0.07605774337790003\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705674255988038 <= 0.07605774337790003\n",
      "    2. Newton decrement 0.028506936723328807 <= 0.07605774337790003\n",
      "  Solver did converge at loss = 0.39173103526288156.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467169061947456 <= 0.07605774337790003\n",
      "    2. Newton decrement 0.23585994054199955 <= 0.07605774337790003\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049351678527919 <= 0.07605774337790003\n",
      "    2. Newton decrement 0.02901987970259185 <= 0.07605774337790003\n",
      "  Solver did converge at loss = 0.39137535960260944.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241655829289346 <= 0.07605774337790003\n",
      "    2. Newton decrement 0.2339431472527131 <= 0.07605774337790003\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153740354091233 <= 0.07605774337790003\n",
      "    2. Newton decrement 0.028158516581696345 <= 0.07605774337790003\n",
      "  Solver did converge at loss = 0.39490136292394845.\n",
      "Results: -0.9043098730934681\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.71018312292111\n",
      "Tolerance: 0.06926426577431528\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384168421327 <= 0.06926426577431528\n",
      "    2. Newton decrement 0.23634586845340405 <= 0.06926426577431528\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619760290965 <= 0.06926426577431528\n",
      "    2. Newton decrement 0.02850678209263909 <= 0.06926426577431528\n",
      "  Solver did converge at loss = 0.3917314459361161.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162954829737 <= 0.06926426577431528\n",
      "    2. Newton decrement 0.23585981765466618 <= 0.06926426577431528\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298887593984 <= 0.06926426577431528\n",
      "    2. Newton decrement 0.02901972016523382 <= 0.06926426577431528\n",
      "  Solver did converge at loss = 0.39137576871948976.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649581115065 <= 0.06926426577431528\n",
      "    2. Newton decrement 0.23394301333825315 <= 0.06926426577431528\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153689019714515 <= 0.06926426577431528\n",
      "    2. Newton decrement 0.028158345436485932 <= 0.06926426577431528\n",
      "  Solver did converge at loss = 0.3949018053609845.\n",
      "Results: -0.9043098302338618\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.69937199928856\n",
      "Tolerance: 0.06925871474976045\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384161527276 <= 0.06925871474976045\n",
      "    2. Newton decrement 0.23634586830771237 <= 0.06925871474976045\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470561969994526 <= 0.06925871474976045\n",
      "    2. Newton decrement 0.028506781921404878 <= 0.06925871474976045\n",
      "  Solver did converge at loss = 0.3917314463908887.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162948066776 <= 0.06925871474976045\n",
      "    2. Newton decrement 0.23585981751858068 <= 0.06925871474976045\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298829135764 <= 0.06925871474976045\n",
      "    2. Newton decrement 0.02901971998856758 <= 0.06925871474976045\n",
      "  Solver did converge at loss = 0.3913757691725357.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416495741959545 <= 0.06925871474976045\n",
      "    2. Newton decrement 0.23394301318995692 <= 0.06925871474976045\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688962869662 <= 0.06925871474976045\n",
      "    2. Newton decrement 0.028158345246970376 <= 0.06925871474976045\n",
      "  Solver did converge at loss = 0.39490180585091816.\n",
      "Results: -0.9043098373781996\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.68177479712529\n",
      "Tolerance: 0.06924919933470768\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384150301274 <= 0.06924919933470768\n",
      "    2. Newton decrement 0.23634586807047434 <= 0.06924919933470768\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619601680653 <= 0.06924919933470768\n",
      "    2. Newton decrement 0.028506781642574437 <= 0.06924919933470768\n",
      "  Solver did converge at loss = 0.3917314471314209.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646716293705425 <= 0.06924919933470768\n",
      "    2. Newton decrement 0.23585981729698502 <= 0.06924919933470768\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298733944718 <= 0.06924919933470768\n",
      "    2. Newton decrement 0.02901971970089181 <= 0.06924919933470768\n",
      "  Solver did converge at loss = 0.39137576991025635.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649562929172 <= 0.06924919933470768\n",
      "    2. Newton decrement 0.23394301294847736 <= 0.06924919933470768\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01415368887030611 <= 0.06924919933470768\n",
      "    2. Newton decrement 0.02815834493837131 <= 0.06924919933470768\n",
      "  Solver did converge at loss = 0.3949018066487053.\n",
      "Results: -0.9043098373781996\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 69.68724853905913\n",
      "Tolerance: 0.06925305446516314\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384153793818 <= 0.06925305446516314\n",
      "    2. Newton decrement 0.23634586814428182 <= 0.06925305446516314\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619632251978 <= 0.06925305446516314\n",
      "    2. Newton decrement 0.02850678172932181 <= 0.06925305446516314\n",
      "  Solver did converge at loss = 0.39173144690103273.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162940480375 <= 0.06925305446516314\n",
      "    2. Newton decrement 0.2358598173659259 <= 0.06925305446516314\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298763559796 <= 0.06925305446516314\n",
      "    2. Newton decrement 0.029019719790391082 <= 0.06925305446516314\n",
      "  Solver did converge at loss = 0.3913757696807429.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649566434407 <= 0.06925305446516314\n",
      "    2. Newton decrement 0.2339430130236044 <= 0.06925305446516314\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688899103707 <= 0.06925305446516314\n",
      "    2. Newton decrement 0.02815834503438007 <= 0.06925305446516314\n",
      "  Solver did converge at loss = 0.3949018064005044.\n",
      "Results: -0.9043098373781996\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 81.20218448624415\n",
      "Tolerance: 0.07604412693230983\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405390458710167 <= 0.07604412693230983\n",
      "    2. Newton decrement 0.23634600138443784 <= 0.07604412693230983\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705674823297795 <= 0.07604412693230983\n",
      "    2. Newton decrement 0.028506938333024475 <= 0.07604412693230983\n",
      "  Solver did converge at loss = 0.39173103098782963.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467169125521278 <= 0.07604412693230983\n",
      "    2. Newton decrement 0.23585994182121944 <= 0.07604412693230983\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049352228088864 <= 0.07604412693230983\n",
      "    2. Newton decrement 0.029019881363379466 <= 0.07604412693230983\n",
      "  Solver did converge at loss = 0.3913753553437296.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416558943320995 <= 0.07604412693230983\n",
      "    2. Newton decrement 0.23394314864672763 <= 0.07604412693230983\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153740888494406 <= 0.07604412693230983\n",
      "    2. Newton decrement 0.028158518363367736 <= 0.07604412693230983\n",
      "  Solver did converge at loss = 0.39490135831811085.\n",
      "Results: -0.9043098730934681\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 69.66408011098173\n",
      "Tolerance: 0.06924103638615565\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384139007365 <= 0.06924103638615565\n",
      "    2. Newton decrement 0.23634586783180125 <= 0.06924103638615565\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619502821716 <= 0.06924103638615565\n",
      "    2. Newton decrement 0.028506781362057313 <= 0.06924103638615565\n",
      "  Solver did converge at loss = 0.3917314478764327.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646716292597511 <= 0.06924103638615565\n",
      "    2. Newton decrement 0.23585981707404863 <= 0.06924103638615565\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298638178004 <= 0.06924103638615565\n",
      "    2. Newton decrement 0.029019719411475894 <= 0.06924103638615565\n",
      "  Solver did converge at loss = 0.3913757706524396.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649551594234 <= 0.06924103638615565\n",
      "    2. Newton decrement 0.2339430127055372 <= 0.06924103638615565\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688777182653 <= 0.06924103638615565\n",
      "    2. Newton decrement 0.028158344627905563 <= 0.06924103638615565\n",
      "  Solver did converge at loss = 0.39490180745131803.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9043098373781996\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 69.68169388541442\n",
      "Tolerance: 0.06925151016936854\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384150249648 <= 0.06925151016936854\n",
      "    2. Newton decrement 0.23634586806938318 <= 0.06925151016936854\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619601228714 <= 0.06925151016936854\n",
      "    2. Newton decrement 0.028506781641292066 <= 0.06925151016936854\n",
      "  Solver did converge at loss = 0.39173144713482677.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162937003608 <= 0.06925151016936854\n",
      "    2. Newton decrement 0.23585981729596567 <= 0.06925151016936854\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298733507107 <= 0.06925151016936854\n",
      "    2. Newton decrement 0.029019719699568736 <= 0.06925151016936854\n",
      "  Solver did converge at loss = 0.3913757699136493.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649562877358 <= 0.06925151016936854\n",
      "    2. Newton decrement 0.23394301294736677 <= 0.06925151016936854\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688869880363 <= 0.06925151016936854\n",
      "    2. Newton decrement 0.02815834493695202 <= 0.06925151016936854\n",
      "  Solver did converge at loss = 0.39490180665237445.\n",
      "Results: -0.9043098373781996\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.65381389934419\n",
      "Tolerance: 0.06923701004538185\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384132452178 <= 0.06923701004538185\n",
      "    2. Newton decrement 0.23634586769327076 <= 0.06923701004538185\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705619445442136 <= 0.06923701004538185\n",
      "    2. Newton decrement 0.02850678119923987 <= 0.06923701004538185\n",
      "  Solver did converge at loss = 0.39173144830885165.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162919544577 <= 0.06923701004538185\n",
      "    2. Newton decrement 0.23585981694465202 <= 0.06923701004538185\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049298582593289 <= 0.06923701004538185\n",
      "    2. Newton decrement 0.029019719243493385 <= 0.06923701004538185\n",
      "  Solver did converge at loss = 0.3913757710832169.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649545015217 <= 0.06923701004538185\n",
      "    2. Newton decrement 0.23394301256453015 <= 0.06923701004538185\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688723132 <= 0.06923701004538185\n",
      "    2. Newton decrement 0.028158344447705347 <= 0.06923701004538185\n",
      "  Solver did converge at loss = 0.39490180791716983.\n",
      "Results: -0.9043098373781996\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 78.88752190982692\n",
      "Tolerance: 0.07631331341552802\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405389339121945 <= 0.07631331341552802\n",
      "    2. Newton decrement 0.23634597772463564 <= 0.07631331341552802\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470566502248928 <= 0.07631331341552802\n",
      "    2. Newton decrement 0.028506910523915123 <= 0.07631331341552802\n",
      "  Solver did converge at loss = 0.3917311048437334.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646716802721707 <= 0.07631331341552802\n",
      "    2. Newton decrement 0.23585991972132553 <= 0.07631331341552802\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049342733902259 <= 0.07631331341552802\n",
      "    2. Newton decrement 0.029019852671645203 <= 0.07631331341552802\n",
      "  Solver did converge at loss = 0.3913754289201601.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241654770652196 <= 0.07631331341552802\n",
      "    2. Newton decrement 0.2339431245636501 <= 0.07631331341552802\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153731656187067 <= 0.07631331341552802\n",
      "    2. Newton decrement 0.02815848758338094 <= 0.07631331341552802\n",
      "  Solver did converge at loss = 0.39490143788830273.\n",
      "Results: -0.9043098445225374\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 78.87538008502705\n",
      "Tolerance: 0.07628107346675995\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405389333075792 <= 0.07628107346675995\n",
      "    2. Newton decrement 0.23634597759686457 <= 0.07628107346675995\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705664969562021 <= 0.07628107346675995\n",
      "    2. Newton decrement 0.02850691037373703 <= 0.07628107346675995\n",
      "  Solver did converge at loss = 0.3917311052425794.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467168021285866 <= 0.07628107346675995\n",
      "    2. Newton decrement 0.23585991960197844 <= 0.07628107346675995\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049342682630895 <= 0.07628107346675995\n",
      "    2. Newton decrement 0.02901985251670088 <= 0.07628107346675995\n",
      "  Solver did converge at loss = 0.39137542931749647.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416547645839614 <= 0.07628107346675995\n",
      "    2. Newton decrement 0.2339431244335934 <= 0.07628107346675995\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153731606329947 <= 0.07628107346675995\n",
      "    2. Newton decrement 0.02815848741716014 <= 0.07628107346675995\n",
      "  Solver did converge at loss = 0.39490143831800567.\n",
      "Results: -0.9043098445225374\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.53492591482221\n",
      "Tolerance: 0.06916513491299753\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384056398675 <= 0.06916513491299753\n",
      "    2. Newton decrement 0.23634586608603825 <= 0.06916513491299753\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705618779723354 <= 0.06916513491299753\n",
      "    2. Newton decrement 0.028506779310229265 <= 0.06916513491299753\n",
      "  Solver did converge at loss = 0.39173145332578385.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162844937308 <= 0.06916513491299753\n",
      "    2. Newton decrement 0.23585981544339196 <= 0.06916513491299753\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049297937697501 <= 0.06916513491299753\n",
      "    2. Newton decrement 0.029019717294558083 <= 0.06916513491299753\n",
      "  Solver did converge at loss = 0.39137577608110097.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416494686854083 <= 0.06916513491299753\n",
      "    2. Newton decrement 0.23394301092856307 <= 0.06916513491299753\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153688096035804 <= 0.06916513491299753\n",
      "    2. Newton decrement 0.0281583423570209 <= 0.06916513491299753\n",
      "  Solver did converge at loss = 0.39490181332198676.\n",
      "Results: -0.9043098516647351\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.49535746054666\n",
      "Tolerance: 0.06914217223311096\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384031028742 <= 0.06914217223311096\n",
      "    2. Newton decrement 0.23634586554989725 <= 0.06914217223311096\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705618557653058 <= 0.06914217223311096\n",
      "    2. Newton decrement 0.02850677868009316 <= 0.06914217223311096\n",
      "  Solver did converge at loss = 0.39173145499933204.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162820049815 <= 0.06914217223311096\n",
      "    2. Newton decrement 0.23585981494260155 <= 0.06914217223311096\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049297722573341 <= 0.06914217223311096\n",
      "    2. Newton decrement 0.029019716644432363 <= 0.06914217223311096\n",
      "  Solver did converge at loss = 0.3913757777482951.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649443223324 <= 0.06914217223311096\n",
      "    2. Newton decrement 0.23394301038283705 <= 0.06914217223311096\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153687886849182 <= 0.06914217223311096\n",
      "    2. Newton decrement 0.028158341659610852 <= 0.06914217223311096\n",
      "  Solver did converge at loss = 0.39490181512492495.\n",
      "Results: -0.9043098516647351\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.49978738407107\n",
      "Tolerance: 0.0691467625308901\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384033870495 <= 0.0691467625308901\n",
      "    2. Newton decrement 0.23634586560995183 <= 0.0691467625308901\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705618582527684 <= 0.0691467625308901\n",
      "    2. Newton decrement 0.02850677875067631 <= 0.0691467625308901\n",
      "  Solver did converge at loss = 0.39173145481187366.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162822837515 <= 0.0691467625308901\n",
      "    2. Newton decrement 0.23585981499869632 <= 0.0691467625308901\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01504929774666989 <= 0.0691467625308901\n",
      "    2. Newton decrement 0.029019716717254597 <= 0.0691467625308901\n",
      "  Solver did converge at loss = 0.3913757775615484.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649446075396 <= 0.0691467625308901\n",
      "    2. Newton decrement 0.23394301044396523 <= 0.0691467625308901\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153687910280665 <= 0.0691467625308901\n",
      "    2. Newton decrement 0.02815834173772952 <= 0.0691467625308901\n",
      "  Solver did converge at loss = 0.3949018149229732.\n",
      "Results: -0.9043098516647351\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.48064343256365\n",
      "Tolerance: 0.0691366591390859\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384021587242 <= 0.0691366591390859\n",
      "    2. Newton decrement 0.23634586535037094 <= 0.0691366591390859\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705618475008828 <= 0.0691366591390859\n",
      "    2. Newton decrement 0.028506778445586127 <= 0.0691366591390859\n",
      "  Solver did converge at loss = 0.3917314556221482.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646716281078786 <= 0.0691366591390859\n",
      "    2. Newton decrement 0.23585981475623083 <= 0.0691366591390859\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049297642514194 <= 0.0691366591390859\n",
      "    2. Newton decrement 0.02901971640248616 <= 0.0691366591390859\n",
      "  Solver did converge at loss = 0.39137577836874643.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649433747516 <= 0.0691366591390859\n",
      "    2. Newton decrement 0.23394301017974356 <= 0.0691366591390859\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153687808999678 <= 0.0691366591390859\n",
      "    2. Newton decrement 0.028158341400067646 <= 0.0691366591390859\n",
      "  Solver did converge at loss = 0.3949018157958936.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9043098516647351\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 69.46588715404093\n",
      "Tolerance: 0.06912939984762174\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384012114616 <= 0.06912939984762174\n",
      "    2. Newton decrement 0.23634586515018657 <= 0.06912939984762174\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705618392092225 <= 0.06912939984762174\n",
      "    2. Newton decrement 0.028506778210305943 <= 0.06912939984762174\n",
      "  Solver did converge at loss = 0.3917314562470175.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162801495359 <= 0.06912939984762174\n",
      "    2. Newton decrement 0.2358598145692457 <= 0.06912939984762174\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049297562191121 <= 0.06912939984762174\n",
      "    2. Newton decrement 0.029019716159742245 <= 0.06912939984762174\n",
      "  Solver did converge at loss = 0.3913757789912432.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649424240478 <= 0.06912939984762174\n",
      "    2. Newton decrement 0.23394300997598025 <= 0.06912939984762174\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153687730893677 <= 0.06912939984762174\n",
      "    2. Newton decrement 0.02815834113966881 <= 0.06912939984762174\n",
      "  Solver did converge at loss = 0.39490181646907446.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -0.9043098516647351\n",
      "================\n",
      "================\n",
      "Configuration:\n",
      "C: 69.45525532887511\n",
      "Tolerance: 0.06912518482829101\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405384005287154 <= 0.06912518482829101\n",
      "    2. Newton decrement 0.2363458650059021 <= 0.06912518482829101\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705618332329433 <= 0.06912518482829101\n",
      "    2. Newton decrement 0.02850677804072583 <= 0.06912518482829101\n",
      "  Solver did converge at loss = 0.39173145669739734.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162794797723 <= 0.06912518482829101\n",
      "    2. Newton decrement 0.2358598144344744 <= 0.06912518482829101\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049297504297648 <= 0.06912518482829101\n",
      "    2. Newton decrement 0.029019715984782642 <= 0.06912518482829101\n",
      "  Solver did converge at loss = 0.391375779439913.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416494173882106 <= 0.06912518482829101\n",
      "    2. Newton decrement 0.23394300982911634 <= 0.06912518482829101\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153687674598178 <= 0.06912518482829101\n",
      "    2. Newton decrement 0.028158340951984138 <= 0.06912518482829101\n",
      "  Solver did converge at loss = 0.394901816954275.\n",
      "Results: -0.9043098516647351\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.45893234540462\n",
      "Tolerance: 0.06912734360574034\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640538400764868 <= 0.06912734360574034\n",
      "    2. Newton decrement 0.2363458650558078 <= 0.06912734360574034\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.01470561835300048 <= 0.06912734360574034\n",
      "    2. Newton decrement 0.028506778099380996 <= 0.06912734360574034\n",
      "  Solver did converge at loss = 0.3917314565416179.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162797114338 <= 0.06912734360574034\n",
      "    2. Newton decrement 0.23585981448108967 <= 0.06912734360574034\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049297524322042 <= 0.06912734360574034\n",
      "    2. Newton decrement 0.029019716045298495 <= 0.06912734360574034\n",
      "  Solver did converge at loss = 0.39137577928472506.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649419758306 <= 0.06912734360574034\n",
      "    2. Newton decrement 0.2339430098799143 <= 0.06912734360574034\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153687694069902 <= 0.06912734360574034\n",
      "    2. Newton decrement 0.02815834101690141 <= 0.06912734360574034\n",
      "  Solver did converge at loss = 0.3949018167864516.\n",
      "Results: -0.9043098516647351\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.44397908813026\n",
      "Tolerance: 0.06911986959643265\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405383998043564 <= 0.06911986959643265\n",
      "    2. Newton decrement 0.23634586485282386 <= 0.06911986959643265\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705618268924284 <= 0.06911986959643265\n",
      "    2. Newton decrement 0.02850677786081035 <= 0.06911986959643265\n",
      "  Solver did converge at loss = 0.39173145717522617.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162787691885 <= 0.06911986959643265\n",
      "    2. Newton decrement 0.23585981429148958 <= 0.06911986959643265\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049297442875718 <= 0.06911986959643265\n",
      "    2. Newton decrement 0.02901971579915978 <= 0.06911986959643265\n",
      "  Solver did converge at loss = 0.39137577991592754.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649410118308 <= 0.06911986959643265\n",
      "    2. Newton decrement 0.23394300967330142 <= 0.06911986959643265\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153687614871522 <= 0.06911986959643265\n",
      "    2. Newton decrement 0.028158340752860837 <= 0.06911986959643265\n",
      "  Solver did converge at loss = 0.3949018174690469.\n",
      "Results: -0.9043098445225374\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.4370680896128\n",
      "Tolerance: 0.06911624878194242\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0640538399360294 <= 0.06911624878194242\n",
      "    2. Newton decrement 0.23634586475898076 <= 0.06911624878194242\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705618230054235 <= 0.06911624878194242\n",
      "    2. Newton decrement 0.028506777750514627 <= 0.06911624878194242\n",
      "  Solver did converge at loss = 0.3917314574681553.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162783335696 <= 0.06911624878194242\n",
      "    2. Newton decrement 0.235859814203834 <= 0.06911624878194242\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049297405221443 <= 0.06911624878194242\n",
      "    2. Newton decrement 0.029019715685365207 <= 0.06911624878194242\n",
      "  Solver did converge at loss = 0.39137578020774444.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649405661556 <= 0.06911624878194242\n",
      "    2. Newton decrement 0.23394300957778041 <= 0.06911624878194242\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153687578256635 <= 0.06911624878194242\n",
      "    2. Newton decrement 0.02815834063078992 <= 0.06911624878194242\n",
      "  Solver did converge at loss = 0.3949018177846237.\n",
      "Results: -0.9043098445225374\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.41911806433063\n",
      "Tolerance: 0.0691059136793741\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405383982065135 <= 0.0691059136793741\n",
      "    2. Newton decrement 0.23634586451515294 <= 0.0691059136793741\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705618129060474 <= 0.0691059136793741\n",
      "    2. Newton decrement 0.028506777463939606 <= 0.0691059136793741\n",
      "  Solver did converge at loss = 0.3917314582292563.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162772017303 <= 0.0691059136793741\n",
      "    2. Newton decrement 0.2358598139760829 <= 0.0691059136793741\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049297307386878 <= 0.0691059136793741\n",
      "    2. Newton decrement 0.029019715389699278 <= 0.0691059136793741\n",
      "  Solver did converge at loss = 0.3913757809659555.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649394081844 <= 0.0691059136793741\n",
      "    2. Newton decrement 0.23394300932959353 <= 0.0691059136793741\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153687483122205 <= 0.0691059136793741\n",
      "    2. Newton decrement 0.028158340313620037 <= 0.0691059136793741\n",
      "  Solver did converge at loss = 0.39490181860456847.\n",
      "Results: -0.9043098445225374\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 81.31437651900208\n",
      "Tolerance: 0.07596466104490715\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405390511357378 <= 0.07596466104490715\n",
      "    2. Newton decrement 0.23634600249700827 <= 0.07596466104490715\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705675284171773 <= 0.07596466104490715\n",
      "    2. Newton decrement 0.02850693964071663 <= 0.07596466104490715\n",
      "  Solver did converge at loss = 0.3917310275148432.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467169177167671 <= 0.07596466104490715\n",
      "    2. Newton decrement 0.23585994286043774 <= 0.07596466104490715\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049352674544032 <= 0.07596466104490715\n",
      "    2. Newton decrement 0.02901988271257821 <= 0.07596466104490715\n",
      "  Solver did converge at loss = 0.39137535188388056.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241655947171835 <= 0.07596466104490715\n",
      "    2. Newton decrement 0.2339431497792033 <= 0.07596466104490715\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153741322635659 <= 0.07596466104490715\n",
      "    2. Newton decrement 0.028158519810771256 <= 0.07596466104490715\n",
      "  Solver did converge at loss = 0.39490135457639725.\n",
      "Results: -0.9043098730934681\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.39780763325983\n",
      "Tolerance: 0.06909560503723802\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405383968359588 <= 0.06909560503723802\n",
      "    2. Newton decrement 0.23634586422551485 <= 0.06909560503723802\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705618009092036 <= 0.06909560503723802\n",
      "    2. Newton decrement 0.02850677712352269 <= 0.06909560503723802\n",
      "  Solver did converge at loss = 0.39173145913335333.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06467162758572388 <= 0.06909560503723802\n",
      "    2. Newton decrement 0.23585981370554177 <= 0.06909560503723802\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049297191170789 <= 0.06909560503723802\n",
      "    2. Newton decrement 0.029019715038483565 <= 0.06909560503723802\n",
      "  Solver did converge at loss = 0.3913757818666197.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06241649380326511 <= 0.06909560503723802\n",
      "    2. Newton decrement 0.23394300903477722 <= 0.06909560503723802\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153687370113821 <= 0.06909560503723802\n",
      "    2. Newton decrement 0.028158339936860177 <= 0.06909560503723802\n",
      "  Solver did converge at loss = 0.39490181957856485.\n",
      "Results: -0.9043098445225374\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Configuration:\n",
      "C: 69.38193510882492\n",
      "Tolerance: 0.06908673380429567\n",
      "Solver: newton-cholesky\n",
      "Oversampling Method: none\n",
      "----------------\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.06405383958145905 <= 0.06908673380429567\n",
      "    2. Newton decrement 0.2363458640096695 <= 0.06908673380429567\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014705617919688808 <= 0.06908673380429567\n",
      "    2. Newton decrement 0.02850677686983614 <= 0.06908673380429567\n",
      "  Solver did converge at loss = 0.39173145980710744.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.0646716274855292 <= 0.06908673380429567\n",
      "    2. Newton decrement 0.23585981350392857 <= 0.06908673380429567\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.015049297104563904 <= 0.06908673380429567\n",
      "    2. Newton decrement 0.02901971477674941 <= 0.06908673380429567\n",
      "  Solver did converge at loss = 0.3913757825378156.\n",
      "Newton iter=1\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.062416493700757185 <= 0.06908673380429567\n",
      "    2. Newton decrement 0.23394300881507313 <= 0.06908673380429567\n",
      "Newton iter=2\n",
      "  Check Convergence\n",
      "    1. max |gradient| 0.014153687285897469 <= 0.06908673380429567\n",
      "    2. Newton decrement 0.028158339656090037 <= 0.06908673380429567\n",
      "  Solver did converge at loss = 0.3949018203044095.\n",
      "Results: -0.9043098373781996\n",
      "================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: [95.68017653731005, 0.058807524193284035, 'sag', 'none']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "import numpy as np\n",
    "import sys\n",
    "# Define the search space\n",
    "search_space = [\n",
    "    Real(0.001, 100, name='C'),\n",
    "    Real(0.00001, 0.1, name='tol'),\n",
    "    Categorical(['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'], name='solver'),\n",
    "    Categorical(['none', 'ada'], name='oversampling_method')\n",
    "]\n",
    "\n",
    "# Define your objective function (e.g., maximizing accuracy)\n",
    "@use_named_args(search_space)\n",
    "def objective_function(C, tol, solver, oversampling_method):\n",
    "    print(\"================\")\n",
    "    print(\"Configuration:\")\n",
    "    print(\"C:\", C)\n",
    "    print(\"Tolerance:\", tol)\n",
    "    print(\"Solver:\", solver)   \n",
    "    print(\"Oversampling Method:\", oversampling_method)\n",
    "    print(\"----------------\")\n",
    "    try:\n",
    "        if oversampling_method == 'none':\n",
    "            X = loans_train_df.loc[:, loans_train_df.columns != \"loan_status\"]\n",
    "            y = loans_train_df[\"loan_status\"]\n",
    "        elif oversampling_method == 'ada':\n",
    "            X = loans_train_ada_df.loc[:, loans_train_ada_df.columns != \"loan_status\"]\n",
    "            y = loans_train_ada_df[\"loan_status\"]\n",
    "            \n",
    "        model = LogisticRegression(class_weight='balanced', C=C, tol=tol, solver=solver, max_iter=300, verbose=True)\n",
    "        roc_auc = cross_val_score(model, X, y, cv=3, scoring='roc_auc').mean()\n",
    "\n",
    "        print(\"Results:\", -roc_auc)\n",
    "        df_hyper_tuning.loc[len(df_hyper_tuning.index)] = [C, tol, solver, oversampling_method, roc_auc] \n",
    "        print(\"================\")\n",
    "        return -roc_auc\n",
    "    except:\n",
    "        print(\"Invalid Config\")\n",
    "        return 100000\n",
    "        \n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "res = gp_minimize(objective_function, search_space, n_calls=500)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters:\", res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e67131-1351-493e-81a6-ad05fae2f05a",
   "metadata": {},
   "source": [
    "These tuning results are saved in a dataframe. The hyperparameter tuning results for all models can be viewed in the <b>./hyper_tuning</b> directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfcdef0-a4fc-4ace-99d9-406f3a1a476f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>tol</th>\n",
       "      <th>solver</th>\n",
       "      <th>oversampling_method</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>95.680177</td>\n",
       "      <td>0.058808</td>\n",
       "      <td>sag</td>\n",
       "      <td>none</td>\n",
       "      <td>0.904708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>15.491306</td>\n",
       "      <td>0.053997</td>\n",
       "      <td>saga</td>\n",
       "      <td>none</td>\n",
       "      <td>0.904677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>54.809968</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>sag</td>\n",
       "      <td>none</td>\n",
       "      <td>0.904670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.015138</td>\n",
       "      <td>sag</td>\n",
       "      <td>none</td>\n",
       "      <td>0.904654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>90.684544</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>none</td>\n",
       "      <td>0.904632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>88.349953</td>\n",
       "      <td>0.071328</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.791064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>11.401321</td>\n",
       "      <td>0.076612</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.791064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.791064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.791064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.423257</td>\n",
       "      <td>0.075388</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.791064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              C       tol     solver oversampling_method   roc_auc\n",
       "103   95.680177  0.058808        sag                none  0.904708\n",
       "374   15.491306  0.053997       saga                none  0.904677\n",
       "367   54.809968  0.021123        sag                none  0.904670\n",
       "409  100.000000  0.015138        sag                none  0.904654\n",
       "94    90.684544  0.007061  liblinear                none  0.904632\n",
       "..          ...       ...        ...                 ...       ...\n",
       "176   88.349953  0.071328      lbfgs                 ada  0.791064\n",
       "116   11.401321  0.076612      lbfgs                 ada  0.791064\n",
       "394    0.001000  0.100000      lbfgs                 ada  0.791064\n",
       "255  100.000000  0.100000      lbfgs                 ada  0.791064\n",
       "1     52.423257  0.075388      lbfgs                 ada  0.791064\n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyper_tuning.sort_values(by=['roc_auc'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bba8eb3a-0460-48fd-8f71-98fe23446730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyper_tuning.to_csv('hyper_tuning/lrc_hyper_tuning.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f516b-fac1-48d6-ad2b-7a0e1feae0f1",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a0b4be-c8fb-4bdf-9959-798cec729398",
   "metadata": {},
   "source": [
    "The results showed that the following configuration produced the best results:\n",
    "\n",
    "<ol>\n",
    "   <li><b>C:</b> 95.680177</li>\n",
    "    <li><b>tol:</b> 0.058808</li>\n",
    "    <li><b>solver:</b> sag</li>\n",
    "    <li><b>oversampling_method: </b>none</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c7a60-8cd8-40e6-8037-35f6909af97a",
   "metadata": {},
   "source": [
    "First, it can be seen that not performing oversampling generally performed better for the LRC as opposed to ADASYN. This may be due to how ADASYN generates synthetic data of the minority class that is harder to differentiate from the initial majority class. This, in turn, makes the classification problem harder for LRCs, considering that it generally performs well for linearly separable data. The introduction of oversampling may have led to the data being more non-linearly separable, and thus, causing a lower performance for LRCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5154c8cc-5f62-4820-8739-273dd03045e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN AUC: 0.8686842180528066\n",
      "None AUC: 0.901555980468623\n"
     ]
    }
   ],
   "source": [
    "print(\"ADASYN AUC:\", df_hyper_tuning[df_hyper_tuning.oversampling_method == 'ada']['roc_auc'].mean())\n",
    "print(\"None AUC:\", df_hyper_tuning[df_hyper_tuning.oversampling_method == 'none']['roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35adb63d-a5f1-4534-8f4c-15db5a16d672",
   "metadata": {},
   "source": [
    "Typically, the high C value may entail overfitting, but the validation score of the configuration says otherwise.\n",
    "\n",
    "In the case of the LRC, having a high C value means lower regularization strengths, entailing a lower bias but a higher variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b065b8-3830-46d5-802b-669e7a64bb1e",
   "metadata": {},
   "source": [
    "Finally, according to the <a href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">sci-kit learn documentations</a>, the \"sag\" solver is able to converge fast for datasets whose features are approximately on the same scale. The result of the hyperparameter tuning process to choose the \"sag\" solver may due to the data cleaning performed, as all of the continuous features in the data have been scaled via standardization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b2a7e-29ac-4145-8bce-e3645b5515e4",
   "metadata": {},
   "source": [
    "# 4. Exporting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1a1f0-a7c4-4fc6-9d6d-8eabbbbac38c",
   "metadata": {},
   "source": [
    "The model with the best configuration found during the hyperparameter tuning process is saved in the <b>./outputs</b> directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d909bfcd-9e27-48d5-a878-b420df7e265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(class_weight='balanced', C=res.x[0], tol=res.x[1], solver=res.x[2], verbose=True, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ce9994-121f-469c-bf24-dba44eea86bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 7 epochs took 0 seconds\n",
      "convergence after 7 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 8 epochs took 0 seconds\n",
      "convergence after 7 epochs took 1 seconds\n",
      "Validation AUC: 0.9043585292763282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "if res.x[3] == 'none':\n",
    "    X = loans_train_df.loc[:, loans_train_df.columns != \"loan_status\"]\n",
    "    y = loans_train_df[\"loan_status\"]\n",
    "elif res.x[3] == 'ada':\n",
    "    X = loans_train_ada_df.loc[:, loans_train_ada_df.columns != \"loan_status\"]\n",
    "    y = loans_train_ada_df[\"loan_status\"]\n",
    "    \n",
    "clf.fit(X,y)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = cross_val_score(clf, X, y, cv=3, scoring='roc_auc').mean()\n",
    "print(\"Validation AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8bd99-883a-4770-97bc-cb81168dc927",
   "metadata": {},
   "source": [
    "Validation AUC from 3-fold cross validation: 0.9043585292763282\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb450233-734b-4031-843e-0bce46c7c188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 6 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./outputs/lrc_model.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "clf.fit(X,y)\n",
    "dump(clf, './outputs/lrc_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7be770-8cbf-4196-a66b-d86c094a27aa",
   "metadata": {},
   "source": [
    "# 5. Fitting into Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b958b1e-90f7-4400-b335-633dd0a7e40b",
   "metadata": {},
   "source": [
    "Finally, we can now generate the predictions made by the DTC on the test data. This is done by isolating the features of the test samples, forwarding it to the DTC for prediction, and appending the predicted class labels with the corresponding IDs of the test data. Predictions for the models can be found in the <b>./predictions</b> directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d3d89b9-51c6-4402-b91a-46eac7d7618b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>PERSON_HOME_OWNERSHIP_MORTGAGE</th>\n",
       "      <th>...</th>\n",
       "      <th>LOAN_GRADE_B</th>\n",
       "      <th>LOAN_GRADE_C</th>\n",
       "      <th>LOAN_GRADE_D</th>\n",
       "      <th>LOAN_GRADE_E</th>\n",
       "      <th>LOAN_GRADE_F</th>\n",
       "      <th>LOAN_GRADE_G</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_11_17</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_18_above</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_5_10</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_5_below</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58645</td>\n",
       "      <td>-0.755638</td>\n",
       "      <td>0.404383</td>\n",
       "      <td>-0.117198</td>\n",
       "      <td>2.836600</td>\n",
       "      <td>1.455666</td>\n",
       "      <td>2.189522</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.364513</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58646</td>\n",
       "      <td>-0.257331</td>\n",
       "      <td>1.127233</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.140622</td>\n",
       "      <td>0.722635</td>\n",
       "      <td>-0.646041</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.266122</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58647</td>\n",
       "      <td>-0.257331</td>\n",
       "      <td>-1.418731</td>\n",
       "      <td>0.403331</td>\n",
       "      <td>-0.937769</td>\n",
       "      <td>1.748450</td>\n",
       "      <td>-0.318861</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.364513</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58648</td>\n",
       "      <td>0.905387</td>\n",
       "      <td>-0.300610</td>\n",
       "      <td>0.169270</td>\n",
       "      <td>-0.398573</td>\n",
       "      <td>-0.470628</td>\n",
       "      <td>-0.209801</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620670</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58649</td>\n",
       "      <td>-0.257331</td>\n",
       "      <td>1.259932</td>\n",
       "      <td>0.923860</td>\n",
       "      <td>1.039281</td>\n",
       "      <td>1.573370</td>\n",
       "      <td>-0.100741</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.266122</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39093</th>\n",
       "      <td>97738</td>\n",
       "      <td>-0.921741</td>\n",
       "      <td>-1.332883</td>\n",
       "      <td>-0.486519</td>\n",
       "      <td>-1.117500</td>\n",
       "      <td>0.044689</td>\n",
       "      <td>-0.646041</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.266122</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39094</th>\n",
       "      <td>97739</td>\n",
       "      <td>-0.921741</td>\n",
       "      <td>-0.389963</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>-0.398573</td>\n",
       "      <td>-1.782989</td>\n",
       "      <td>-0.100741</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.721995</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39095</th>\n",
       "      <td>97740</td>\n",
       "      <td>3.895232</td>\n",
       "      <td>0.098465</td>\n",
       "      <td>-1.896898</td>\n",
       "      <td>1.039281</td>\n",
       "      <td>-1.043084</td>\n",
       "      <td>0.989861</td>\n",
       "      <td>0</td>\n",
       "      <td>2.637868</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39096</th>\n",
       "      <td>97741</td>\n",
       "      <td>-0.921741</td>\n",
       "      <td>-1.019656</td>\n",
       "      <td>0.169270</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>1.425586</td>\n",
       "      <td>2.516703</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.266122</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39097</th>\n",
       "      <td>97742</td>\n",
       "      <td>0.573182</td>\n",
       "      <td>-0.531228</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>1.839088</td>\n",
       "      <td>-0.108264</td>\n",
       "      <td>3.062003</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018914</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39098 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  person_age  person_income  person_emp_length  loan_amnt  \\\n",
       "0      58645   -0.755638       0.404383          -0.117198   2.836600   \n",
       "1      58646   -0.257331       1.127233           0.601227   0.140622   \n",
       "2      58647   -0.257331      -1.418731           0.403331  -0.937769   \n",
       "3      58648    0.905387      -0.300610           0.169270  -0.398573   \n",
       "4      58649   -0.257331       1.259932           0.923860   1.039281   \n",
       "...      ...         ...            ...                ...        ...   \n",
       "39093  97738   -0.921741      -1.332883          -0.486519  -1.117500   \n",
       "39094  97739   -0.921741      -0.389963           0.601227  -0.398573   \n",
       "39095  97740    3.895232       0.098465          -1.896898   1.039281   \n",
       "39096  97741   -0.921741      -1.019656           0.169270   0.859550   \n",
       "39097  97742    0.573182      -0.531228           0.601227   1.839088   \n",
       "\n",
       "       loan_int_rate  loan_percent_income  cb_person_default_on_file  \\\n",
       "0           1.455666             2.189522                          0   \n",
       "1           0.722635            -0.646041                          1   \n",
       "2           1.748450            -0.318861                          1   \n",
       "3          -0.470628            -0.209801                          0   \n",
       "4           1.573370            -0.100741                          1   \n",
       "...              ...                  ...                        ...   \n",
       "39093       0.044689            -0.646041                          0   \n",
       "39094      -1.782989            -0.100741                          0   \n",
       "39095      -1.043084             0.989861                          0   \n",
       "39096       1.425586             2.516703                          1   \n",
       "39097      -0.108264             3.062003                          0   \n",
       "\n",
       "       cb_person_cred_hist_length  PERSON_HOME_OWNERSHIP_MORTGAGE  ...  \\\n",
       "0                       -1.364513                               0  ...   \n",
       "1                       -0.266122                               1  ...   \n",
       "2                       -1.364513                               0  ...   \n",
       "3                        0.620670                               0  ...   \n",
       "4                       -0.266122                               1  ...   \n",
       "...                           ...                             ...  ...   \n",
       "39093                   -0.266122                               1  ...   \n",
       "39094                   -0.721995                               1  ...   \n",
       "39095                    2.637868                               1  ...   \n",
       "39096                   -0.266122                               1  ...   \n",
       "39097                    1.018914                               0  ...   \n",
       "\n",
       "       LOAN_GRADE_B  LOAN_GRADE_C  LOAN_GRADE_D  LOAN_GRADE_E  LOAN_GRADE_F  \\\n",
       "0                 0             0             0             0             1   \n",
       "1                 0             1             0             0             0   \n",
       "2                 0             0             0             1             0   \n",
       "3                 0             0             0             0             0   \n",
       "4                 0             0             1             0             0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "39093             1             0             0             0             0   \n",
       "39094             0             0             0             0             0   \n",
       "39095             0             0             0             0             0   \n",
       "39096             0             0             1             0             0   \n",
       "39097             1             0             0             0             0   \n",
       "\n",
       "       LOAN_GRADE_G  CB_PERSON_CRED_HIST_LENGTH_11_17  \\\n",
       "0                 0                                 0   \n",
       "1                 0                                 0   \n",
       "2                 0                                 0   \n",
       "3                 0                                 0   \n",
       "4                 0                                 0   \n",
       "...             ...                               ...   \n",
       "39093             0                                 0   \n",
       "39094             0                                 0   \n",
       "39095             0                                 0   \n",
       "39096             0                                 0   \n",
       "39097             0                                 0   \n",
       "\n",
       "       CB_PERSON_CRED_HIST_LENGTH_18_above  CB_PERSON_CRED_HIST_LENGTH_5_10  \\\n",
       "0                                        0                                0   \n",
       "1                                        0                                0   \n",
       "2                                        0                                0   \n",
       "3                                        0                                1   \n",
       "4                                        0                                0   \n",
       "...                                    ...                              ...   \n",
       "39093                                    0                                0   \n",
       "39094                                    0                                0   \n",
       "39095                                    1                                0   \n",
       "39096                                    0                                0   \n",
       "39097                                    0                                1   \n",
       "\n",
       "       CB_PERSON_CRED_HIST_LENGTH_5_below  \n",
       "0                                       1  \n",
       "1                                       1  \n",
       "2                                       1  \n",
       "3                                       0  \n",
       "4                                       1  \n",
       "...                                   ...  \n",
       "39093                                   1  \n",
       "39094                                   1  \n",
       "39095                                   0  \n",
       "39096                                   1  \n",
       "39097                                   0  \n",
       "\n",
       "[39098 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Import Testing Dataset\n",
    "loans_test_df = pd.read_csv('./outputs/cleaned_loans_test.csv')\n",
    "loans_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371db56e-c3b2-4dc0-8b41-e4eaa9393a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>PERSON_HOME_OWNERSHIP_MORTGAGE</th>\n",
       "      <th>PERSON_HOME_OWNERSHIP_OTHER</th>\n",
       "      <th>...</th>\n",
       "      <th>LOAN_GRADE_B</th>\n",
       "      <th>LOAN_GRADE_C</th>\n",
       "      <th>LOAN_GRADE_D</th>\n",
       "      <th>LOAN_GRADE_E</th>\n",
       "      <th>LOAN_GRADE_F</th>\n",
       "      <th>LOAN_GRADE_G</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_11_17</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_18_above</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_5_10</th>\n",
       "      <th>CB_PERSON_CRED_HIST_LENGTH_5_below</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.755638</td>\n",
       "      <td>0.404383</td>\n",
       "      <td>-0.117198</td>\n",
       "      <td>2.836600</td>\n",
       "      <td>1.455666</td>\n",
       "      <td>2.189522</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.364513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.257331</td>\n",
       "      <td>1.127233</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.140622</td>\n",
       "      <td>0.722635</td>\n",
       "      <td>-0.646041</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.266122</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.257331</td>\n",
       "      <td>-1.418731</td>\n",
       "      <td>0.403331</td>\n",
       "      <td>-0.937769</td>\n",
       "      <td>1.748450</td>\n",
       "      <td>-0.318861</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.364513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.905387</td>\n",
       "      <td>-0.300610</td>\n",
       "      <td>0.169270</td>\n",
       "      <td>-0.398573</td>\n",
       "      <td>-0.470628</td>\n",
       "      <td>-0.209801</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.257331</td>\n",
       "      <td>1.259932</td>\n",
       "      <td>0.923860</td>\n",
       "      <td>1.039281</td>\n",
       "      <td>1.573370</td>\n",
       "      <td>-0.100741</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.266122</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39093</th>\n",
       "      <td>-0.921741</td>\n",
       "      <td>-1.332883</td>\n",
       "      <td>-0.486519</td>\n",
       "      <td>-1.117500</td>\n",
       "      <td>0.044689</td>\n",
       "      <td>-0.646041</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.266122</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39094</th>\n",
       "      <td>-0.921741</td>\n",
       "      <td>-0.389963</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>-0.398573</td>\n",
       "      <td>-1.782989</td>\n",
       "      <td>-0.100741</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.721995</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39095</th>\n",
       "      <td>3.895232</td>\n",
       "      <td>0.098465</td>\n",
       "      <td>-1.896898</td>\n",
       "      <td>1.039281</td>\n",
       "      <td>-1.043084</td>\n",
       "      <td>0.989861</td>\n",
       "      <td>0</td>\n",
       "      <td>2.637868</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39096</th>\n",
       "      <td>-0.921741</td>\n",
       "      <td>-1.019656</td>\n",
       "      <td>0.169270</td>\n",
       "      <td>0.859550</td>\n",
       "      <td>1.425586</td>\n",
       "      <td>2.516703</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.266122</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39097</th>\n",
       "      <td>0.573182</td>\n",
       "      <td>-0.531228</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>1.839088</td>\n",
       "      <td>-0.108264</td>\n",
       "      <td>3.062003</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39098 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_age  person_income  person_emp_length  loan_amnt  loan_int_rate  \\\n",
       "0       -0.755638       0.404383          -0.117198   2.836600       1.455666   \n",
       "1       -0.257331       1.127233           0.601227   0.140622       0.722635   \n",
       "2       -0.257331      -1.418731           0.403331  -0.937769       1.748450   \n",
       "3        0.905387      -0.300610           0.169270  -0.398573      -0.470628   \n",
       "4       -0.257331       1.259932           0.923860   1.039281       1.573370   \n",
       "...           ...            ...                ...        ...            ...   \n",
       "39093   -0.921741      -1.332883          -0.486519  -1.117500       0.044689   \n",
       "39094   -0.921741      -0.389963           0.601227  -0.398573      -1.782989   \n",
       "39095    3.895232       0.098465          -1.896898   1.039281      -1.043084   \n",
       "39096   -0.921741      -1.019656           0.169270   0.859550       1.425586   \n",
       "39097    0.573182      -0.531228           0.601227   1.839088      -0.108264   \n",
       "\n",
       "       loan_percent_income  cb_person_default_on_file  \\\n",
       "0                 2.189522                          0   \n",
       "1                -0.646041                          1   \n",
       "2                -0.318861                          1   \n",
       "3                -0.209801                          0   \n",
       "4                -0.100741                          1   \n",
       "...                    ...                        ...   \n",
       "39093            -0.646041                          0   \n",
       "39094            -0.100741                          0   \n",
       "39095             0.989861                          0   \n",
       "39096             2.516703                          1   \n",
       "39097             3.062003                          0   \n",
       "\n",
       "       cb_person_cred_hist_length  PERSON_HOME_OWNERSHIP_MORTGAGE  \\\n",
       "0                       -1.364513                               0   \n",
       "1                       -0.266122                               1   \n",
       "2                       -1.364513                               0   \n",
       "3                        0.620670                               0   \n",
       "4                       -0.266122                               1   \n",
       "...                           ...                             ...   \n",
       "39093                   -0.266122                               1   \n",
       "39094                   -0.721995                               1   \n",
       "39095                    2.637868                               1   \n",
       "39096                   -0.266122                               1   \n",
       "39097                    1.018914                               0   \n",
       "\n",
       "       PERSON_HOME_OWNERSHIP_OTHER  ...  LOAN_GRADE_B  LOAN_GRADE_C  \\\n",
       "0                                0  ...             0             0   \n",
       "1                                0  ...             0             1   \n",
       "2                                0  ...             0             0   \n",
       "3                                0  ...             0             0   \n",
       "4                                0  ...             0             0   \n",
       "...                            ...  ...           ...           ...   \n",
       "39093                            0  ...             1             0   \n",
       "39094                            0  ...             0             0   \n",
       "39095                            0  ...             0             0   \n",
       "39096                            0  ...             0             0   \n",
       "39097                            0  ...             1             0   \n",
       "\n",
       "       LOAN_GRADE_D  LOAN_GRADE_E  LOAN_GRADE_F  LOAN_GRADE_G  \\\n",
       "0                 0             0             1             0   \n",
       "1                 0             0             0             0   \n",
       "2                 0             1             0             0   \n",
       "3                 0             0             0             0   \n",
       "4                 1             0             0             0   \n",
       "...             ...           ...           ...           ...   \n",
       "39093             0             0             0             0   \n",
       "39094             0             0             0             0   \n",
       "39095             0             0             0             0   \n",
       "39096             1             0             0             0   \n",
       "39097             0             0             0             0   \n",
       "\n",
       "       CB_PERSON_CRED_HIST_LENGTH_11_17  CB_PERSON_CRED_HIST_LENGTH_18_above  \\\n",
       "0                                     0                                    0   \n",
       "1                                     0                                    0   \n",
       "2                                     0                                    0   \n",
       "3                                     0                                    0   \n",
       "4                                     0                                    0   \n",
       "...                                 ...                                  ...   \n",
       "39093                                 0                                    0   \n",
       "39094                                 0                                    0   \n",
       "39095                                 0                                    1   \n",
       "39096                                 0                                    0   \n",
       "39097                                 0                                    0   \n",
       "\n",
       "       CB_PERSON_CRED_HIST_LENGTH_5_10  CB_PERSON_CRED_HIST_LENGTH_5_below  \n",
       "0                                    0                                   1  \n",
       "1                                    0                                   1  \n",
       "2                                    0                                   1  \n",
       "3                                    1                                   0  \n",
       "4                                    0                                   1  \n",
       "...                                ...                                 ...  \n",
       "39093                                0                                   1  \n",
       "39094                                0                                   1  \n",
       "39095                                0                                   0  \n",
       "39096                                0                                   1  \n",
       "39097                                1                                   0  \n",
       "\n",
       "[39098 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = loans_test_df.loc[:, loans_test_df.columns != \"id\"]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "830e57d8-3e01-4f09-97f1-f0ff467f82b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc9307ba-4d77-4f2a-b6ea-7fd9feeb33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_predictions_df = loans_test_df[\"id\"].copy(deep=True)\n",
    "loans_predictions_df = loans_predictions_df.to_frame()\n",
    "loans_predictions_df.insert(1, 'loan_status', y_pred, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb837f7a-2495-418b-ac4d-5bc25b7db9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39093</th>\n",
       "      <td>97738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39094</th>\n",
       "      <td>97739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39095</th>\n",
       "      <td>97740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39096</th>\n",
       "      <td>97741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39097</th>\n",
       "      <td>97742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39098 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  loan_status\n",
       "0      58645            1\n",
       "1      58646            0\n",
       "2      58647            1\n",
       "3      58648            0\n",
       "4      58649            1\n",
       "...      ...          ...\n",
       "39093  97738            0\n",
       "39094  97739            0\n",
       "39095  97740            0\n",
       "39096  97741            1\n",
       "39097  97742            1\n",
       "\n",
       "[39098 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f45d08e3-0419-4750-bf78-4da0546cab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_predictions_df.to_csv('predictions/lrc_predictions.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290308d-dd16-49b7-b7ae-e838e4fe0990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
